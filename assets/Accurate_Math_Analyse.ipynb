{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Accurate Integer Mathematics in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "The model weightings created by the sister CoLab [Accurate_Math_Train](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/Accurate_Math_Train.ipynb) are loaded from HuggingFace.\n",
        "\n",
        "Focus is on ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K.pth which was initialised with add_d6_l2_h3_dm510_dh170_ctx22_seed129000_train30K.pth before being trained, and has a (post training) loss of 1.3e-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens used in vocab. (Token indexes 0 to 9 represent digits 0 to 9)\n",
        "PLUS_INDEX = 10\n",
        "MINUS_INDEX = 11\n",
        "EQUALS_INDEX = 12\n",
        "MULT_INDEX = 13\n",
        "DIV_INDEX = 14\n",
        "MAX_INDEX = DIV_INDEX"
      ],
      "metadata": {
        "id": "cwXrSj8KGj-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Main configuration class for main model creation and training\n",
        "class Config():\n",
        "  #@markdown Main Model\n",
        "  n_layers: int = 3 #@param\n",
        "  n_heads: int = 4 #@param\n",
        "\n",
        "  d_vocab: int = MAX_INDEX+1\n",
        "  d_model: int = 510\n",
        "  d_mlp: int = 4 * d_model\n",
        "  d_head: int = 170\n",
        "  seed: int = 129000 #@param\n",
        "\n",
        "  #@markdown Data\n",
        "  n_digits: int = 6 #@param\n",
        "  n_ctx: int = 3 * n_digits + 4\n",
        "  act_fn: str = 'relu'\n",
        "  batch_size: int = 64 #@param\n",
        "\n",
        "  #@markdown Optimizer\n",
        "  n_training_steps: int = 45000 #@param\n",
        "  lr: float = 0.00008 #@param\n",
        "  weight_decay: int = 0.1 #@param\n",
        "\n",
        "  # Save graphs to CoLab temp files as PDF and HTML. Can manually export files for re-use in papers.\n",
        "  save_graph_to_file: bool = True\n",
        "\n",
        "  #@markdown Actions\n",
        "\n",
        "  # Percent of questions that are multiplication, subtraction (rest are addition questions).\n",
        "  perc_mult: int = 0 #@param\n",
        "  perc_sub: int = 100 #@param\n",
        "  def perc_add(self):\n",
        "    return max(0, 100 - self.perc_mult - self.perc_sub)\n",
        "\n",
        "  #@markdown Insert Model\n",
        "  insert: bool = True #@param   Was the model trained using an inserted \"known good\" model\n",
        "\n",
        "  # Save graphs to CoLab temp files as PDF and HTML. Can manually export files for re-use in papers.\n",
        "  save_graph_to_file: bool = True\n",
        "\n",
        "  # The format to output prettytable in. Options are text|html|json|csv|latex\n",
        "  # Use Text for this CoLab, latex for Overleaf output, and html for GitHub blog output\n",
        "  table_out_format: str = \"text\"\n",
        "\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def file_name_suffix(digits, layers, heads, d_model, d_head, ctx, seed, training_steps):\n",
        "  epoch_str = str(training_steps//1000) + \"K\"\n",
        "  return '_d{}_l{}_h{}_dm{}_dh{}_ctx{}_seed{}_train{}'.format(digits, layers, heads, d_model, d_head, ctx, seed, epoch_str)\n",
        "\n",
        "fname_prefix = 'ins_' if cfg.insert else ''\n",
        "fname_prefix += 'mul' if cfg.perc_mult == 100 else 'sub' if cfg.perc_sub == 100 else 'add' if cfg.perc_add() == 100 else 'mix'\n",
        "main_fname_suffix = fname_prefix + file_name_suffix(cfg.n_digits, cfg.n_layers, cfg.n_heads, cfg.d_model, cfg.d_head, cfg.n_ctx, cfg.seed, cfg.n_training_steps)\n",
        "main_fname_full = main_fname_suffix + '.pth'\n",
        "\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Mult=\", cfg.perc_mult, \"%Sub=\", cfg.perc_sub, \"%Add=\", cfg.perc_add(), main_fname_suffix)\n",
        "\n",
        "print_config()"
      ],
      "metadata": {
        "id": "n0DJkn5l2gq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2fb4e41-216d-4eaf-8268-c82e2ed0badf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 2: Import libraries\n",
        "Imports standard libraries. Don't bother reading.\n",
        "You will need to give permission for this CoLab to access your Google Drive to load the model weights (created by the \"Accurate Math - Train\" CoLab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d1ab5c-e669-470c-a30b-1fa48fcaac31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable) (0.2.12)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.25.0)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.14.1)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.16.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.25)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.0)\n",
            "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.1.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.1)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.35.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.5.0)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.1)\n",
            "Requirement already satisfied: typeguard<3,>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (12.3.101)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer_lens) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer_lens) (0.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.40)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
            "Requirement already satisfied: torchtyping in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtyping) (2.1.2)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from torchtyping) (2.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->torchtyping) (12.3.101)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    %pip install numpy\n",
        "    %pip install matplotlib\n",
        "    %pip install prettytable\n",
        "\n",
        "    %pip install kaleido\n",
        "    %pip install transformer_lens\n",
        "    %pip install torchtyping\n",
        "    %pip install transformers\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d16f10-3039-429b-9b6a-1bf9c19f8053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use seaborn library to display heatmaps\n",
        "use_sns= True\n",
        "try:\n",
        "  import seaborn as sns\n",
        "except Exception as e:\n",
        "  print(\"sns import exception\", e)\n",
        "  use_sns = False\n",
        "\n",
        "# Use Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import exception\", e)\n",
        "  use_pca = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6TE7A9SxySA",
        "outputId": "71c5e9fc-03e3-4db7-ba1a-0e687bfc9ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sns import exception module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'\n",
            "pca import exception module 'numpy.linalg._umath_linalg' has no attribute '_ilp64'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3: Create model\n",
        "This section defines the token embedding / unembedding and creates the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QYFZIalJ3tK"
      },
      "outputs": [],
      "source": [
        "# Embedding / Unembedding\n",
        "\n",
        "def token_to_char(i):\n",
        "  if i < 10:\n",
        "   return str(i)\n",
        "  if i == PLUS_INDEX:\n",
        "    return \"+\"\n",
        "  if i == MINUS_INDEX:\n",
        "    return \"-\"\n",
        "  if i == EQUALS_INDEX:\n",
        "    return \"=\"\n",
        "  if i == MULT_INDEX:\n",
        "    return \"*\"\n",
        "  if i == DIV_INDEX:\n",
        "    return \"\\\\\"\n",
        "  return \"?\"\n",
        "\n",
        "def tokens_to_string(tokens):\n",
        "    tokens = utils.to_numpy(tokens)\n",
        "    return \"\".join([token_to_char(i) for i in tokens[:cfg.n_ctx]])\n",
        "\n",
        "def string_to_tokens(string, batch: bool=False):\n",
        "    lookup = {str(i):i for i in range(10)}\n",
        "    lookup['+']=PLUS_INDEX\n",
        "    lookup['-']=MINUS_INDEX\n",
        "    lookup['=']=EQUALS_INDEX\n",
        "    lookup['*']=MULT_INDEX\n",
        "    lookup['\\\\']=DIV_INDEX\n",
        "\n",
        "    tokens = [lookup[i] for i in string if i not in '\\n ']\n",
        "    if batch:\n",
        "        return torch.tensor(tokens)[None, :]\n",
        "    else:\n",
        "        return torch.tensor(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp,\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx,\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.seed,\n",
        ")\n",
        "\n",
        "main_model = HookedTransformer(ht_cfg)\n",
        "\n",
        "optimizer = optim.AdamW(main_model.parameters(),\n",
        "                        lr = cfg.lr,\n",
        "                        weight_decay = cfg.weight_decay,\n",
        "                        betas = (0.9, 0.98))\n",
        "\n",
        "max_iter = cfg.n_training_steps\n",
        "warmup_iter = max_iter // 5\n",
        "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=int(warmup_iter))\n",
        "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(np.ceil((max_iter-warmup_iter))))\n",
        "scheduler  = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[int(warmup_iter)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Loss Function & Data Generator\n",
        "This section defines the loss function and the training/tesing data generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2iNO-nKDBW"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "# Calculate the per-token probability by comparing a batch of prediction \"logits\" to answer \"tokens\"\n",
        "def logits_to_tokens_loss(logits, tokens):\n",
        "  # Addition answer can have one extra digit than question. Answer also has a +/- sign\n",
        "  n_answer_digits = cfg.n_digits+2\n",
        "\n",
        "  # The addition answer digit token probabilities\n",
        "  ans_logits = logits[:, -(n_answer_digits+1):-1]\n",
        "\n",
        "  # Convert raw score (logits) vector into a probability distribution.\n",
        "  # Emphasize the largest scores and suppress the smaller ones, to make them more distinguishable.\n",
        "  ans_probs = F.log_softmax(ans_logits.to(torch.float64), dim=-1)\n",
        "\n",
        "  max_prob_tokens = torch.argmax(ans_probs, dim=-1)\n",
        "\n",
        "  # The addition answer digit tokens\n",
        "  ans_tokens = tokens[:, -(n_answer_digits):]\n",
        "\n",
        "  # Extract values from the ans_probs tensor, based on indices from the ans_tokens tensor\n",
        "  ans_loss = torch.gather(ans_probs, -1, ans_tokens[:, :, None])[..., 0]\n",
        "\n",
        "  return ans_loss, max_prob_tokens\n",
        "\n",
        "\n",
        "# Calculate loss as negative of average per-token mean probability\n",
        "def loss_fn(ans_loss):\n",
        "  return -ans_loss.mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSp8pS1eKHf6"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" data generator function. Invoked using next().\n",
        "# Returns a Add, Sub or Mult question batch depending on cfg.perc_mult and cfg.perc_sub\n",
        "# \"Addition\" batch entries are formated XXXXX+YYYYY=+ZZZZZZ e.g. 550030+800020=+1350050\n",
        "# \"Subtraction\" batch entries are formated XXXXX-YYYYY=-ZZZZZZ e.g. 550030-800020=-0249990, 800020-550030=+0249990\n",
        "# \"Multiplication\" batch entries are formated 000XXX*000YYY=+ZZZZZZ e.g. 000345*000678=+233910\n",
        "def data_generator( ):\n",
        "    torch.manual_seed(cfg.seed)\n",
        "    while True:\n",
        "        #generate a batch of questions (answers calculated below)\n",
        "        batch = torch.zeros((cfg.batch_size, cfg.n_ctx)).to(torch.int64)\n",
        "        x = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "        y = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "\n",
        "        batch_rand = random.randint(1, 100)\n",
        "        batch_op = MULT_INDEX if batch_rand <= cfg.perc_mult else MINUS_INDEX if batch_rand <= cfg.perc_mult + cfg.perc_sub else PLUS_INDEX\n",
        "\n",
        "        if batch_op == MULT_INDEX:\n",
        "          # Convert from NNNNNN*NNNNNN= to 000NNN*000NNN= so answer (product) is NNNNNN\n",
        "          num_zeros = cfg.n_digits // 2\n",
        "          for z in range(num_zeros):\n",
        "            x[:, z] = 0\n",
        "            y[:, z] = 0\n",
        "\n",
        "        batch[:, :cfg.n_digits] = x\n",
        "        batch[:, cfg.n_digits] = batch_op\n",
        "        batch[:, 1+cfg.n_digits:1+cfg.n_digits*2] = y\n",
        "        batch[:, 1+cfg.n_digits*2] = EQUALS_INDEX\n",
        "\n",
        "        # Convert each row into a 5-digit number\n",
        "        if cfg.n_digits == 5:\n",
        "          x_values = x[:, 0] * 10000 + x[:, 1] * 1000 + x[:, 2] * 100 + x[:, 3] * 10 + x[:, 4]\n",
        "          y_values = y[:, 0] * 10000 + y[:, 1] * 1000 + y[:, 2] * 100 + y[:, 3] * 10 + y[:, 4]\n",
        "        else:\n",
        "          if cfg.n_digits == 6:\n",
        "            x_values = x[:, 0] * 100000 + x[:, 1] * 10000 + x[:, 2] * 1000 + x[:, 3] * 100 + x[:, 4] * 10 + x[:, 5]\n",
        "            y_values = y[:, 0] * 100000 + y[:, 1] * 10000 + y[:, 2] * 1000 + y[:, 3] * 100 + y[:, 4] * 10 + y[:, 5]\n",
        "\n",
        "        # Elementwise operations giving 1D tensor\n",
        "        if batch_op == MULT_INDEX:\n",
        "          answers = x_values * y_values\n",
        "        else:\n",
        "          if batch_op == MINUS_INDEX:\n",
        "            answers = x_values - y_values\n",
        "          else:\n",
        "            answers = x_values + y_values\n",
        "\n",
        "        for i in range(cfg.batch_size):\n",
        "          answer = answers[i]\n",
        "\n",
        "          sign = PLUS_INDEX\n",
        "          if answer < 0:\n",
        "            sign = MINUS_INDEX\n",
        "            answer = - answer\n",
        "\n",
        "          batch[i, 2+cfg.n_digits*2] = sign\n",
        "          for j in range(cfg.n_digits+1):\n",
        "            batch[i, cfg.n_ctx-j-1] = answer % 10\n",
        "            answer = answer // 10\n",
        "            if answer == 0:\n",
        "                break\n",
        "\n",
        "        yield batch.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "# Initialise the data generator\n",
        "ds = data_generator()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test data generator\n",
        "tokens = next(ds)\n",
        "print(tokens[:3,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtmioT1THbJA",
        "outputId": "b3029f17-e8e6-4d18-b6fc-3952fbabf0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5,  0,  4,  4,  4,  6, 11,  6,  1,  2,  2,  4,  2, 12, 11,  0,  1,  0,\n",
            "          7,  7,  9,  6],\n",
            "        [ 5,  7,  8,  3,  3,  2, 11,  2,  1,  9,  6,  8,  2, 12, 10,  0,  3,  5,\n",
            "          8,  6,  5,  0],\n",
            "        [ 9,  9,  9,  1,  0,  4, 11,  0,  0,  1,  4,  7,  2, 12, 10,  0,  9,  9,\n",
            "          7,  6,  3,  2]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5 Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92b3416-95b1-41a2-fc24-65270f26cf4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file /content/drive/MyDrive/AI/CoLabOutput/ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HookedTransformer(\n",
              "  (embed): Embed()\n",
              "  (hook_embed): HookPoint()\n",
              "  (pos_embed): PosEmbed()\n",
              "  (hook_pos_embed): HookPoint()\n",
              "  (blocks): ModuleList(\n",
              "    (0-2): 3 x TransformerBlock(\n",
              "      (ln1): LayerNorm(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (ln2): LayerNorm(\n",
              "        (hook_scale): HookPoint()\n",
              "        (hook_normalized): HookPoint()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (hook_k): HookPoint()\n",
              "        (hook_q): HookPoint()\n",
              "        (hook_v): HookPoint()\n",
              "        (hook_z): HookPoint()\n",
              "        (hook_attn_scores): HookPoint()\n",
              "        (hook_pattern): HookPoint()\n",
              "        (hook_result): HookPoint()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (hook_pre): HookPoint()\n",
              "        (hook_post): HookPoint()\n",
              "      )\n",
              "      (hook_attn_in): HookPoint()\n",
              "      (hook_q_input): HookPoint()\n",
              "      (hook_k_input): HookPoint()\n",
              "      (hook_v_input): HookPoint()\n",
              "      (hook_mlp_in): HookPoint()\n",
              "      (hook_attn_out): HookPoint()\n",
              "      (hook_mlp_out): HookPoint()\n",
              "      (hook_resid_pre): HookPoint()\n",
              "      (hook_resid_mid): HookPoint()\n",
              "      (hook_resid_post): HookPoint()\n",
              "    )\n",
              "  )\n",
              "  (ln_final): LayerNorm(\n",
              "    (hook_scale): HookPoint()\n",
              "    (hook_normalized): HookPoint()\n",
              "  )\n",
              "  (unembed): Unembed()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "print(\"Loading model\", main_fname_full)\n",
        "\n",
        "utils.clear_huggingface_cache()\n",
        "model.load_state_dict(utils.download_file_from_hf(repo_name=\"PhilipQuirke/Accurate6DigitSubtraction\", file_name=main_fname_full, force_is_torch=True))\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxoBWHNKRf0"
      },
      "source": [
        "# Part 8: Sample Questions Set Up\n",
        "\n",
        "Create sets of sample questions to ask the model to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj_xSuSSKR9t"
      },
      "outputs": [],
      "source": [
        "# Insert a number into the question\n",
        "def insert_question_number(the_question, index, first_digit_index, the_digits, n):\n",
        "\n",
        "  last_digit_index = first_digit_index + the_digits - 1\n",
        "\n",
        "  for j in range(the_digits):\n",
        "    the_question[index, last_digit_index-j] = n % 10\n",
        "    n = n // 10\n",
        "\n",
        "\n",
        "# Create a single question\n",
        "def make_a_question(the_question, index, q1, q2, operator ):\n",
        "\n",
        "  insert_question_number(the_question, index, 0, cfg.n_digits, q1)\n",
        "\n",
        "  the_question[index, cfg.n_digits] = operator\n",
        "\n",
        "  insert_question_number( the_question, index, cfg.n_digits+1, cfg.n_digits, q2)\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+1] = EQUALS_INDEX\n",
        "\n",
        "  answer = q1+q2\n",
        "  if operator == MINUS_INDEX:\n",
        "    answer = q1-q2\n",
        "  else:\n",
        "    if operator == MULT_INDEX:\n",
        "      answer = q1*q2\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+2] = PLUS_INDEX if answer >= 0 else MINUS_INDEX\n",
        "  if answer < 0:\n",
        "    answer = -answer\n",
        "\n",
        "  insert_question_number(the_question, index, 2*cfg.n_digits + 3, cfg.n_digits+1, answer)\n",
        "\n",
        "\n",
        "# Create a batch of questions from a 2D matrix of ints\n",
        "def make_questions(q_matrix, operator):\n",
        "  length = len(q_matrix)\n",
        "\n",
        "  questions = torch.zeros((length, cfg.n_ctx)).to(torch.int64)\n",
        "\n",
        "  limit = 10 ** cfg.n_digits\n",
        "  for i in range(length):\n",
        "    if (q_matrix[i][0] < limit) and (q_matrix[i][1] < limit) :\n",
        "      make_a_question(questions, i, q_matrix[i][0], q_matrix[i][1], operator)\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xiOHRfGKW-W"
      },
      "outputs": [],
      "source": [
        "# Analyse the question and return the use case as Addition (BA, MC, SimpleUS9 or CascadeUS9) or Subtraction (BS, B1, C1, CN)\n",
        "def get_question_case(q):\n",
        "  qa = utils.to_numpy(q)\n",
        "  qn = qa[:2*cfg.n_digits+2]\n",
        "\n",
        "  operator = qa[cfg.n_digits]\n",
        "\n",
        "  if operator == PLUS_INDEX:\n",
        "\n",
        "    # Locate the MC and MS digits (if any)\n",
        "    mc = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    ms = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if qn[dn] + qn[dn + cfg.n_digits + 1] == 9:\n",
        "        ms[cfg.n_digits-1-dn] = 1\n",
        "      if qn[dn] + qn[dn + cfg.n_digits +1] > 9:\n",
        "        mc[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "    # Calculate the use case of a question\n",
        "    if torch.sum(mc) == 0:\n",
        "      return \"BA\"\n",
        "\n",
        "    if torch.sum(ms) == 0:\n",
        "      return \"MC1\"\n",
        "\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-2 and mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1:\n",
        "        return \"CUS\" # Cascade US 9\n",
        "\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-1 and mc[dn] == 1 and ms[dn+1] == 1:\n",
        "        return \"SUS\" # Simple US 9\n",
        "\n",
        "    return \"MC1\"\n",
        "\n",
        "\n",
        "  if operator == MINUS_INDEX:\n",
        "    a = tokens_to_signed_int(qn, 0, cfg.n_digits)\n",
        "    b = tokens_to_signed_int(qn, cfg.n_digits + 1, cfg.n_digits)\n",
        "    if a < b:\n",
        "      return \"NEG\"\n",
        "    return \"POS\"\n",
        "\n",
        "    #temp PQR\n",
        "\n",
        "\n",
        "  if operator == MULT_INDEX:\n",
        "    return \"MUL\"\n",
        "\n",
        "\n",
        "  return \"OP?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCPyETTKaEs"
      },
      "outputs": [],
      "source": [
        "# Manually create some questions that strongly test one use case\n",
        "\n",
        "\n",
        "# Make BaseAdd questions\n",
        "def make_add_ba_questions():\n",
        "    return make_questions(\n",
        "      [[12345, 33333],\n",
        "      [33333, 12345],\n",
        "      [45762, 33113],\n",
        "      [888, 11111],\n",
        "      [2362, 23123],\n",
        "      [15, 81],\n",
        "      [1000, 4440],\n",
        "      [4440, 1000],\n",
        "      [24033, 25133],\n",
        "      [23533, 21133],\n",
        "      [32500, 1],\n",
        "      [31500, 1111],\n",
        "      [5500, 12323],\n",
        "      [4500, 2209],\n",
        "      [ 33345, 66643], # =099988\n",
        "      [ 66643, 33345], # =099988\n",
        "      [10990, 44000],\n",
        "      [60000, 30000],\n",
        "      [10000, 20000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make UseCarry1 (addition) questions\n",
        "def make_add_uc1_questions():\n",
        "    return make_questions(\n",
        "      [[ 15, 45],\n",
        "      [ 25, 55],\n",
        "      [ 35, 59],\n",
        "      [ 40035, 40049],\n",
        "      [ 5025, 5059],\n",
        "      [ 15, 65],\n",
        "      [ 44000, 46000],\n",
        "      [ 70000, 40000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 85000],\n",
        "      [ 67000, 85000],\n",
        "      [ 99000, 76000],\n",
        "      [ 1500, 4500],\n",
        "      [ 2500, 5500],\n",
        "      [ 3500, 5900],\n",
        "      [ 15020, 45091],\n",
        "      [ 25002, 55019],\n",
        "      [ 35002, 59019]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make SimpleUseSum9 (addition) questions\n",
        "def make_add_simple_us9_questions():\n",
        "    return make_questions(\n",
        "      [[ 55, 45],\n",
        "      [ 45, 55],\n",
        "      [ 45, 59],\n",
        "      [ 35, 69],\n",
        "      [ 25, 79],\n",
        "      [ 15, 85],\n",
        "      [ 15, 88],\n",
        "      [ 15508, 14500],\n",
        "      [ 14508, 15500],\n",
        "      [ 24533, 25933],\n",
        "      [ 23533, 26933],\n",
        "      [ 32500, 7900],\n",
        "      [ 31500, 8500],\n",
        "      [ 550, 450],\n",
        "      [ 450, 550],\n",
        "      [ 10880, 41127],\n",
        "      [ 41127, 10880],\n",
        "      [ 12386, 82623]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make CascadeUseSum9 (addition) questions\n",
        "def make_add_cascade_us9_questions():\n",
        "    return make_questions(\n",
        "      # These are two level UseSum9 cascades\n",
        "      [[ 555, 445],\n",
        "      [ 3340, 6660],\n",
        "      [ 8880, 1120],\n",
        "      [ 1120, 8880],\n",
        "      [ 123, 877],\n",
        "      [ 877, 123],\n",
        "      [ 321, 679],\n",
        "      [ 679, 321],\n",
        "      [ 1283, 88786],\n",
        "      # These are three level UseSum9 cascades\n",
        "      [ 5555, 4445],\n",
        "      [ 55550, 44450],\n",
        "      [ 334, 666],\n",
        "      [ 3340, 6660],\n",
        "      [ 33400, 66600],\n",
        "      [ 888, 112],\n",
        "      [ 8880, 1120],\n",
        "      [ 88800, 11200],\n",
        "      [ 1234, 8766],\n",
        "      [ 4321, 5679],\n",
        "      # These are four level UseSum9 cascades\n",
        "      [ 44445, 55555],\n",
        "      [ 33334, 66666],\n",
        "      [ 88888, 11112],\n",
        "      [ 12345, 87655],\n",
        "      [ 54321, 45679],\n",
        "      [ 45545, 54455],\n",
        "      [ 36634, 63366],\n",
        "      [ 81818, 18182],\n",
        "      [ 87345, 12655],\n",
        "      [ 55379, 44621]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make questions focus mainly on 1 digit at a time\n",
        "# (assuming that the 0 + 0 digit additions/subtractions are trivial bigrams)\n",
        "def make_add_answerdigit_questions():\n",
        "    return make_questions(\n",
        "      [[ 1, 0],\n",
        "      [ 4, 3],\n",
        "      [ 5, 5],\n",
        "      [ 8, 1],\n",
        "      [ 40, 30],\n",
        "      [ 44, 46],\n",
        "      [ 400, 300],\n",
        "      [ 440, 460],\n",
        "      [ 800, 100],\n",
        "      [ 270, 470],\n",
        "      [ 600, 300],\n",
        "      [ 4000, 3000],\n",
        "      [ 4400, 4600],\n",
        "      [ 6000, 3000],\n",
        "      [ 7000, 4000],\n",
        "      [ 40000, 30000],\n",
        "      [ 44000, 46000],\n",
        "      [ 60000, 30000],\n",
        "      [ 70000, 40000],\n",
        "      [ 10000, 20000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 85000],\n",
        "      [ 67000, 85000],\n",
        "      [ 99000, 76000],\n",
        "      [ 76000, 99000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make BaseSub questions - when no column generates a Borrow One\n",
        "def make_sub_bs_questions():\n",
        "    return make_questions(\n",
        "      [[66666, 12345],\n",
        "      [33333, 12321],\n",
        "      [45762, 34551],\n",
        "      [78901, 78901], # = +000000\n",
        "      [23123, 23123], # = +000000\n",
        "      [86, 15],\n",
        "      [4440, 1230],\n",
        "      [88746, 86544],\n",
        "      [27833, 25133],\n",
        "      [23533, 21133],\n",
        "      [32501, 1],\n",
        "      [31511, 1111],\n",
        "      [55555, 12323],\n",
        "      [45454, 22022],\n",
        "      [66643, 3341],\n",
        "      [66643, 30042],\n",
        "      [99999, 44012],\n",
        "      [60000, 30000],\n",
        "      [99000, 99000]], # = +000000\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction \"borrow 1\" questions with exactly one \"borrow 1\" instance\n",
        "def make_sub_b1_questions():\n",
        "    return make_questions(\n",
        "      [[22222, 11113],\n",
        "      [ 22222, 11131],\n",
        "      [ 22222, 11311],\n",
        "      [ 22222, 13111],\n",
        "      [    14,     8],\n",
        "      [   140,    80],\n",
        "      [  1400,   800],\n",
        "      [ 14000,  8000],\n",
        "      [ 55514, 11108],\n",
        "      [ 55140, 11080],\n",
        "      [ 51400, 10800],\n",
        "      [ 14000,  8000],\n",
        "      [ 88888, 22229],\n",
        "      [ 88888, 22292],\n",
        "      [ 88888, 22922],\n",
        "      [ 88888, 29222]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction \"cascade 1\" questions\n",
        "def make_sub_c1_questions():\n",
        "    return make_questions(\n",
        "      [[22212, 11113],\n",
        "      [ 22122, 11131],\n",
        "      [ 21222, 11311],\n",
        "      [   904,     8],\n",
        "      [  9040,    80],\n",
        "      [ 90400,   800],\n",
        "      [ 55514, 11118],\n",
        "      [ 55140, 11180],\n",
        "      [ 51400, 11800],\n",
        "      [ 88888, 22289],\n",
        "      [ 88888, 22892],\n",
        "      [ 88888, 28922]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction \"cascade multiple steps\" questions\n",
        "def make_sub_cn_questions():\n",
        "    return make_questions(\n",
        "      [[21112, 11113],\n",
        "      [ 21122, 11131],\n",
        "      [ 99004,     8],\n",
        "      [ 90040,    80],\n",
        "      [ 55114, 11118],\n",
        "      [ 51140, 11180],\n",
        "      [ 88888, 22889],\n",
        "      [ 88888, 28892]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction questions with negative answers\n",
        "def make_sub_neg_questions():\n",
        "    return make_questions(\n",
        "      [[ 0, 1],\n",
        "      [ 88888, 88889],\n",
        "      [ 55555, 55556],\n",
        "      [ 88881, 88891],\n",
        "      [ 55551, 55561],\n",
        "      [ 88811, 88911],\n",
        "      [ 55511, 55611],\n",
        "      [ 8, 12],\n",
        "      [ 40, 232],\n",
        "      [ 44, 523],\n",
        "      [ 234, 334],\n",
        "      [ 7777, 13434],\n",
        "      [ 88888, 92222]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "\n",
        "# Returns random and manually-chosen questions\n",
        "def make_varied_questions():\n",
        "  g0 = next(ds) # Could be Add, Sub or Mult\n",
        "  g1 = next(ds) # Could be Add, Sub or Mult\n",
        "\n",
        "  if cfg.perc_mult == 100 :\n",
        "    return torch.vstack((g0.cuda(), g1.cuda()))\n",
        "\n",
        "  p0 = make_add_ba_questions()\n",
        "  p1 = make_add_uc1_questions()\n",
        "  p2 = make_add_simple_us9_questions()\n",
        "  p3 = make_add_cascade_us9_questions()\n",
        "  p4 = make_add_answerdigit_questions()\n",
        "\n",
        "  s0 = make_sub_bs_questions()\n",
        "  s1 = make_sub_b1_questions()\n",
        "  s2 = make_sub_c1_questions()\n",
        "  s3 = make_sub_cn_questions()\n",
        "  s4 = make_sub_neg_questions()\n",
        "\n",
        "  if cfg.perc_sub == 0 :\n",
        "    return torch.vstack((g0.cuda(), p0.cuda(), p1.cuda(), p2.cuda(), p3.cuda(), p4.cuda(), g1.cuda()))\n",
        "\n",
        "  if cfg.perc_sub == 100 :\n",
        "    return torch.vstack((g0.cuda(), s0.cuda(), s1.cuda(), s2.cuda(), s3.cuda(), s4.cuda(), g1.cuda()))\n",
        "\n",
        "  return torch.vstack((g0.cuda(), p0.cuda(), s0.cuda(), p1.cuda(), s1.cuda(), p2.cuda(), s2.cuda(), p3.cuda(), s3.cuda(), p4.cuda(), s4.cuda(), g1.cuda()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RHrsjKqKhR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ed1af4-dffe-4ae1-bbd5-cf5f066769f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ActivationCache with keys ['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.attn.hook_result', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.attn.hook_result', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.attn.hook_result', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized']\n",
            "Sample Mean Loss 2.641695170449223e-06\n",
            "Sample blocks.0.attn.hook_z torch.Size([196, 22, 4, 170])\n",
            "Mean blocks.0.attn.hook_z torch.Size([1, 22, 4, 170])\n",
            "Sample blocks.0.hook_resid_post torch.Size([196, 22, 510])\n",
            "Mean blocks.0.hook_resid_post torch.Size([1, 22, 510])\n",
            "Sample blocks.0.mlp.hook_post torch.Size([196, 22, 2040])\n",
            "Mean blocks.0.mlp.hook_post torch.Size([1, 22, 2040])\n"
          ]
        }
      ],
      "source": [
        "# Build a test batch of random and manually-chosen questions\n",
        "varied_questions = make_varied_questions();\n",
        "\n",
        "\n",
        "# Run the sample batch, gather the cache\n",
        "main_model.reset_hooks()\n",
        "main_model.set_use_attn_result(True)\n",
        "sample_logits, sample_cache = main_model.run_with_cache(varied_questions.cuda())\n",
        "print(sample_cache) # Gives names of datasets in the cache\n",
        "sample_losses_raw, sample_max_prob_tokens = logits_to_tokens_loss(sample_logits, varied_questions.cuda())\n",
        "sample_loss_mean = utils.to_numpy(loss_fn(sample_losses_raw).mean())\n",
        "print(\"Sample Mean Loss\", sample_loss_mean) # Loss < 0.04 is good\n",
        "\n",
        "\n",
        "# attn.hook_z is the \"attention head output\" hook point name (at a specified layer)\n",
        "l_attn_hook_z_name = [utils.get_act_name('z', 0, 'a'),utils.get_act_name('z', 1, 'a'),utils.get_act_name('z', 2, 'a')] # 'blocks.0.attn.hook_z' etc\n",
        "sample_attn_z = sample_cache[l_attn_hook_z_name[0]]\n",
        "print(\"Sample\", l_attn_hook_z_name[0], sample_attn_z.shape) # gives [350, 22, 3, 170] = num_questions, cfg.n_ctx, n_heads, d_head\n",
        "mean_attn_z = torch.mean(sample_attn_z, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_attn_hook_z_name[0], mean_attn_z.shape) # gives [1, 22, 3, 170] = 1, cfg.n_ctx, n_heads, d_head\n",
        "\n",
        "\n",
        "# hook_resid_pre is the \"pre residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_pre_name = ['blocks.0.hook_resid_pre','blocks.1.hook_resid_pre','blocks.2.hook_resid_pre']\n",
        "\n",
        "\n",
        "# hook_resid_post is the \"post residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_post_name = ['blocks.0.hook_resid_post','blocks.1.hook_resid_post','blocks.2.hook_resid_post']\n",
        "sample_resid_post = sample_cache[l_hook_resid_post_name[0]]\n",
        "print(\"Sample\", l_hook_resid_post_name[0], sample_resid_post.shape) # gives [350, 22, 510] = num_questions, cfg.n_ctx, d_model\n",
        "mean_resid_post = torch.mean(sample_resid_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_hook_resid_post_name[0], mean_resid_post.shape) # gives [1, 22, 510] = 1, cfg.n_ctx, d_model\n",
        "\n",
        "\n",
        "# mlp.hook_post is the \"MLP layer\" hook point name (at a specified layer)\n",
        "l_mlp_hook_post_name = [utils.get_act_name('post', 0),utils.get_act_name('post', 1),utils.get_act_name('post', 2)] # 'blocks.0.mlp.hook_post' etc\n",
        "sample_mlp_hook_post = sample_cache[l_mlp_hook_post_name[0]]\n",
        "print(\"Sample\", l_mlp_hook_post_name[0], sample_mlp_hook_post.shape) # gives [350, 22, 2040] = num_questions, cfg.n_ctx, d_model*4\n",
        "mean_mlp_hook_post = torch.mean(sample_mlp_hook_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_mlp_hook_post_name[0], mean_mlp_hook_post.shape) # gives [1, 22, 2040] = 1, cfg.n_ctx, d_model*4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_unsigned_int( q, offset, digits ):\n",
        "  a = 0\n",
        "  for j in range(digits):\n",
        "    a = a * 10 + q[offset+j]\n",
        "  return a\n",
        "\n",
        "\n",
        "def tokens_to_signed_int( q, offset, digits ):\n",
        "  a = tokens_to_unsigned_int( q, offset+1, digits )\n",
        "  if q[offset] == MINUS_INDEX:\n",
        "    a = - a\n",
        "  return a"
      ],
      "metadata": {
        "id": "GHQpt2iOqffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = True\n",
        "\n",
        "class T_Config():\n",
        "  num_questions : int\n",
        "  correct_answers : int\n",
        "  total_mean_loss : float\n",
        "\n",
        "  sum_num_questions : int\n",
        "  sum_correct_answers : int\n",
        "\n",
        "  output = PrettyTable()\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0.0\n",
        "    self.sum_num_questions = 0\n",
        "    self.sum_correct_answers = 0\n",
        "\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Case\", \"#Questions\", \"#Correct\", \"%Correct\", \"Mean loss\"]\n",
        "\n",
        "\n",
        "  # Clear the question summary results\n",
        "  def clear_questions_results(self, title):\n",
        "    global verbose\n",
        "\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0\n",
        "\n",
        "    if verbose:\n",
        "      print(title)\n",
        "\n",
        "\n",
        "  # Print the question summary results\n",
        "  def print_questions_results(self, prefix):\n",
        "    self.output.add_row([prefix, self.num_questions, str(self.correct_answers), 100*self.correct_answers/self.num_questions, self.total_mean_loss/self.num_questions])\n",
        "    self.sum_num_questions += self.num_questions\n",
        "    self.sum_correct_answers += self.correct_answers\n",
        "\n",
        "\n",
        "  # Print the overall summary results\n",
        "  def print_overall_results(self):\n",
        "    print_config()\n",
        "    print()\n",
        "\n",
        "    self.output.add_row([\"OVERALL\", self.sum_num_questions, self.sum_correct_answers, \"\", \"\"])\n",
        "    print(self.output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "\n",
        "tcfg = T_Config()\n",
        "tcfg.reset()"
      ],
      "metadata": {
        "id": "IjhfLpSW9Jsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "# Ask model to predict answer for each question & collect results\n",
        "def do_questions(questions):\n",
        "  global verbose\n",
        "  global tcfg\n",
        "\n",
        "  tcfg.num_questions = questions.shape[0]\n",
        "\n",
        "  # Run with no hook\n",
        "  all_logits = main_model(questions.cuda())\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  for question_num in range(tcfg.num_questions):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    losses = loss_fn(all_losses_raw[question_num])\n",
        "    mean_loss = utils.to_numpy(losses.mean())\n",
        "    tcfg.total_mean_loss += mean_loss\n",
        "\n",
        "    model_answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "    model_answer_num = int(model_answer_str)\n",
        "\n",
        "    # 5 digit addition yields a 6 digit answer. Hence cfg.n_digits+1\n",
        "    a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "\n",
        "    correct = (model_answer_num == a)\n",
        "    if correct :\n",
        "      tcfg.correct_answers += 1\n",
        "\n",
        "    if verbose:\n",
        "      print(tokens_to_string(q), \"ModelAnswer:\", model_answer_str, \"Correct:\", correct, \"Loss:\", mean_loss )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lag8C3d_KkeQ"
      },
      "source": [
        "# Part 9: Prediction Analysis By Use Case\n",
        "This section sets up addition (BA, UC1 and US9) and subtraction (BS, B1, C1, CN) test cases that will be re-used in later experiments to show the impact of ablating heads or token positions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6RdolRKnnR"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_add() > 0:\n",
        "  print( \"ADDITION:\")\n",
        "\n",
        "  tcfg.reset()\n",
        "\n",
        "  tcfg.clear_questions_results(\"BaseAdd cases\")\n",
        "  do_questions(make_add_ba_questions())\n",
        "  tcfg.print_questions_results(\"BaseAdd\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"These are Use Carry 1 (UC1) examples (not UseSum9 examples)\")\n",
        "  do_questions(make_add_uc1_questions())\n",
        "  tcfg.print_questions_results(\"UseCarry1\")\n",
        "\n",
        "\n",
        "  tcfg.clear_questions_results(\"These are simple (one level) UseSum9 examples\")\n",
        "  do_questions(make_add_simple_us9_questions())\n",
        "  tcfg.print_questions_results(\"SimpleUS9\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"These are UseSum9 two, three and four level cascades\")\n",
        "  do_questions(make_add_cascade_us9_questions())\n",
        "  tcfg.print_questions_results(\"CascadeUS9\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"These questions focus on different answer digits\")\n",
        "  do_questions(make_add_answerdigit_questions(PLUS_INDEX))\n",
        "  tcfg.print_questions_results(\"AnswerDigits\")\n",
        "\n",
        "  tcfg.print_overall_results()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_sub > 0:\n",
        "  print( \"SUBTRACTION:\")\n",
        "\n",
        "  tcfg.reset()\n",
        "\n",
        "  tcfg.clear_questions_results(\"BaseSub cases\")\n",
        "  do_questions(make_sub_bs_questions())\n",
        "  tcfg.print_questions_results(\"Sub BS\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"Sub Borrow 1 cases\")\n",
        "  do_questions(make_sub_b1_questions())\n",
        "  tcfg.print_questions_results(\"Sub B1\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"Sub Cascade 1 cases\")\n",
        "  do_questions(make_sub_c1_questions())\n",
        "  tcfg.print_questions_results(\"Sub C1\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"Sub Cascade N cases\")\n",
        "  do_questions(make_sub_cn_questions())\n",
        "  tcfg.print_questions_results(\"Sub CN\")\n",
        "\n",
        "  tcfg.clear_questions_results(\"SubNeg cases\")\n",
        "  do_questions(make_sub_neg_questions())\n",
        "  tcfg.print_questions_results(\"SubNeg\")\n",
        "\n",
        "  tcfg.print_overall_results()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW2SNwxJ-3Kn",
        "outputId": "d233d9a4-cd34-47e2-8481-a39bc1fb4215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUBTRACTION:\n",
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "+---------+------------+----------+----------+------------------------+\n",
            "|   Case  | #Questions | #Correct | %Correct |       Mean loss        |\n",
            "+---------+------------+----------+----------+------------------------+\n",
            "|  Sub BS |     19     |    19    |  100.0   | 5.494446282837866e-06  |\n",
            "|  Sub B1 |     16     |    16    |  100.0   | 8.084363835950773e-08  |\n",
            "|  Sub C1 |     12     |    12    |  100.0   | 2.5461243104058557e-08 |\n",
            "|  Sub CN |     8      |    8     |  100.0   | 3.909303230483572e-08  |\n",
            "|  SubNeg |     13     |    13    |  100.0   | 3.153648964286771e-05  |\n",
            "| OVERALL |     68     |    68    |          |                        |\n",
            "+---------+------------+----------+----------+------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyK7QeUjLLFm"
      },
      "source": [
        "# Part 11: Set Up \"Count\" Framework\n",
        "\n",
        "Create way to get model to predict sample question answers and analysis/show results. Use prefix \"c_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYPI4tw0LNhV"
      },
      "outputs": [],
      "source": [
        "# Build up a list of success/failure by case (BA, MC1, US9) found, and the frequency of each case\n",
        "c_case_counts = {}\n",
        "\n",
        "\n",
        "def count_question_cases(questions):\n",
        "  global c_case_counts\n",
        "\n",
        "  c_case_counts = {}\n",
        "\n",
        "  for i in range(questions.shape[0]):\n",
        "    q_case = get_question_case(questions[i])\n",
        "\n",
        "    if q_case in c_case_counts:\n",
        "      # If the key is already in the dictionary, increment its count\n",
        "      c_case_counts[q_case] += 1\n",
        "    else:\n",
        "      # If the key is not in the dictionary, add it with a count of 1\n",
        "      c_case_counts[q_case] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXEfGBMLPFW"
      },
      "outputs": [],
      "source": [
        "# Compare each digit in the answer. Returns a A+45 pattern where '+' means a failed sign and '4' means a failed 4th digit\n",
        "def get_digit_accuracy_impact(a_int, answer_str):\n",
        "  a_str = str(a_int.cpu().numpy()).zfill(cfg.n_digits+1)\n",
        "  match_str = \"A\"\n",
        "  for i in range(cfg.n_digits+1):\n",
        "    match_str += \"\" if answer_str[i] == a_str[i] else str(cfg.n_digits-i)\n",
        "\n",
        "    #pqr handle+/-mismatch\n",
        "\n",
        "  return \"\" if match_str == \"A\" else match_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liT_UbPOLRhO"
      },
      "outputs": [],
      "source": [
        "# Build up a list of success/failure digit-patterns found, and the frequency of each pattern\n",
        "c_pattern_fails = {}\n",
        "\n",
        "\n",
        "def clear_pattern_fails():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  c_pattern_fails = {}\n",
        "\n",
        "\n",
        "def add_pattern_fail(match_str):\n",
        "  global c_pattern_fails\n",
        "\n",
        "  if match_str in c_pattern_fails:\n",
        "    # If the key is already in the dictionary, increment its count\n",
        "    c_pattern_fails[match_str] += 1\n",
        "  else:\n",
        "    # If the key is not in the dictionary, add it with a count of 1\n",
        "    c_pattern_fails[match_str] = 1\n",
        "\n",
        "\n",
        "def get_pattern_fails():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  results = \"\"\n",
        "  top_result = \"\"\n",
        "  if len(c_pattern_fails) > 0 :\n",
        "    sorted_fails = dict(sorted(c_pattern_fails.items(), key=lambda item: item[1], reverse=True))\n",
        "    for key, value in sorted_fails.items():\n",
        "      this_cell = key + \"=\" + str(value)\n",
        "\n",
        "      results = results + this_cell + \" \"\n",
        "\n",
        "      if top_result == \"\":\n",
        "        top_result = this_cell\n",
        "      else:\n",
        "        top_result = top_result + \", \" + this_cell\n",
        "\n",
        "  return results, top_result\n",
        "\n",
        "\n",
        "def get_pattern_fails_total():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  if len(c_pattern_fails) == 0:\n",
        "    return 0\n",
        "\n",
        "  total_sum = 0\n",
        "  for key, value in c_pattern_fails.items():\n",
        "      if isinstance(value, int):\n",
        "          total_sum += value\n",
        "  return total_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TudM4_8PLTh1"
      },
      "outputs": [],
      "source": [
        "# Build up a count of failure cases\n",
        "c_case_fails = {}\n",
        "\n",
        "\n",
        "def clear_case_fails():\n",
        "  global c_case_fails\n",
        "\n",
        "  c_case_fails = {}\n",
        "\n",
        "\n",
        "def add_case_fail(case_key):\n",
        "  global c_case_fails\n",
        "\n",
        "  if case_key in c_case_fails:\n",
        "    # If the key is already in the dictionary, increment its count\n",
        "    c_case_fails[case_key] += 1\n",
        "  else:\n",
        "    # If the key is not in the dictionary, add it with a count of 1\n",
        "    c_case_fails[case_key] = 1\n",
        "\n",
        "\n",
        "def total_case_fails():\n",
        "  global c_case_fails\n",
        "\n",
        "  answer = 0\n",
        "  for _, value in c_case_fails.items():\n",
        "    answer = answer + value\n",
        "  return answer\n",
        "\n",
        "\n",
        "def get_case_fails():\n",
        "  global c_case_fails\n",
        "  global c_case_counts\n",
        "\n",
        "  results = \"\"\n",
        "  num_results = len(c_case_fails)\n",
        "  if num_results > 0:\n",
        "    sorted_fails = dict(sorted(c_case_fails.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    for key, value in sorted_fails.items():\n",
        "      percent = round(100 * value / c_case_counts[key])\n",
        "      results = results + \"%\" + key + \"=\" + str(percent)+ \" \"\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqmNRgCgLWV1"
      },
      "outputs": [],
      "source": [
        "def predict_experiment_question(questions, the_hook, the_threshold):\n",
        "\n",
        "  c_loss_mean = 0\n",
        "\n",
        "  clear_case_fails()\n",
        "  clear_pattern_fails()\n",
        "  count_question_cases(questions)\n",
        "\n",
        "  main_model.reset_hooks()\n",
        "  main_model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = main_model.run_with_hooks(questions.cuda(), return_type=\"logits\", fwd_hooks=the_hook)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  answer_str = \"\"\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    c_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if c_loss_mean > the_threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      # 5 digit addition yields a 6 digit answer. Hence cfg.n_digits+1\n",
        "      a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "\n",
        "      match_str = get_digit_accuracy_impact( a, answer_str )\n",
        "      # Only count the question if the model got the question wrong\n",
        "      if 'A' in match_str:\n",
        "        the_case = get_question_case(q)\n",
        "        add_case_fail(the_case)\n",
        "        add_pattern_fail(match_str)\n",
        "        if verbose:\n",
        "          print(tokens_to_string(q), \"ModelAnswer:\", answer_str, \"Matches:\", match_str, \"Loss:\", c_loss_mean, \"Case:\", the_case )\n",
        "\n",
        "  return c_loss_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 12: Ablate ALL Heads in EACH token position. What is the impact on Loss?\n",
        "\n",
        "Here we ablate all heads in each token position (overriding the model memory aka residual stream) and see if loss increases. If loss increases the token position is used by the algorithm. Unused token positions can be excluded from further analysis. Use \"C_\" prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7LwECBLajQ"
      },
      "outputs": [],
      "source": [
        "class C_Config():\n",
        "  position : int = 0  # zero-based token position to ablate\n",
        "  threshold : float = 0.01\n",
        "  questions = varied_questions\n",
        "  output = PrettyTable()\n",
        "  perc_list = []\n",
        "  hook_calls : int = 0\n",
        "\n",
        "  min_useful_position : int = -1 # Minimum useful position where loss increases on ablation\n",
        "  max_useful_position : int = -1 # Maximum useful position where loss increases on ablation\n",
        "\n",
        "\n",
        "ccfg = C_Config()\n",
        "ccfg.output.field_names = [\"Position\", \"Fails\", \"% Fails by Case\", \"# Fails by Patterns\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "\n",
        "def c_set_resid_post_hook(value, hook):\n",
        "  global ccfg\n",
        "\n",
        "  #print( \"In hook\", l_hook_resid_post_name[ccfg.layer], ccfg.ablate, ccfg.position, value.shape) # Get [64, 22, 510] = cfg.batch_size, num_tokens, d_model\n",
        "\n",
        "  # Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,ccfg.position,:] = mean_resid_post[0,ccfg.position,:].clone()\n",
        "\n",
        "\n",
        "num_questions = 0\n",
        "if cfg.n_digits >= 5 :\n",
        "  c_fwd_hooks = [(l_hook_resid_post_name[0], c_set_resid_post_hook)] if cfg.n_layers == 1 else [(l_hook_resid_post_name[0], c_set_resid_post_hook),(l_hook_resid_post_name[1], c_set_resid_post_hook)]\n",
        "\n",
        "  num_questions = ccfg.questions.shape[0]\n",
        "\n",
        "  for ccfg.position in range(cfg.n_ctx):\n",
        "    loss_mean = predict_experiment_question(ccfg.questions, c_fwd_hooks, ccfg.threshold)\n",
        "\n",
        "    num_fails = total_case_fails()\n",
        "    perc_fails = 0\n",
        "    if num_fails > 0:\n",
        "      perc_fails = round(100 * num_fails / num_questions)\n",
        "\n",
        "      if ccfg.min_useful_position == -1:\n",
        "        ccfg.min_useful_position = ccfg.position\n",
        "      ccfg.max_useful_position = ccfg.position\n",
        "\n",
        "    ccfg.perc_list = ccfg.perc_list + [perc_fails]\n",
        "\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "    ccfg.output.add_row([str(ccfg.position), str(perc_fails)+\"%\", get_case_fails(), pattern_results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "outputId": "92940245-c7c2-4770-a332-c3f9c07db8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "num_questions= 196 min_useful_position= 0 max_useful_position= 20\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Position | Fails | % Fails by Case  |                                                                                                                                                                                                            # Fails by Patterns                                                                                                                                                                                                            |\n",
            "+----------+-------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|    0     |  23%  | %NEG=40 %POS=12  |                                                                                                                                                    A6543210=14 A643210=7 A60=4 A621=3 A653210=3 A64210=2 A64310=2 A610=2 A6210=2 A63210=2 A654210=1 A630=1 A640=1 A654321=1 A654320=1                                                                                                                                                     |\n",
            "|    1     |  13%  | %POS=16 %NEG=10  |                                                                                                                                                     A543210=7 A53210=2 A54320=2 A4320=2 A6543210=2 A5320=1 A43210=1 A64=1 A6=1 A60=1 A0=1 A643210=1 A54321=1 A65210=1 A5410=1 A4310=1                                                                                                                                                     |\n",
            "|    2     |  10%  | %POS=12 %NEG=6   |                                                                                                                                                                A543210=5 A4320=2 A6543210=2 A5320=1 A43210=1 A64=1 A60=1 A0=1 A63210=1 A54321=1 A654210=1 A54320=1 A5410=1                                                                                                                                                                |\n",
            "|    3     |   8%  | %NEG=10 %POS=6   |                                                                                                                                                                A643210=3 A654310=1 A53210=1 A420=1 A543210=1 A643=1 A6=1 A632=1 A0=1 A54321=1 A6543210=1 A64320=1 A54310=1                                                                                                                                                                |\n",
            "|    4     |   6%  |  %POS=6 %NEG=5   |                                                                                                                                                                    A654310=1 A53210=1 A654321=1 A420=1 A543210=1 A6543210=1 A64=1 A54321=1 A643210=1 A64320=1 A54310=1                                                                                                                                                                    |\n",
            "|    5     |   7%  |  %POS=7 %NEG=6   |                                                                                                                                                                A543210=2 A654310=1 A53210=1 A654321=1 A420=1 A6543210=1 A64=1 A632=1 A54321=1 A643210=1 A64320=1 A54310=1                                                                                                                                                                 |\n",
            "|    6     |  24%  | %POS=24 %NEG=25  |                                                                                                                        A543210=10 A643210=6 A6543210=6 A64210=3 A654321=2 A64310=2 A654320=2 A63210=2 A2=2 A4310=1 A65432=1 A54310=1 A53210=1 A642=1 A640=1 A6421=1 A620=1 A6321=1 A43210=1 A10=1 A210=1 A54320=1                                                                                                                         |\n",
            "|    7     |  37%  | %NEG=48 %POS=30  |                                                                                             A6543210=16 A543210=15 A643210=4 A4310=3 A54310=3 A210=3 A54320=2 A64210=2 A64320=2 A0=2 A1=2 A654321=2 A4321=1 A654310=1 A521=1 A43210=1 A6421=1 A6410=1 A64310=1 A630=1 A6430=1 A3210=1 A3=1 A640=1 A4320=1 A53210=1 A653210=1 A642=1 A654320=1                                                                                             |\n",
            "|    8     |   0%  |                  |                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|    9     |  33%  | %POS=30 %NEG=37  |                                                                                           A543210=13 A6543210=10 A643210=6 A64320=4 A654321=3 A53210=3 A54321=3 A621=2 A654320=1 A54320=1 A6421=1 A6432=1 A63210=1 A64321=1 A6410=1 A6321=1 A6310=1 A641=1 A632=1 A6320=1 A6430=1 A64210=1 A654210=1 A653210=1 A43210=1 A41=1 A54210=1 A65430=1                                                                                           |\n",
            "|    10    |   9%  | %POS=8 %NEG=10   |                                                                                                                                                                       A63210=3 A543210=2 A6321=2 A0=2 A654321=1 A53210=1 A6=1 A60=1 A610=1 A621=1 A654210=1 A5431=1                                                                                                                                                                       |\n",
            "|    11    |  19%  | %POS=18 %NEG=21  |                                                                                                                                    A6543210=7 A543210=6 A643210=4 A621=3 A654321=2 A53210=2 A64321=2 A654320=1 A43210=1 A54320=1 A6321=1 A6421=1 A64210=1 A6431=1 A6420=1 A20=1 A210=1 A6210=1 A5431=1                                                                                                                                    |\n",
            "|    12    |  24%  | %POS=25 %NEG=23  |                                                                                                                     A6543210=6 A643210=6 A543210=5 A64210=4 A54320=3 A610=3 A60=3 A654321=2 A6421=2 A63210=2 A43210=1 A53210=1 A620=1 A6310=1 A6321=1 A64310=1 A64321=1 A653210=1 A64320=1 A654320=1 A5431=1 A4310=1                                                                                                                      |\n",
            "|    13    |  55%  | %POS=62 %NEG=44  |                                                                                     A6543210=29 A64310=8 A643210=7 A64321=7 A64320=6 A64210=5 A654320=4 A6421=4 A654310=3 A6=3 A6410=3 A632=3 A653210=2 A610=2 A63210=2 A6321=2 A6432=2 A65431=2 A654210=1 A65210=1 A6310=1 A643=1 A60=1 A621=1 A631=1 A6210=1 A6431=1 A63=1 A630=1 A6430=1 A654321=1                                                                                     |\n",
            "|    14    |   0%  |                  |                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "|    15    |  87%  | %POS=84 %NEG=91  | A6543210=36 A543210=36 A64321=6 A54320=5 A643210=5 A64210=5 A654321=4 A54310=4 A64310=4 A6432=4 A64320=4 A53210=3 A6421=3 A6=3 A6410=3 A0=3 A421=3 A43210=2 A54210=2 A610=2 A4210=2 A654320=2 A6520=1 A65321=1 A654310=1 A4310=1 A65420=1 A6310=1 A643=1 A632=1 A60=1 A631=1 A6210=1 A6431=1 A63=1 A630=1 A6430=1 A40=1 A410=1 A10=1 A430=1 A65210=1 A640=1 A54321=1 A531=1 A65320=1 A6420=1 A654210=1 A653210=1 A5410=1 A5320=1 A5431=1  |\n",
            "|    16    |  96%  | %POS=95 %NEG=99  |                               A543210=34 A6543210=32 A643210=20 A64321=7 A64310=6 A654210=5 A54320=5 A53210=5 A64320=5 A30=5 A654321=4 A4310=4 A54310=4 A654320=4 A63=3 A6421=3 A632=3 A63210=3 A321=3 A3210=3 A43210=2 A4320=2 A6310=2 A6432=2 A6410=2 A310=2 A5431=2 A65420=1 A654310=1 A54210=1 A643=1 A630=1 A6321=1 A61=1 A641=1 A6=1 A60=1 A640=1 A6430=1 A653210=1 A65210=1 A5310=1 A54321=1 A4321=1                               |\n",
            "|    17    |  87%  | %POS=84 %NEG=90  |                               A543210=33 A6543210=24 A643210=14 A64210=8 A654310=7 A43210=6 A654321=5 A54320=5 A53210=5 A6430=4 A20=4 A210=4 A6431=3 A21=3 A54321=3 A65420=2 A54210=2 A54310=2 A4320=2 A64310=2 A6421=2 A63210=2 A6321=2 A6410=2 A6210=2 A63=2 A6310=2 A6420=2 A65430=2 A5210=1 A64321=1 A632=1 A6432=1 A641=1 A643=1 A3210=1 A320=1 A65410=1 A65310=1 A653210=1 A421=1 A654210=1 A654320=1                               |\n",
            "|    18    |  88%  | %POS=85 %NEG=91  |                     A543210=38 A6543210=28 A643210=9 A10=6 A64210=5 A654320=5 A6432=5 A43210=4 A4310=4 A53210=4 A632=4 A65432=3 A64320=3 A654210=3 A6430=3 A54310=3 A6420=3 A64321=3 A2=3 A654321=2 A610=2 A63210=2 A640=2 A6410=2 A642=2 A64310=2 A210=2 A54210=1 A654310=1 A5210=1 A6421=1 A630=1 A643=1 A6=1 A6321=1 A62=1 A631=1 A620=1 A6431=1 A3210=1 A310=1 A653210=1 A5310=1 A54321=1 A5431=1 A421=1 A5410=1                      |\n",
            "|    19    |  96%  | %POS=95 %NEG=98  |                        A543210=34 A6543210=32 A643210=19 A64210=7 A654321=7 A64310=6 A54320=5 A63210=5 A210=5 A4310=4 A54310=4 A60=4 A64320=4 A0=4 A53210=3 A6410=3 A6320=3 A654320=3 A43210=2 A54321=2 A4320=2 A610=2 A6310=2 A6430=2 A6210=2 A630=2 A10=2 A65420=1 A54210=1 A654310=1 A5210=1 A5432=1 A6542=1 A3210=1 A30=1 A65421=1 A640=1 A5321=1 A65321=1 A653210=1 A5310=1 A4210=1 A6420=1 A654210=1 A5410=1                        |\n",
            "|    20    |  94%  | %POS=94 %NEG=94  |  A6543210=33 A543210=33 A643210=13 A64321=7 A64210=6 A64310=5 A654321=4 A4310=4 A54320=4 A53210=4 A64320=4 A0=4 A6421=3 A6=3 A63210=3 A6410=3 A632=3 A654320=3 A43210=2 A65420=2 A54310=2 A4320=2 A610=2 A6432=2 A21=2 A210=2 A654210=2 A653210=2 A5431=2 A54210=1 A654310=1 A5210=1 A6310=1 A6321=1 A643=1 A60=1 A621=1 A631=1 A6210=1 A6431=1 A63=1 A630=1 A6430=1 A10=1 A3210=1 A30=1 A640=1 A5310=1 A54321=1 A421=1 A6420=1 A5410=1   |\n",
            "|    21    |   0%  |                  |                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "+----------+-------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_questions, \"min_useful_position=\", ccfg.min_useful_position, \"max_useful_position=\", ccfg.max_useful_position )\n",
        "print()\n",
        "\n",
        "plt.hist(ccfg.perc_list, cfg.n_ctx, facecolor='blue', alpha=0.5)\n",
        "plt.xlabel('Position')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(r'Histogram of IQ: $\\mu=100$, $\\sigma=15$')\n",
        "# Tweak spacing to prevent clipping of ylabel\n",
        "plt.subplots_adjust(left=0.15)\n",
        "plt.show()\n",
        "\n",
        "print(ccfg.output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 13: Setup: Cell matrix\n",
        "\n",
        "Uses \"u_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qgSo4acLj5D"
      },
      "outputs": [],
      "source": [
        "class UsefulCell():\n",
        "  # Is this cell an attention head? If not, it must be an MLP layer\n",
        "  is_head: bool = True\n",
        "\n",
        "  position: int = 0  # token-position\n",
        "  layer: int = 0\n",
        "  head: int = 0\n",
        "\n",
        "\n",
        "# We (once) calculate the list of cells (attention head and MLP layers per position) that are useful to the model.\n",
        "calc_useful_cells = True\n",
        "# Once this list of useful cells is calculated (available) it is used to speed up functions.\n",
        "useful_cells = []\n",
        "\n",
        "\n",
        "def add_useful_cell(the_is_head, the_position, the_layer, the_head):\n",
        "  global calc_useful_cells\n",
        "  global useful_cells\n",
        "\n",
        "  if calc_useful_cells:\n",
        "    useful_cell = UsefulCell()\n",
        "    useful_cell.is_head = the_is_head\n",
        "    useful_cell.position = the_position\n",
        "    useful_cell.layer = the_layer\n",
        "    useful_cell.head = the_head\n",
        "\n",
        "    useful_cells = useful_cells + [useful_cell]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTaSo-UzLlZ_"
      },
      "outputs": [],
      "source": [
        "class U_Config():\n",
        "  # This is a head+MLP (row) by token (column) matrix of percent of failure percentages with associated notes\n",
        "  fail_percs = [[]]\n",
        "  fail_notes = [[]]\n",
        "  num_heads : int\n",
        "  num_mlps : int\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.fail_percs = [[0 for _ in range(cfg.n_ctx)] for _ in range((cfg.n_heads + 1) * cfg.n_layers)]\n",
        "    self.fail_notes = [[\"\" for _ in range(cfg.n_ctx)] for _ in range((cfg.n_heads + 1) * cfg.n_layers)]\n",
        "    self.num_heads = 0\n",
        "    self.num_mlps = 0\n",
        "\n",
        "\n",
        "ucfg = U_Config()\n",
        "ucfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "def add_u_fail_perc( the_position, the_layer, the_head, perc_fails, notes ):\n",
        "  global ucfg\n",
        "\n",
        "  the_row = the_layer * (cfg.n_heads+1) + the_head\n",
        "\n",
        "  if ucfg.fail_percs[the_row][the_position] == 0 :\n",
        "    ucfg.fail_percs[the_row][the_position] = perc_fails\n",
        "\n",
        "    add_useful_cell(the_head != cfg.n_heads, the_position, the_layer, the_head)\n",
        "\n",
        "  else:\n",
        "    print( \"add_u_fail_perc: Bad index\", the_row, the_position)\n",
        "\n",
        "  ucfg.fail_percs[the_row][the_position] = perc_fails\n",
        "  ucfg.fail_notes[the_row][the_position] = notes\n",
        "\n",
        "\n",
        "def add_head_fail_perc( the_position, the_layer, the_head, perc_fails, notes ):\n",
        "  global ucfg\n",
        "\n",
        "  add_u_fail_perc( the_position, the_layer, the_head, perc_fails, notes )\n",
        "  ucfg.num_heads += 1\n",
        "\n",
        "\n",
        "def add_mlp_fail_perc( the_position, the_layer, perc_fails, notes ):\n",
        "  global ucfg\n",
        "\n",
        "  add_u_fail_perc( the_position, the_layer, cfg.n_heads, perc_fails, notes )\n",
        "  ucfg.num_mlps += 1\n",
        "\n",
        "\n",
        "def get_column_headings():\n",
        "  datums = [\"Position\"]\n",
        "  for i in range(ccfg.min_useful_position, ccfg.max_useful_position+1):\n",
        "    datums = datums + [\"P\"+str(i)]\n",
        "  return datums\n",
        "\n",
        "\n",
        "def get_row_heading(i):\n",
        "  head = i % (cfg.n_heads + 1)\n",
        "  layer = i // (cfg.n_heads + 1)\n",
        "  return ( \"L\" + str(layer) + \"H\" + str(head) ) if head < cfg.n_heads else \"MLP \"\n",
        "\n",
        "\n",
        "# Print a 2 by 2 matrix of the percentage failures.\n",
        "def print_u_fail_percs():\n",
        "  global ucfg\n",
        "  global mcfg\n",
        "\n",
        "  print(\"The % failure rate when each head or MLP in each position is ablated, # failed heads =\", ucfg.num_heads, \", # failed mlps =\", ucfg.num_mlps )\n",
        "\n",
        "  cell_output = PrettyTable()\n",
        "\n",
        "  col_headings = get_column_headings()\n",
        "  cell_output.field_names = col_headings\n",
        "\n",
        "  num_rows = (cfg.n_heads + 1) * cfg.n_layers\n",
        "  num_cols = ccfg.max_useful_position - ccfg.min_useful_position + 1\n",
        "  percs_matrix = torch.zeros((num_rows, num_cols)).to(torch.int64)\n",
        "  mask_matrix = torch.zeros((num_rows, num_cols)).to(torch.int64)\n",
        "  row_headings = []\n",
        "\n",
        "  for i in range(num_rows):\n",
        "    row_heading = get_row_heading(i)\n",
        "    row_headings = row_headings + [row_heading]\n",
        "\n",
        "    datums = [row_heading]\n",
        "    for j in range(num_cols):\n",
        "      value = ucfg.fail_percs[i][ccfg.min_useful_position + j]\n",
        "      datums = datums + [\"\" if value == 0 else str(value)+\"%\"]\n",
        "      percs_matrix[i,j] = value\n",
        "      mask_matrix[i,j] = ( value == 0 )\n",
        "\n",
        "    cell_output.add_row(datums)\n",
        "\n",
        "  # Display a 2D heat map of the percentages\n",
        "  if use_sns == True:\n",
        "\n",
        "    sns.set_theme(rc={\"figure.dpi\": 96}) # use higher resolution\n",
        "    # %config InlineBackend.figure_format = \"svg\"\n",
        "    sns.set(font_scale=0.8)\n",
        "    sns.heatmap(utils.to_numpy(percs_matrix), annot=True, mask=utils.to_numpy(mask_matrix), cmap=\"YlGnBu\", xticklabels=col_headings[1:], yticklabels=row_headings)\n",
        "    plt.show()\n",
        "  else:\n",
        "    # Display a \"pretty\" table in html for use in blog\n",
        "    print(cell_output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "\n",
        "# Print a 2 by 2 matrix of notes.\n",
        "def print_u_fail_notes():\n",
        "  global ucfg\n",
        "  global mcfg\n",
        "\n",
        "  print(\"The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\")\n",
        "\n",
        "  cell_output = PrettyTable()\n",
        "  cell_output.field_names = get_column_headings()\n",
        "\n",
        "  for i in range((cfg.n_heads + 1) * cfg.n_layers):\n",
        "    datums = [get_row_heading(i)]\n",
        "    for j in range(ccfg.min_useful_position, ccfg.max_useful_position+1):\n",
        "      datums = datums + [ucfg.fail_notes[i][j]]\n",
        "    cell_output.add_row(datums)\n",
        "\n",
        "  print(cell_output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99LIC1l4MD32"
      },
      "source": [
        "# Part 14: Setup: Ablate each MLP in EACH position. Impact on Loss?\n",
        "Ablating the MLP in each layer in each position and seeing if the loss increases shows which head+layer+MLP are used by the algorithm. Use \"m_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class M_Config():\n",
        "  position : int  # zero-based token-position to ablate\n",
        "  layer : int # zero-based layer to ablate. 0 to cfg.n_layers\n",
        "  threshold : float\n",
        "  output = PrettyTable()\n",
        "  hook_calls : int\n",
        "  questions = varied_questions\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.position = 0\n",
        "    self.layer = 0\n",
        "    self.threshold = 0.12\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Position\", \"MLP Layer\", \"% Fails\", \"% Fails by Case\", \"# Fails by Patterns\"]\n",
        "    self.hook_calls = 0\n",
        "\n",
        "\n",
        "\n",
        "mcfg = M_Config()\n",
        "mcfg.reset()"
      ],
      "metadata": {
        "id": "CaB1fAWbxqWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOxNc9SAMGRH"
      },
      "outputs": [],
      "source": [
        "def m_mlp_hook_post(value, hook):\n",
        "  global mcfg\n",
        "\n",
        "  mcfg.hook_calls += 1\n",
        "  #print( \"In m_mlp_hook_post\", value.shape) # Get [1, 22, 2040] = ???, cfg.n_ctx, ???\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to the MLP\n",
        "  value[:,mcfg.position,:] =  mean_mlp_hook_post[:,mcfg.position,:].clone()\n",
        "\n",
        "\n",
        "def m_perform_core(show_all = False):\n",
        "  global mcfg\n",
        "\n",
        "  the_hook = [(l_mlp_hook_post_name[mcfg.layer], m_mlp_hook_post)]\n",
        "  loss_mean = predict_experiment_question(mcfg.questions, the_hook, mcfg.threshold)\n",
        "\n",
        "  num_fails = total_case_fails()\n",
        "  if show_all or (num_fails > 0):\n",
        "    perc_fails = round(100 * num_fails / mcfg.questions.shape[0])\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "\n",
        "    mcfg.output.add_row([str(mcfg.position), str(mcfg.layer), perc_fails, get_case_fails(), pattern_results])\n",
        "\n",
        "    add_mlp_fail_perc( mcfg.position, mcfg.layer, perc_fails, top_pattern )\n",
        "\n",
        "\n",
        "def m_perform(all_cells):\n",
        "  global mcfg\n",
        "\n",
        "  if cfg.n_digits >= 5 :\n",
        "    ucfg.reset()\n",
        "    mcfg.reset()\n",
        "    if all_cells:\n",
        "      for mcfg.position in range(cfg.n_ctx):\n",
        "        for mcfg.layer in range(cfg.n_layers):\n",
        "          m_perform_core()\n",
        "    else:\n",
        "      for useful_cell in useful_cells:\n",
        "        if not useful_cell.is_head:\n",
        "          mcfg.position = useful_cell.position\n",
        "          mcfg.layer = useful_cell.layer\n",
        "          m_perform_core()\n",
        "\n",
        "\n",
        "def m_print_results(title):\n",
        "    global mcfg\n",
        "\n",
        "    print_config()\n",
        "    print()\n",
        "    print(title, mcfg.questions.shape[0])\n",
        "    print(mcfg.output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKZF_B6OMIq3"
      },
      "source": [
        "# Part 15: Setup: Ablate EACH head in EACH position. Impact on Digit & Task Loss?\n",
        "Ablating each head in each layer in each position and seeing if the loss increases shows which position+layer+head are used by the algorithm. Use \"h_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class H_Config():\n",
        "  position : int # zero-based token position to ablate. 0 to cfg.n_ctx - 1\n",
        "  layer : int # zero-based layer to ablate. 0 to cfg.n_layers - 1\n",
        "  head : int # zero-based head to ablate. 0 to cfg.n_heads - 1\n",
        "  threshold : float\n",
        "  output = PrettyTable()\n",
        "  hook_calls: int\n",
        "  questions = varied_questions\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.position = 0 # zero-based token position to ablate. 0 to say 17\n",
        "    self.layer = 0 # zero-based layer to ablate. 0 to 1\n",
        "    self.head = 0 # zero-based head to ablate. 0 to 2\n",
        "    self.threshold = 0.12\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Position\", \"Layer\", \"Head\", \"% Fails\", \"% Fails by Case\", \"# Fails by Impact\"]\n",
        "    self.hook_calls = 0\n",
        "\n",
        "\n",
        "hcfg = H_Config()\n",
        "hcfg.reset()"
      ],
      "metadata": {
        "id": "zHdJEIw1yMXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EnisO6MMGQ"
      },
      "outputs": [],
      "source": [
        "def h_set_attn_hook_z(value, hook):\n",
        "  global hcfg\n",
        "\n",
        "  hcfg.hook_calls += 1\n",
        "  # print( \"In h_set_attn_hook_z\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,hcfg.position,hcfg.head,:] = mean_attn_z[:,hcfg.position,hcfg.head,:].clone()\n",
        "\n",
        "\n",
        "def h_perform_core(show_all = False):\n",
        "  global hcfg\n",
        "\n",
        "  the_hook = [(l_attn_hook_z_name[hcfg.layer], h_set_attn_hook_z)]\n",
        "  loss_mean = predict_experiment_question(hcfg.questions, the_hook, hcfg.threshold)\n",
        "\n",
        "  num_fails = total_case_fails()\n",
        "  if show_all or (num_fails > 0):\n",
        "    perc_fails = round(100 * num_fails / hcfg.questions.shape[0])\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "\n",
        "    hcfg.output.add_row([str(hcfg.position), str(hcfg.layer), str(hcfg.head), perc_fails, get_case_fails(), pattern_results])\n",
        "\n",
        "    add_head_fail_perc( hcfg.position, hcfg.layer, hcfg.head, perc_fails, top_pattern)\n",
        "\n",
        "  return num_fails\n",
        "\n",
        "\n",
        "def h_perform(all_cells):\n",
        "  global hcfg\n",
        "\n",
        "  if cfg.n_digits >= 5 :\n",
        "    hcfg.reset()\n",
        "    if all_cells:\n",
        "      for hcfg.position in range(ccfg.min_useful_position, ccfg.max_useful_position+1):\n",
        "        for hcfg.layer in range(cfg.n_layers):\n",
        "          for hcfg.head in range(cfg.n_heads):\n",
        "            h_perform_core()\n",
        "    else:\n",
        "      for useful_cell in useful_cells:\n",
        "        if useful_cell.is_head:\n",
        "          hcfg.position = useful_cell.position\n",
        "          hcfg.layer = useful_cell.layer\n",
        "          hcfg.head = useful_cell.head\n",
        "          h_perform_core()\n",
        "\n",
        "\n",
        "def h_print_results(title, the_format=\"\"):\n",
        "  global hcfg\n",
        "\n",
        "  print_config()\n",
        "  print()\n",
        "  print(title, hcfg.questions.shape[0], \", #hook_calls=\", hcfg.hook_calls)\n",
        "\n",
        "  if the_format == \"\":\n",
        "    the_format = cfg.table_out_format\n",
        "  print(hcfg.output.get_formatted_string(out_format=the_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16: Calculate show cell matrixes\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uluv96KMQJS"
      },
      "outputs": [],
      "source": [
        "def calc_cell_matrices(title, questions, all_cells):\n",
        "  global mcfg\n",
        "  global hcfg\n",
        "  global verbose\n",
        "\n",
        "  mcfg.questions = questions\n",
        "  m_perform(all_cells)\n",
        "  if verbose:\n",
        "    m_print_results(title)\n",
        "\n",
        "  hcfg.questions = questions\n",
        "  h_perform(all_cells)\n",
        "  if verbose:\n",
        "    h_print_results(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE64pXy1MRsw"
      },
      "outputs": [],
      "source": [
        "def print_cell_matrices():\n",
        "  global verbose\n",
        "\n",
        "  verbose = False\n",
        "\n",
        "  print_config()\n",
        "  print()\n",
        "  print_u_fail_percs()\n",
        "  print()\n",
        "  print_u_fail_notes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beec1788-0800-4276-dfc0-73f9af5d4f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 85 , # failed mlps = 29\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "| Position |  P0 | P1 | P2 | P3 | P4 | P5 |  P6 |  P7 | P8 |  P9 | P10 | P11 | P12 | P13 | P14 | P15 | P16 | P17 | P18 | P19 | P20 |\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "|   L0H0   |  1% | 8% | 3% | 3% |    | 1% | 24% | 35% |    | 30% |  5% | 10% | 22% |  9% |     | 21% | 21% | 25% | 13% | 33% | 16% |\n",
            "|   L0H1   | 16% |    |    |    |    |    |     |     |    |  1% |  6% |  6% |  1% | 61% |     | 92% | 86% | 90% | 84% | 88% | 86% |\n",
            "|   L0H2   |     |    |    |    |    |    |     |     |    |     |  4% |  4% |  2% |     |     | 38% | 49% | 42% | 45% | 49% | 37% |\n",
            "|   L0H3   |     |    |    |    |    |    |     |     |    |  1% |     |     |     |     |     | 37% | 37% | 45% | 43% | 40% |     |\n",
            "|   MLP    |  2% |    |    |    |    |    |  2% |  2% |    |  1% |  3% |  5% |  9% |  8% |     | 56% | 70% | 62% | 59% | 67% | 60% |\n",
            "|   L1H0   |     |    |    |    |    |    |     |     |    |  2% |  1% |  1% |     |  1% |     |  5% |  3% | 14% |  2% |  8% |  3% |\n",
            "|   L1H1   |     |    |    |    |    |    |  2% |     |    |  2% |  3% |  2% |  2% |     |     | 10% | 17% | 14% |  3% | 39% |  8% |\n",
            "|   L1H2   |     |    |    |    |    |    |     |     |    |     |     |     |     |     |     |  7% | 31% | 31% | 32% | 16% | 28% |\n",
            "|   L1H3   |     |    |    |    |    |    |     |     |    |     |     |     |     |  1% |     |     |     |     |     |     |     |\n",
            "|   MLP    |     |    |    |    |    |    |     |     |    |     |  3% |  8% | 17% |     |     | 25% | 37% | 36% |  6% | 18% |  7% |\n",
            "|   L2H0   |     |    |    |    |    |    |     |     |    |     |     |     |     |  3% |     |     |  2% |  1% |     |     |     |\n",
            "|   L2H1   |     |    |    |    |    |    |     |     |    |     |     |     |     |  3% |     |  1% |  4% |     |     |     |     |\n",
            "|   L2H2   |     |    |    |    |    |    |     |     |    |     |     |     |     |  2% |     |  3% |  2% |  1% |     |     |     |\n",
            "|   L2H3   |     |    |    |    |    |    |     |     |    |     |     |     |     |  2% |     |     |  1% |     |     |     |     |\n",
            "|   MLP    |     |    |    |    |    |    |     |     |    |     |     |     |     |  1% |     |  9% | 15% | 21% | 16% |  4% |     |\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------+----+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Position |                                                  P0                                                  |                                                P1                                               |                             P2                            |                    P3                   | P4 |        P5        |                                                                                  P6                                                                                  |                                                                                                                                   P7                                                                                                                                  | P8 |                                                                                                                                P9                                                                                                                               |                                     P10                                     |                                                              P11                                                               |                                                                                               P12                                                                                                |                                                                                                                                                   P13                                                                                                                                                    | P14 |                                                                                                                                                                                                              P15                                                                                                                                                                                                               |                                                                                                                                                                                                     P16                                                                                                                                                                                                      |                                                                                                                                                                                                P17                                                                                                                                                                                                |                                                                                                                                                                                              P18                                                                                                                                                                                               |                                                                                                                                                                                                           P19                                                                                                                                                                                                           |                                                                                                                                                                                                                         P20                                                                                                                                                                                                                          |\n",
            "+----------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------+----+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|   L0H0   |                                                A60=1                                                 | A543210=5, A6543210=2, A5320=1, A43210=1, A4320=1, A64=1, A63210=1, A54321=1, A54320=1, A5410=1 | A543210=1, A5320=1, A43210=1, A64=1, A63210=1, A6543210=1 | A53210=1, A420=1, A64=1, A6=1, A64320=1 |    | A420=1, A54321=1 | A543210=12, A6543210=7, A643210=6, A64210=3, A654321=2, A4310=2, A64310=2, A53210=2, A654320=2, A63210=2, A2=2, A54310=1, A6421=1, A620=1, A6321=1, A43210=1, A210=1 | A543210=15, A6543210=14, A643210=4, A4310=3, A210=3, A54320=2, A54310=2, A64210=2, A64320=2, A0=2, A1=2, A654321=2, A4321=1, A654310=1, A521=1, A43210=1, A6421=1, A6410=1, A64310=1, A630=1, A6430=1, A3210=1, A3=1, A640=1, A4320=1, A53210=1, A653210=1, A654320=1 |    | A543210=11, A6543210=10, A643210=5, A64320=4, A654321=3, A53210=3, A621=2, A654210=2, A54321=2, A654320=1, A54320=1, A6421=1, A6432=1, A64321=1, A6321=1, A6310=1, A632=1, A6320=1, A6430=1, A64210=1, A63210=1, A653210=1, A43210=1, A41=1, A54210=1, A65430=1 | A64321=2, A654321=1, A6321=1, A640=1, A6431=1, A6430=1, A64310=1, A654210=1 | A6432=3, A643210=3, A543210=2, A64320=2, A64321=2, A54320=1, A6543210=1, A64210=1, A6421=1, A6431=1, A6430=1, A6321=1, A5431=1 | A64321=9, A643210=6, A64210=3, A63210=3, A54320=2, A543210=2, A6543210=2, A610=2, A6321=2, A64320=2, A654320=2, A654321=1, A43210=1, A53210=1, A632=1, A640=1, A621=1, A6410=1, A6310=1, A6421=1 |                                                                                        A632=3, A60=2, A630=2, A64310=1, A643210=1, A6410=1, A64210=1, A64321=1, A610=1, A6421=1, A64320=1, A631=1, A6210=1, A63=1                                                                                        |     |                                                                                                             A6543210=6, A543210=6, A53210=4, A6410=3, A6432=3, A54320=2, A64321=2, A64210=2, A640=2, A654310=1, A64=1, A6421=1, A64320=1, A6431=1, A643=1, A6430=1, A430=1, A4310=1, A531=1, A643210=1, A654320=1                                                                                                              |                                                                                      A543210=6, A6543210=5, A643210=4, A54320=2, A64210=2, A6310=2, A6421=2, A64321=2, A6420=2, A654210=1, A53210=1, A654320=1, A643=1, A64310=1, A630=1, A6321=1, A6432=1, A63210=1, A30=1, A310=1, A321=1, A54310=1, A5431=1, A4310=1                                                                                      |                                                                                         A543210=9, A6543210=7, A632=3, A64321=3, A643210=2, A53210=2, A6210=2, A6432=2, A64210=2, A6410=2, A64320=2, A54321=2, A43210=1, A4320=1, A62=1, A620=1, A621=1, A641=1, A20=1, A210=1, A21=1, A654310=1, A63210=1                                                                                        |                                                                                                           A64321=4, A6543210=3, A6321=3, A543210=2, A654321=1, A654310=1, A6431=1, A61=1, A640=1, A610=1, A621=1, A6410=1, A64210=1, A631=1, A643210=1, A64310=1, A210=1, A654320=1                                                                                                            |                                                                         A6543210=10, A643210=10, A64210=6, A543210=5, A60=3, A6320=3, A64320=3, A6410=2, A64310=2, A53210=2, A54321=1, A654321=1, A65420=1, A6321=1, A6430=1, A610=1, A6210=1, A6310=1, A63210=1, A630=1, A0=1, A210=1, A653210=1, A5310=1, A5431=1, A54320=1, A54310=1, A4310=1                                                                        |                                                                                                                                                                A543210=10, A0=4, A4310=3, A54320=3, A43210=2, A210=2, A5431=2, A54210=1, A5210=1, A53210=1, A30=1, A54321=1, A5410=1                                                                                                                                                                 |\n",
            "|   L0H1   | A6543210=14, A643210=6, A654320=3, A64210=2, A60=2, A64310=1, A640=1, A653210=1, A63210=1, A654210=1 |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                              A630=1                                                                                                                             |         A60=4, A610=2, A621=2, A654321=1, A53210=1, A6=1, A654210=1         |                         A543210=3, A621=3, A654320=1, A6310=1, A64310=1, A643210=1, A6431=1, A53210=1                          |                                                                                            A654321=1                                                                                             | A6543210=31, A643210=11, A64310=8, A64321=7, A64210=6, A654320=6, A64320=6, A654310=4, A6421=4, A654321=3, A6=3, A6410=3, A632=3, A610=2, A63210=2, A6321=2, A6432=2, A65431=2, A65210=1, A653210=1, A6310=1, A643=1, A60=1, A621=1, A631=1, A6210=1, A6431=1, A63=1, A630=1, A6430=1, A6420=1, A65410=1 |     | A543210=30, A6543210=28, A643210=15, A64210=8, A64321=8, A54320=5, A64310=5, A6410=5, A6432=5, A654321=4, A54310=4, A6421=4, A40=4, A421=4, A53210=3, A4310=3, A653210=3, A64=3, A64320=3, A43210=2, A65420=2, A54210=2, A4320=2, A643=2, A640=2, A6431=2, A6430=2, A410=2, A4210=2, A5431=2, A654320=2, A5320=1, A3210=1, A6310=1, A6321=1, A6320=1, A430=1, A63210=1, A54321=1, A6420=1, A310=1, A65210=1, A65320=1, A5410=1 |     A6543210=30, A543210=24, A643210=15, A64321=10, A64310=8, A654321=5, A30=5, A54310=4, A63=4, A654320=3, A54210=3, A4310=3, A54320=3, A53210=3, A6310=3, A63210=3, A6321=3, A632=3, A64320=3, A321=3, A3210=3, A43210=2, A4320=2, A630=2, A6432=2, A6430=2, A310=2, A653210=2, A5431=2, A654310=1, A643=1, A631=1, A6210=1, A6431=1, A6420=1, A64210=1, A5310=1, A54321=1, A4321=1, A654210=1, A410=1     | A543210=33, A6543210=29, A643210=14, A64210=10, A64321=7, A54320=6, A53210=5, A64320=5, A43210=4, A654321=4, A632=4, A20=4, A210=4, A62=3, A6432=3, A21=3, A54321=3, A654320=3, A65420=2, A654310=2, A4320=2, A6210=2, A64310=2, A6421=2, A63210=2, A654210=2, A6420=2, A653210=2, A54310=1, A5210=1, A641=1, A6310=1, A620=1, A621=1, A6321=1, A610=1, A6320=1, A3210=1, A320=1, A41=1, A54210=1 | A6543210=35, A543210=27, A643210=12, A64321=9, A64310=6, A10=6, A6321=5, A64210=5, A43210=4, A6410=4, A654210=3, A54320=3, A654321=3, A4310=3, A61=3, A610=3, A21=3, A6420=2, A54310=2, A53210=2, A6431=2, A6421=2, A631=2, A63210=2, A54210=1, A5210=1, A5430=1, A64320=1, A621=1, A6210=1, A6310=1, A210=1, A3210=1, A310=1, A65320=1, A653210=1, A530=1, A54321=1, A5320=1, A421=1, A5431=1 |                  A6543210=33, A543210=24, A643210=13, A64210=9, A54321=6, A64320=6, A64310=5, A54310=5, A63210=5, A4310=4, A54320=4, A53210=4, A64321=4, A60=4, A0=4, A210=4, A6410=3, A6320=3, A654320=3, A4320=2, A610=2, A6310=2, A6430=2, A6210=2, A630=2, A10=2, A654210=2, A65420=1, A54210=1, A654310=1, A521=1, A43210=1, A654321=1, A6431=1, A321=1, A30=1, A653210=1, A4210=1, A642=1, A541=1                 | A6543210=28, A543210=27, A643210=8, A64210=7, A64321=7, A54320=6, A654321=4, A4310=4, A64310=4, A64320=4, A0=4, A54310=3, A53210=3, A6421=3, A6=3, A63210=3, A6410=3, A632=3, A21=3, A654320=3, A43210=2, A65420=2, A4320=2, A610=2, A6321=2, A6432=2, A10=2, A654210=2, A653210=2, A5431=2, A54210=1, A654310=1, A643=1, A60=1, A621=1, A631=1, A6210=1, A6431=1, A63=1, A630=1, A6430=1, A210=1, A3210=1, A30=1, A640=1, A5310=1, A54321=1, A421=1 |\n",
            "|   L0H2   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                       A60=3, A610=2, A53210=1, A621=1                       |                                       A543210=3, A654320=1, A6410=1, A64210=1, A53210=1                                        |                                                                                     A6421=1, A63=1, A5431=1                                                                                      |                                                                                                                                                                                                                                                                                                          |     |                                                                                    A543210=19, A6543210=11, A643210=9, A4310=4, A54320=4, A53210=4, A64210=2, A4320=2, A54310=2, A653210=2, A5431=2, A43210=1, A65420=1, A5210=1, A6310=1, A54210=1, A65321=1, A3210=1, A640=1, A654321=1, A421=1, A654320=1, A6420=1, A654210=1, A65320=1                                                                                     |                          A543210=15, A6543210=14, A643210=8, A64321=7, A64310=4, A64320=4, A654320=3, A4310=3, A54310=3, A4210=2, A54320=2, A4320=2, A63=2, A6321=2, A6432=2, A6430=2, A54210=1, A65421=1, A5420=1, A6310=1, A643=1, A632=1, A631=1, A6431=1, A630=1, A30=1, A310=1, A321=1, A65210=1, A653210=1, A510=1, A54321=1, A654321=1, A63210=1, A53210=1, A5431=1, A410=1                           |                                                 A6543210=18, A543210=17, A43210=6, A643210=6, A64210=5, A6421=3, A654321=2, A53210=2, A54320=2, A654310=2, A65420=1, A5210=1, A54310=1, A4320=1, A62=1, A6321=1, A64321=1, A632=1, A64320=1, A63210=1, A20=1, A210=1, A21=1, A320=1, A6420=1, A653210=1, A654210=1, A54210=1, A54321=1, A654320=1                                                 |                                                               A543210=22, A6543210=21, A643210=6, A654210=4, A43210=3, A654321=3, A64210=2, A54320=2, A64321=2, A6410=2, A10=2, A21=2, A210=2, A4310=2, A5420=1, A65432=1, A5430=1, A6421=1, A6310=1, A64310=1, A6321=1, A631=1, A6210=1, A3210=1, A654320=1, A53210=1, A5431=1                                                                |                                                          A6543210=23, A543210=19, A643210=9, A63210=4, A64210=3, A53210=3, A64310=3, A54310=3, A654320=3, A54320=2, A6310=2, A64320=2, A210=2, A4310=2, A43210=1, A65420=1, A54210=1, A54321=1, A64321=1, A610=1, A6320=1, A630=1, A0=1, A10=1, A30=1, A65321=1, A5310=1, A4210=1, A654321=1, A6420=1, A5410=1                                                          |                                                                             A543210=14, A6543210=14, A643210=6, A654321=2, A64210=2, A4310=2, A64310=2, A54320=2, A53210=2, A6410=2, A6421=2, A0=2, A210=2, A654210=2, A54210=1, A5210=1, A43210=1, A65420=1, A610=1, A63=1, A630=1, A6432=1, A21=1, A653210=1, A54321=1, A63210=1, A654320=1, A6420=1, A5410=1, A5431=1                                                                             |\n",
            "|   L0H3   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                              A630=1                                                                                                                             |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                                                                                                                                                                                          |     |                                                                                             A543210=27, A53210=8, A54320=5, A54310=4, A54210=2, A4310=2, A4320=2, A410=2, A421=2, A4210=2, A6543210=2, A310=2, A5320=1, A65321=1, A654321=1, A43210=1, A40=1, A654210=1, A653210=1, A54321=1, A531=1, A5410=1, A5431=1, A654320=1                                                                                              |                                                                                                                   A543210=32, A54320=5, A30=5, A4310=4, A54310=4, A53210=3, A321=3, A3210=3, A54210=2, A4320=2, A310=2, A5431=2, A43210=1, A5420=1, A4210=1, A643210=1, A54321=1, A4321=1                                                                                                                    |                                               A543210=24, A6543210=9, A43210=4, A54320=4, A53210=4, A64321=4, A20=4, A54310=3, A643210=3, A210=3, A54321=3, A6210=2, A6321=2, A654310=2, A64210=1, A5210=1, A5430=1, A65420=1, A63210=1, A63=1, A620=1, A6310=1, A6430=1, A3210=1, A320=1, A653210=1, A64310=1, A421=1, A640=1, A654320=1, A54210=1                                               |                                                        A543210=31, A54320=5, A43210=4, A4310=4, A6543210=4, A54310=3, A643210=3, A10=3, A21=3, A64210=2, A64310=2, A210=2, A654320=2, A5420=1, A654310=1, A5210=1, A5320=1, A6432=1, A610=1, A3210=1, A310=1, A53210=1, A653210=1, A54321=1, A63210=1, A5431=1, A42=1, A5410=1, A543=1                                                         |                                                                                      A543210=33, A54310=5, A4310=4, A54320=4, A54321=3, A53210=3, A0=3, A43210=2, A6543210=2, A4320=2, A10=2, A210=2, A54210=1, A521=1, A643210=1, A5432=1, A5321=1, A65420=1, A6421=1, A6432=1, A63=1, A3210=1, A30=1, A653210=1, A4210=1, A5410=1                                                                                     |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   MLP    |                                            A60=2, A6210=1                                            |                                                                                                 |                                                           |                                         |    |                  |                                                                       A543210=1, A210=1, A60=1                                                                       |                                                                                                                    A643210=1, A654321=1, A6543210=1                                                                                                                   |    |                                                                                                                             A64320=2                                                                                                                            |                       A60=3, A53210=1, A610=1, A621=1                       |                          A543210=3, A654320=1, A643=1, A64310=1, A643210=1, A6431=1, A621=1, A53210=1                          |                                                         A64321=9, A6321=2, A654321=1, A621=1, A6421=1, A6210=1, A2=1, A64320=1, A5410=1                                                          |                                                                                                    A643210=2, A64320=2, A610=2, A63210=2, A64310=2, A6543210=1, A6=1, A6321=1, A60=1, A621=1, A6210=1                                                                                                    |     |                                                                           A543210=33, A6543210=30, A53210=6, A643210=5, A54320=5, A653210=3, A54310=3, A54210=2, A4320=2, A4310=2, A654320=2, A6520=1, A654321=1, A5320=1, A65321=1, A43210=1, A65420=1, A65210=1, A640=1, A54321=1, A310=1, A531=1, A65320=1, A654210=1, A63210=1, A5410=1, A5431=1                                                                           | A543210=25, A6543210=23, A643210=12, A53210=5, A30=5, A654320=4, A63=4, A63210=4, A654321=3, A54320=3, A6310=3, A64321=3, A632=3, A43210=2, A654210=2, A5420=2, A54210=2, A54310=2, A6321=2, A630=2, A64320=2, A310=2, A4310=2, A5431=2, A65421=1, A4320=1, A64210=1, A64310=1, A643=1, A642=1, A631=1, A6431=1, A6432=1, A6430=1, A321=1, A3210=1, A420=1, A653210=1, A65210=1, A54321=1, A4321=1, A65420=1 |          A543210=22, A6543210=20, A643210=11, A54310=6, A43210=5, A54320=5, A654321=4, A63210=4, A64210=3, A654310=3, A64321=3, A632=3, A65420=2, A54210=2, A53210=2, A62=2, A54321=2, A654320=2, A5210=1, A5430=1, A4320=1, A6321=1, A631=1, A64310=1, A6210=1, A621=1, A6421=1, A6430=1, A64320=1, A3210=1, A65410=1, A6420=1, A65310=1, A653210=1, A421=1, A65430=1, A640=1, A654210=1         | A543210=24, A6543210=20, A643210=8, A54320=5, A64210=4, A654321=3, A43210=3, A53210=3, A64321=3, A654320=3, A4310=3, A654210=2, A64320=2, A63210=2, A6321=2, A2=2, A210=2, A653210=2, A4320=1, A54210=1, A654310=1, A430=1, A6430=1, A65432=1, A642=1, A61=1, A610=1, A6310=1, A632=1, A64310=1, A6420=1, A6421=1, A631=1, A6210=1, A3210=1, A310=1, A54310=1, A5431=1, A42=1, A5410=1, A543=1 | A6543210=27, A543210=23, A643210=11, A64210=5, A63210=4, A4310=3, A54320=3, A54310=3, A64310=3, A64320=3, A210=3, A43210=2, A65420=2, A5432=2, A654321=2, A53210=2, A60=2, A610=2, A6310=2, A6210=2, A653210=2, A54321=2, A54210=1, A65431=1, A5210=1, A64321=1, A6321=1, A6431=1, A6421=1, A6410=1, A630=1, A1=1, A3210=1, A30=1, A654210=1, A640=1, A4320=1, A5310=1, A4210=1, A6420=1, A65421=1, A65432=1, A654320=1 |                                A543210=28, A6543210=19, A643210=11, A64210=4, A54320=4, A64310=4, A64321=4, A63210=3, A0=3, A654321=2, A4320=2, A53210=2, A6=2, A6321=2, A632=2, A43210=1, A65420=1, A5210=1, A54310=1, A6310=1, A643=1, A6410=1, A610=1, A621=1, A6432=1, A6421=1, A64320=1, A6431=1, A63=1, A6430=1, A210=1, A21=1, A3210=1, A30=1, A640=1, A5310=1, A5431=1, A654320=1, A6420=1, A4310=1, A5410=1                                 |\n",
            "|   L1H0   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                       A63=1, A6=1, A630=1                                                                                                                       |                                  A654210=1                                  |                                                            A6431=1                                                             |                                                                                                                                                                                                  |                                                                                                                                                 A63210=1                                                                                                                                                 |     |                                                                                                                                                                                             A543210=6, A53210=1, A4310=1, A54320=1                                                                                                                                                                                             |                                                                                                                                                                         A643210=1, A6543210=1, A632=1, A6432=1, A654321=1, A654320=1                                                                                                                                                                         |                                                                                                                   A643210=6, A6543210=5, A64321=2, A64320=2, A654321=1, A53210=1, A621=1, A6321=1, A6310=1, A632=1, A6430=1, A654310=1, A653210=1, A654210=1, A54321=1, A65430=1                                                                                                                  |                                                                                                                                                                                       A6543210=2, A620=1                                                                                                                                                                                       |                                                                                                                                                                 A6543210=5, A543210=2, A654321=2, A643210=1, A53210=1, A1=1, A210=1, A54321=1, A653210=1                                                                                                                                                                |                                                                                                                                                                                                               A543210=3, A4320=1, A0=1                                                                                                                                                                                                               |\n",
            "|   L1H1   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                        A4320=1, A310=1, A30=1                                                                        |                                                                                                                                                                                                                                                                       |    |                                                                                                                         A320=2, A3210=1                                                                                                                         |                  A60=2, A53210=1, A6210=1, A621=1, A63210=1                 |                                                  A6430=2, A543210=1, A53210=1                                                  |                                                                                    A6430=1, A43210=1, A6320=1                                                                                    |                                                                                                                                                                                                                                                                                                          |     |                                                                                                                                                          A543210=8, A54320=2, A4320=2, A53210=1, A5320=1, A43210=1, A54321=1, A65320=1, A5410=1, A6543210=1, A4310=1                                                                                                                                                           |                                                                                                                                       A643210=9, A6543210=5, A64210=4, A6420=3, A63=2, A6421=2, A64321=2, A654321=1, A654310=1, A654320=1, A64310=1, A642=1, A64320=1                                                                                                                                        |                                                                                                                             A6543210=8, A6410=3, A654321=2, A6210=2, A632=2, A641=2, A654320=2, A65420=1, A6432=1, A64210=1, A654210=1, A653210=1, A64310=1, A654310=1                                                                                                                            |                                                                                                                                                                                A6543210=3, A654210=1, A643210=1                                                                                                                                                                                |                                                                     A6543210=17, A643210=10, A543210=6, A64210=4, A63210=4, A64321=3, A60=3, A64320=3, A64310=3, A610=2, A6430=2, A6320=2, A654320=2, A4321=1, A65420=1, A654310=1, A54310=1, A6321=1, A6310=1, A6421=1, A6210=1, A630=1, A0=1, A3=1, A640=1, A654321=1, A642=1, A4310=1, A654210=1                                                                     |                                                                                                                                                                               A64321=3, A63210=2, A632=2, A64310=2, A643=1, A6=1, A610=1, A621=1, A64210=1, A643210=1                                                                                                                                                                                |\n",
            "|   L1H2   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                                                                                                                                                                                          |     |                                                                                                                                                                                       A6543210=7, A653210=3, A60=1, A643210=1, A654320=1                                                                                                                                                                                       |                                                                                              A543210=10, A6543210=10, A643210=8, A64310=4, A53210=4, A64321=4, A54320=3, A632=3, A64320=2, A654321=1, A54210=1, A654210=1, A643=1, A631=1, A63=1, A630=1, A30=1, A65210=1, A653210=1, A510=1, A541=1, A654320=1                                                                                              |                                                                                          A543210=10, A6543210=8, A643210=8, A64210=5, A54320=3, A654321=3, A63210=3, A64321=3, A43210=2, A6321=2, A64320=2, A654310=2, A64310=2, A5210=1, A65420=1, A621=1, A6421=1, A320=1, A53210=1, A6420=1, A54310=1                                                                                          |                                                                                    A543210=13, A6543210=13, A64210=5, A643210=4, A43210=3, A654321=3, A654210=2, A4310=2, A6421=2, A6321=2, A6410=2, A654310=1, A53210=1, A54310=1, A63210=1, A6310=1, A64321=1, A64310=1, A610=1, A21=1, A310=1, A654320=1                                                                                    |                                                                                                                           A6543210=10, A64210=3, A543210=2, A64310=2, A643210=2, A6410=2, A43210=1, A431=1, A4320=1, A5431=1, A65420=1, A60=1, A64320=1, A6430=1, A654321=1, A6420=1, A54320=1                                                                                                                          |                                                                                        A543210=13, A6543210=4, A0=4, A643210=3, A43210=2, A64210=2, A4310=2, A54320=2, A53210=2, A6410=2, A64320=2, A5210=1, A654321=1, A4320=1, A65420=1, A6310=1, A60=1, A64321=1, A6210=1, A6421=1, A6432=1, A210=1, A30=1, A54321=1, A5431=1, A6420=1, A654320=1, A5410=1                                                                                        |\n",
            "|   L1H3   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                                  A60=1                                                                                                                                                   |     |                                                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   MLP    |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                   A643210=2, A53210=1, A6421=1, A654210=1                   |               A543210=3, A621=3, A643210=2, A654320=1, A631=1, A6421=1, A64321=1, A6431=1, A53210=1, A6543210=1                |  A543210=4, A64320=3, A60=3, A654321=2, A6421=2, A64210=2, A643210=2, A6430=2, A610=2, A54320=1, A53210=1, A620=1, A6310=1, A632=1, A6320=1, A64321=1, A653210=1, A63210=1, A6543210=1, A5431=1  |                                                                                                                                                                                                                                                                                                          |     |                                                                                                                               A6543210=17, A543210=12, A53210=3, A54320=2, A653210=2, A654210=2, A654320=2, A654321=1, A5320=1, A54210=1, A65321=1, A43210=1, A640=1, A4320=1, A643210=1, A310=1                                                                                                                               |                                                                                                       A6543210=20, A543210=19, A643210=6, A654321=4, A54320=4, A654320=3, A53210=2, A64210=2, A64321=2, A4320=1, A5420=1, A64310=1, A643=1, A653210=1, A54310=1, A654210=1, A64320=1, A5431=1, A4310=1                                                                                                       |                                                                         A543210=19, A6543210=12, A43210=5, A64210=4, A54310=3, A643210=3, A54321=3, A54210=2, A54320=2, A64321=2, A210=2, A654321=1, A5430=1, A53210=1, A63210=1, A6321=1, A631=1, A632=1, A621=1, A643=1, A6421=1, A654210=1, A6420=1, A653210=1, A640=1                                                                         |                                                                                                                                                                       A6543210=7, A543210=2, A64321=1, A210=1, A654320=1                                                                                                                                                                       |                                                                                                                  A6543210=7, A543210=7, A643210=3, A54320=2, A4310=2, A4321=1, A54321=1, A654310=1, A43210=1, A65420=1, A630=1, A6430=1, A0=1, A210=1, A654210=1, A640=1, A653210=1, A53210=1, A54310=1                                                                                                                 |                                                                                                                                                                                            A543210=6, A6543210=3, A65420=1, A643210=1, A654321=1, A640=1                                                                                                                                                                                             |\n",
            "|   L2H0   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                              A60=4, A610=2                                                                                                                                               |     |                                                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                       A63=1, A630=1, A6410=1, A6430=1                                                                                                                                                                                        |                                                                                                                                                                                             A6543210=1                                                                                                                                                                                            |                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   L2H1   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                 A643210=3, A6543210=1, A640=1, A63210=1                                                                                                                                  |     |                                                                                                                                                                                                            A53210=1                                                                                                                                                                                                            |                                                                                                                                                                                    A543210=3, A3210=2, A53210=1, A5431=1                                                                                                                                                                                     |                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   L2H2   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                        A63210=2, A610=1, A6210=1                                                                                                                                         |     |                                                                                                                                                                                             A643210=2, A65420=1, A6410=1, A64210=1                                                                                                                                                                                             |                                                                                                                                                                                         A654320=1, A6310=1, A63210=1                                                                                                                                                                                         |                                                                                                                                                                                              A6210=1                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   L2H3   |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                            A64210=2, A64310=1                                                                                                                                            |     |                                                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                    A30=1                                                                                                                                                                                                     |                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "|   MLP    |                                                                                                      |                                                                                                 |                                                           |                                         |    |                  |                                                                                                                                                                      |                                                                                                                                                                                                                                                                       |    |                                                                                                                                                                                                                                                                 |                                                                             |                                                                                                                                |                                                                                                                                                                                                  |                                                                                                                                                  A60=2                                                                                                                                                   |     |                                                                                                                                                                      A543210=6, A6543210=3, A654321=2, A54320=2, A53210=2, A54210=1, A65321=1, A654210=1                                                                                                                                                                       |                                                                                                                                               A6543210=6, A643210=6, A543210=4, A654210=3, A64310=2, A64321=2, A6430=2, A653210=2, A6432=1, A6431=1, A64320=1                                                                                                                                                |                                                                                     A6543210=5, A64320=4, A20=4, A643210=3, A62=3, A632=3, A543210=2, A6432=2, A210=2, A43210=1, A53210=1, A65420=1, A6210=1, A620=1, A64321=1, A6320=1, A3210=1, A654310=1, A654210=1, A6420=1, A63210=1, A654320=1, A54210=1                                                                                    |                                                                                                                   A64321=6, A643210=6, A6543210=4, A543210=2, A6410=2, A64210=2, A54320=1, A5210=1, A654321=1, A6321=1, A621=1, A6421=1, A631=1, A6310=1, A64310=1, A63210=1                                                                                                                   |                                                                                                                                                                                     A6543210=4, A6421=1, A6410=1, A3210=1, A543210=1                                                                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "+----------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+-----------------------------------------------------------+-----------------------------------------+----+------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "def run_cell_matrices():\n",
        "  global calc_useful_cells\n",
        "\n",
        "  calc_useful_cells = True\n",
        "  calc_cell_matrices(\"Varied questions\", varied_questions, True)\n",
        "  calc_useful_cells = False\n",
        "\n",
        "  print_cell_matrices()\n",
        "\n",
        "\n",
        "run_cell_matrices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1S8LoDMXEC"
      },
      "source": [
        "# Part 17 - Case Analysis\n",
        "Just processing Addition (BA, MC, US9) and Subtraction (BS, B1, C1, CN) questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utqnefc2MYxl"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_cell_matrices(\"BA questions\", make_add_ba_questions(), False)\n",
        "  print_cell_matrices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biUdemo5MZAz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_cell_matrices(\"UC1 questions\", make_add_uc1_questions(), False)\n",
        "  print_cell_matrices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV1zYsCeMarq"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_cell_matrices(\"Simple US9 questions\", make_add_simple_us9_questions(), False)\n",
        "  print_cell_matrices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjLzcox9McGN"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_cell_matrices(\"Cascade US9 questions\", make_add_cascade_us9_questions(), False)\n",
        "  print_cell_matrices()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_cell_matrices(\"Base Sub questions\", make_sub_bs_questions(), False)\n",
        "  print_cell_matrices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CjctKSc7CzC",
        "outputId": "8042b770-3d63-42b8-f1a6-3526c2f0a38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 41 , # failed mlps = 14\n",
            "+----------+----+----+----+-----+----+----+----+----+----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+-----+-----+\n",
            "| Position | P0 | P1 | P2 |  P3 | P4 | P5 | P6 | P7 | P8 |  P9 | P10 | P11 | P12 | P13  | P14 | P15  | P16 | P17 | P18 | P19 | P20 |\n",
            "+----------+----+----+----+-----+----+----+----+----+----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+-----+-----+\n",
            "|   L0H0   |    | 5% | 5% | 11% |    |    |    | 5% |    | 11% |  5% | 21% | 32% |  5%  |     | 16%  | 21% | 21% | 11% | 37% |     |\n",
            "|   L0H1   |    |    |    |     |    |    |    |    |    |     |  5% |  5% |     | 100% |     | 100% | 95% | 79% | 79% | 89% | 74% |\n",
            "|   L0H2   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      | 58% | 32% | 32% | 58% | 11% |\n",
            "|   L0H3   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |  5% | 16% |  5% |     |     |\n",
            "|   MLP    |    |    |    |     |    |    |    |    |    |     |     |  5% | 26% | 21%  |     |      | 79% | 63% | 58% | 79% | 68% |\n",
            "|   L1H0   |    |    |    |     |    |    |    |    |    | 11% |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   L1H1   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      | 37% |  5% |     | 79% | 16% |\n",
            "|   L1H2   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      | 32% | 53% | 47% | 11% |  5% |\n",
            "|   L1H3   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   MLP    |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      | 42% | 26% |  5% |     |     |\n",
            "|   L2H0   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   L2H1   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   L2H2   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   L2H3   |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |     |     |     |     |     |\n",
            "|   MLP    |    |    |    |     |    |    |    |    |    |     |     |     |     |      |     |      |  5% | 26% | 11% |     |     |\n",
            "+----------+----+----+----+-----+----+----+----+----+----+-----+-----+-----+-----+------+-----+------+-----+-----+-----+-----+-----+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+----+-------+-------+-------------+----+----+----+---------+----+------------------+---------+--------------------+------------------+----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------+------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+\n",
            "| Position | P0 |   P1  |   P2  |      P3     | P4 | P5 | P6 |    P7   | P8 |        P9        |   P10   |        P11         |       P12        |                                                P13                                                 | P14 |                                        P15                                        |                                        P16                                         |                                        P17                                        |                                            P18                                            |                                             P19                                             |                                            P20                                            |\n",
            "+----------+----+-------+-------+-------------+----+----+----+---------+----+------------------+---------+--------------------+------------------+----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------+------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+\n",
            "|   L0H0   |    | A64=1 | A64=1 | A64=1, A6=1 |    |    |    | A6421=1 |    | A6421=1, A6432=1 | A6321=1 | A6432=3, A643210=1 | A64321=5, A632=1 |                                             A643210=1                                              |     |                              A64=1, A6410=1, A64321=1                             |                         A64210=1, A6310=1, A6421=1, A643=1                         |                         A6210=1, A643210=1, A6432=1, A62=1                        |                                       A6431=1, A61=1                                      |                         A60=2, A643210=2, A64210=1, A6321=1, A6430=1                        |                                                                                           |\n",
            "|   L0H1   |    |       |       |             |    |    |    |         |    |                  |   A6=1  |      A6310=1       |                  | A643210=4, A6=3, A6321=2, A64321=2, A64310=2, A6421=1, A610=1, A63210=1, A6310=1, A64210=1, A643=1 |     | A643210=5, A64321=4, A64=3, A64310=2, A6421=1, A6410=1, A6310=1, A64210=1, A643=1 |      A643210=4, A64321=3, A63=3, A6310=2, A6321=2, A64310=2, A63210=1, A643=1      | A643210=5, A62=3, A641=1, A6210=1, A6310=1, A64321=1, A64310=1, A64210=1, A6432=1 |     A61=3, A643210=2, A6321=2, A64321=2, A64310=2, A64320=1, A610=1, A6420=1, A6431=1     | A64321=3, A60=3, A63210=3, A643210=2, A64210=1, A610=1, A6310=1, A6431=1, A64310=1, A6430=1 | A6=3, A6321=2, A64321=2, A643210=1, A6421=1, A610=1, A63210=1, A64310=1, A64210=1, A643=1 |\n",
            "|   L0H2   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |           A643210=3, A64321=2, A6321=2, A63=1, A6310=1, A64310=1, A643=1           |                    A643210=2, A6421=1, A62=1, A6321=1, A64210=1                   |                      A643210=2, A6421=1, A6310=1, A64321=1, A64310=1                      |              A63210=3, A643210=2, A64310=2, A64321=1, A64210=1, A610=1, A6310=1             |                                      A610=1, A64310=1                                     |\n",
            "|   L0H3   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                     A643210=1                                      |                             A6210=1, A63210=1, A6321=1                            |                                         A643210=1                                         |                                                                                             |                                                                                           |\n",
            "|   MLP    |    |       |       |             |    |    |    |         |    |                  |         |       A643=1       |     A64321=5     |                                  A6=1, A610=1, A63210=1, A6321=1                                   |     |                                                                                   | A643210=3, A63=3, A6310=2, A64321=2, A64210=1, A63210=1, A6321=1, A64310=1, A643=1 |     A643210=3, A62=2, A63210=2, A6321=1, A631=1, A64321=1, A64310=1, A64210=1     | A643210=2, A64320=1, A642=1, A61=1, A610=1, A63210=1, A6310=1, A632=1, A64321=1, A64310=1 |  A643210=4, A60=2, A63210=2, A64321=1, A610=1, A6321=1, A6310=1, A64310=1, A6431=1, A6421=1 |          A643210=3, A6=2, A6321=2, A64310=2, A63210=1, A6310=1, A64210=1, A643=1          |\n",
            "|   L1H0   |    |       |       |             |    |    |    |         |    |   A63=1, A6=1    |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   L1H1   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                             A64210=3, A63=2, A643210=2                             |                                      A6432=1                                      |                                                                                           |       A64321=3, A60=3, A63210=2, A643210=2, A610=1, A6321=1, A6310=1, A6421=1, A6430=1      |                                   A63210=1, A643=1, A6=1                                  |\n",
            "|   L1H2   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                       A643210=3, A64321=1, A64310=1, A643=1                        |                       A643210=5, A63210=2, A6321=2, A64321=1                      |             A643210=3, A6421=1, A63210=1, A6310=1, A6321=1, A64321=1, A64310=1            |                                     A643210=1, A64210=1                                     |                                          A6310=1                                          |\n",
            "|   L1H3   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   MLP    |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                  A643210=3, A64321=2, A64210=1, A64310=1, A643=1                   |                   A63210=1, A6321=1, A631=1, A64321=1, A64210=1                   |                                          A64321=1                                         |                                                                                             |                                                                                           |\n",
            "|   L2H0   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   L2H1   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   L2H2   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   L2H3   |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                                                                    |                                                                                   |                                                                                           |                                                                                             |                                                                                           |\n",
            "|   MLP    |    |       |       |             |    |    |    |         |    |                  |         |                    |                  |                                                                                                    |     |                                                                                   |                                     A643210=1                                      |                              A62=3, A6210=1, A6432=1                              |                                     A6321=1, A64321=1                                     |                                                                                             |                                                                                           |\n",
            "+----------+----+-------+-------+-------------+----+----+----+---------+----+------------------+---------+--------------------+------------------+----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------+------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_cell_matrices(\"Borrow one questions\", make_sub_b1_questions(), False)\n",
        "  print_cell_matrices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNQvplU87Lkp",
        "outputId": "126a1bb8-6137-4cb0-97c4-f2fb0378557e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 45 , # failed mlps = 15\n",
            "+----------+----+----+----+----+----+----+----+-----+----+----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 | P6 |  P7 | P8 | P9 | P10 | P11 | P12 | P13  | P14 | P15  | P16  | P17  | P18  | P19  | P20  |\n",
            "+----------+----+----+----+----+----+----+----+-----+----+----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "|   L0H0   |    |    |    |    |    |    | 6% | 25% |    | 6% | 12% | 19% | 62% | 50%  |     | 50%  | 56%  | 69%  | 62%  | 75%  |      |\n",
            "|   L0H1   |    |    |    |    |    |    |    |     |    |    |     |  6% |     | 100% |     | 100% | 100% | 100% | 100% | 100% | 100% |\n",
            "|   L0H2   |    |    |    |    |    |    |    |     |    |    |     |  6% |     |      |     |      | 50%  | 38%  | 19%  | 31%  | 19%  |\n",
            "|   L0H3   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      |      | 31%  | 19%  |  6%  |      |\n",
            "|   MLP    |    |    |    |    |    |    |    |     |    |    |     |  6% | 25% | 19%  |     |      | 56%  | 50%  | 38%  | 31%  | 62%  |\n",
            "|   L1H0   |    |    |    |    |    |    |    |     |    | 6% |     |     |     |      |     |      | 12%  | 19%  |      |      |      |\n",
            "|   L1H1   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      | 38%  | 38%  |      | 62%  | 38%  |\n",
            "|   L1H2   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      | 44%  | 44%  | 38%  | 25%  | 25%  |\n",
            "|   L1H3   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |    |     |    |    |  6% |  6% |     |      |     |      |      | 38%  |      |      |      |\n",
            "|   L2H0   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   L2H1   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   L2H2   |    |    |    |    |    |    |    |     |    |    |     |     |     |  6%  |     |  6%  |  6%  |  6%  |      |      |      |\n",
            "|   L2H3   |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |    |     |    |    |     |     |     |      |     |      | 19%  | 25%  | 31%  |  6%  |      |\n",
            "+----------+----+----+----+----+----+----+----+-----+----+----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+----+----+----+----+----+----+----------+----------------------------------------+----+----------+------------------+-------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+-----+----------------------------------------------------------------+---------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 |    P6    |                   P7                   | P8 |    P9    |       P10        |              P11              |                                   P12                                   |                                 P13                                 | P14 |                              P15                               |                                    P16                                    |                             P17                              |                             P18                              |                                   P19                                   |                                 P20                                 |\n",
            "+----------+----+----+----+----+----+----+----------+----------------------------------------+----+----------+------------------+-------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+-----+----------------------------------------------------------------+---------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+\n",
            "|   L0H0   |    |    |    |    |    |    | A64210=1 | A6410=1, A64210=1, A643210=1, A64320=1 |    | A64321=1 | A640=1, A64321=1 | A64320=1, A643210=1, A64210=1 | A64210=2, A6321=2, A640=1, A643210=1, A610=1, A621=1, A6410=1, A64321=1 |          A632=3, A6410=1, A64210=1, A64321=1, A60=1, A610=1         |     |          A6432=3, A6410=2, A64210=1, A64321=1, A640=1          | A643210=2, A64310=1, A6421=1, A630=1, A6310=1, A6321=1, A64321=1, A6432=1 | A632=3, A64210=2, A64321=2, A6410=1, A620=1, A6210=1, A621=1 | A6321=3, A64321=2, A640=1, A610=1, A621=1, A6410=1, A64210=1 |      A6320=3, A64210=2, A643210=2, A6410=2, A60=1, A610=1, A6210=1      |                                                                     |\n",
            "|   L0H1   |    |    |    |    |    |    |          |                                        |    |          |                  |            A64310=1           |                                                                         | A6410=3, A64210=3, A64321=3, A632=3, A60=1, A610=1, A621=1, A6432=1 |     | A6410=4, A6432=4, A64210=3, A64321=2, A640=1, A6421=1, A6321=1 |  A64310=3, A643210=3, A64321=3, A632=3, A630=1, A6310=1, A6321=1, A6432=1 | A64210=6, A64321=3, A632=3, A620=1, A6210=1, A621=1, A6432=1 |     A64321=4, A6410=3, A64210=3, A6321=3, A610=2, A621=1     | A6410=3, A64210=3, A643210=3, A6320=3, A60=1, A610=1, A6210=1, A64320=1 | A6410=3, A64210=3, A64321=3, A632=3, A60=1, A610=1, A621=1, A6432=1 |\n",
            "|   L0H2   |    |    |    |    |    |    |          |                                        |    |          |                  |            A6410=1            |                                                                         |                                                                     |     |                                                                |               A64310=2, A643210=2, A64321=2, A632=1, A6432=1              |                  A64210=4, A64321=1, A632=1                  |                  A6410=1, A64321=1, A6321=1                  |                  A643210=2, A64210=1, A6320=1, A64320=1                 |                          A6410=2, A64210=1                          |\n",
            "|   L0H3   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                                                                           |               A64321=2, A63=1, A620=1, A6210=1               |                  A6432=1, A610=1, A64210=1                   |                                 A6421=1                                 |                                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |          |                                        |    |          |                  |            A64310=1           |                        A6321=2, A621=1, A64321=1                        |                        A60=1, A610=1, A621=1                        |     |                                                                |       A632=3, A630=1, A6310=1, A6321=1, A643210=1, A64321=1, A642=1       |         A632=3, A64321=2, A64210=1, A6210=1, A621=1          |             A64210=2, A6321=2, A64321=1, A6420=1             |                    A64210=2, A610=1, A6210=1, A6410=1                   |     A632=2, A64210=2, A64321=2, A6410=1, A610=1, A621=1, A6432=1    |\n",
            "|   L1H0   |    |    |    |    |    |    |          |                                        |    |  A630=1  |                  |                               |                                                                         |                                                                     |     |                                                                |                              A632=1, A6432=1                              |                       A64321=2, A621=1                       |                                                              |                                                                         |                                                                     |\n",
            "|   L1H1   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                        A643210=3, A6421=2, A64310=1                       |              A6410=2, A632=2, A6210=1, A64210=1              |                                                              |         A64210=3, A6320=2, A643210=2, A610=1, A6210=1, A64320=1         |              A632=2, A610=1, A621=1, A64210=1, A64321=1             |\n",
            "|   L1H2   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                   A632=3, A64321=2, A64310=1, A643210=1                   |                  A64210=4, A64321=2, A621=1                  |              A6410=2, A64210=2, A6321=1, A610=1              |                         A6410=2, A60=1, A64210=1                        |                       A6410=2, A60=1, A64321=1                      |\n",
            "|   L1H3   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                                                                           |                                                              |                                                              |                                                                         |                                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |          |                                        |    |          |     A6421=1      |           A643210=1           |                                                                         |                                                                     |     |                                                                |                                                                           |          A64210=2, A632=1, A621=1, A64321=1, A643=1          |                                                              |                                                                         |                                                                     |\n",
            "|   L2H0   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                                                                           |                                                              |                                                              |                                                                         |                                                                     |\n",
            "|   L2H1   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                                                                           |                                                              |                                                              |                                                                         |                                                                     |\n",
            "|   L2H2   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                A610=1                               |     |                            A6410=1                             |                                  A6310=1                                  |                           A6210=1                            |                                                              |                                                                         |                                                                     |\n",
            "|   L2H3   |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                                                                           |                                                              |                                                              |                                                                         |                                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |          |                                        |    |          |                  |                               |                                                                         |                                                                     |     |                                                                |                        A643210=1, A64321=1, A6432=1                       |                   A632=2, A620=1, A64321=1                   |             A64321=2, A621=1, A6410=1, A64210=1              |                                 A6410=1                                 |                                                                     |\n",
            "+----------+----+----+----+----+----+----+----------+----------------------------------------+----+----------+------------------+-------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+-----+----------------------------------------------------------------+---------------------------------------------------------------------------+--------------------------------------------------------------+--------------------------------------------------------------+-------------------------------------------------------------------------+---------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_cell_matrices(\"Sub Cascade 1 questions\", make_sub_c1_questions(), False)\n",
        "  print_cell_matrices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL53nb9i7Ln6",
        "outputId": "4af81c28-401f-425a-90b0-67ff37acccbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 45 , # failed mlps = 15\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 |  P6 |  P7 | P8 |  P9 | P10 | P11 | P12 | P13  | P14 | P15  | P16  | P17  | P18  | P19  | P20  |\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "|   L0H0   |    |    |    |    |    |    | 33% | 25% |    | 33% |  8% | 25% | 58% | 33%  |     | 33%  | 42%  | 33%  | 33%  | 67%  |      |\n",
            "|   L0H1   |    |    |    |    |    |    |     |     |    |     |     | 17% |     | 100% |     | 100% | 100% | 100% | 100% | 100% | 100% |\n",
            "|   L0H2   |    |    |    |    |    |    |     |     |    |     |     |  8% |  8% |      |     |      | 58%  | 33%  | 17%  | 25%  | 25%  |\n",
            "|   L0H3   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      |      | 33%  |  8%  |  8%  |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |     | 17% | 25% | 17%  |     |      | 42%  | 25%  | 42%  | 67%  | 58%  |\n",
            "|   L1H0   |    |    |    |    |    |    |     |     |    |     |     |  8% |     |      |     |      |      | 33%  |  8%  |      |      |\n",
            "|   L1H1   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      | 50%  | 33%  |      | 58%  | 33%  |\n",
            "|   L1H2   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      | 33%  | 33%  | 17%  |  8%  | 25%  |\n",
            "|   L1H3   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |  8% | 42% | 67% |      |     |      |      |  8%  |      |      |      |\n",
            "|   L2H0   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   L2H1   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   L2H2   |    |    |    |    |    |    |     |     |    |     |     |     |     | 17%  |     | 17%  |  8%  |      |      |      |      |\n",
            "|   L2H3   |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |     |     |     |      |     |      | 17%  | 17%  | 50%  |      |      |\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+------+-----+------+------+------+------+------+------+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+----+----+----+----+----+----+--------------------------------------+------------------------------+----+---------------------------------------+-----------+-----------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------+-------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 |                  P6                  |              P7              | P8 |                   P9                  |    P10    |                      P11                      |                           P12                           |                                         P13                                          | P14 |                                P15                                 |                                P16                                |                                     P17                                     |                                    P18                                     |                                 P19                                 |                                         P20                                          |\n",
            "+----------+----+----+----+----+----+----+--------------------------------------+------------------------------+----+---------------------------------------+-----------+-----------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------+-------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n",
            "|   L0H0   |    |    |    |    |    |    | A6421=1, A643210=1, A620=1, A64210=1 | A64210=1, A64320=1, A64310=1 |    | A64320=1, A6321=1, A6310=1, A643210=1 |  A6431=1  |           A6421=1, A64321=1, A6431=1          |          A643210=3, A64321=2, A6310=1, A6421=1          |                          A6421=1, A64320=1, A631=1, A6210=1                          |     |                A6421=1, A64320=1, A6431=1, A64210=1                |          A64321=1, A6420=1, A63210=1, A643210=1, A64210=1         |                     A641=1, A6410=1, A64320=1, A64321=1                     |                        A64321=2, A631=1, A643210=1                         |           A643210=3, A64210=2, A64320=1, A6310=1, A63210=1          |                                                                                      |\n",
            "|   L0H1   |    |    |    |    |    |    |                                      |                              |    |                                       |           |               A643210=1, A6431=1              |                                                         | A6421=2, A64320=2, A64321=2, A631=1, A6210=1, A63210=1, A64210=1, A643210=1, A6431=1 |     | A6421=2, A6431=2, A64210=2, A643210=2, A64321=2, A64320=1, A6320=1 | A64321=4, A64320=2, A643210=2, A631=1, A63210=1, A6210=1, A6431=1 | A64321=3, A6421=2, A64320=2, A6321=1, A610=1, A63210=1, A64210=1, A643210=1 | A643210=3, A6421=2, A64321=2, A631=1, A6210=1, A63210=1, A64210=1, A6431=1 | A64210=3, A643210=3, A64320=2, A6310=1, A6210=1, A63210=1, A64310=1 | A6421=2, A64320=2, A64321=2, A631=1, A6210=1, A63210=1, A64210=1, A643210=1, A6431=1 |\n",
            "|   L0H2   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                    A64210=1                   |                         A6421=1                         |                                                                                      |     |                                                                    |                A64321=3, A64320=2, A631=1, A6431=1                |                         A6421=2, A64320=1, A63210=1                         |                              A631=1, A6210=1                               |                     A64320=1, A6310=1, A64310=1                     |                                  A6421=2, A643210=1                                  |\n",
            "|   L0H3   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                                                                   |                          A64321=2, A6321=1, A6310=1                         |                                 A643210=1                                  |                               A6432=1                               |                                                                                      |\n",
            "|   MLP    |    |    |    |    |    |    |                                      |                              |    |                                       |           |               A643210=1, A6431=1              |                    A64321=2, A6421=1                    |                                  A6210=1, A63210=1                                   |     |                                                                    |                A63210=2, A631=1, A64320=1, A6431=1                |                          A6421=1, A6430=1, A63210=1                         |               A6421=1, A631=1, A6210=1, A63210=1, A643210=1                |      A64210=2, A643210=2, A64320=1, A6310=1, A6210=1, A63210=1      |              A64321=2, A6421=1, A63210=1, A643210=1, A64320=1, A6431=1               |\n",
            "|   L1H0   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                    A6431=1                    |                                                         |                                                                                      |     |                                                                    |                                                                   |                    A64320=1, A6321=1, A6310=1, A643210=1                    |                                   A620=1                                   |                                                                     |                                                                                      |\n",
            "|   L1H1   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |               A64321=2, A6420=2, A643210=1, A64210=1              |                           A641=2, A6210=1, A6410=1                          |                                                                            |               A643210=3, A64320=2, A63210=1, A64310=1               |                            A64321=2, A63210=1, A643210=1                             |\n",
            "|   L1H2   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                    A643210=2, A631=1, A64321=1                    |                    A6421=1, A64320=1, A64210=1, A643210=1                   |                             A6421=1, A64210=1                              |                               A64320=1                              |                              A6210=1, A64210=1, A6421=1                              |\n",
            "|   L1H3   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                                                                   |                                                                             |                                                                            |                                                                     |                                                                                      |\n",
            "|   MLP    |    |    |    |    |    |    |                                      |                              |    |                                       | A643210=1 | A631=1, A643210=1, A6421=1, A64321=1, A6431=1 | A6421=2, A64320=2, A620=1, A6310=1, A64210=1, A643210=1 |                                                                                      |     |                                                                    |                                                                   |                                   A6421=1                                   |                                                                            |                                                                     |                                                                                      |\n",
            "|   L2H0   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                                                                   |                                                                             |                                                                            |                                                                     |                                                                                      |\n",
            "|   L2H1   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                                                                   |                                                                             |                                                                            |                                                                     |                                                                                      |\n",
            "|   L2H2   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                  A6210=1, A63210=1                                   |     |                        A64210=1, A643210=1                         |                              A63210=1                             |                                                                             |                                                                            |                                                                     |                                                                                      |\n",
            "|   L2H3   |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                                                                   |                                                                             |                                                                            |                                                                     |                                                                                      |\n",
            "|   MLP    |    |    |    |    |    |    |                                      |                              |    |                                       |           |                                               |                                                         |                                                                                      |     |                                                                    |                         A64321=1, A6431=1                         |                             A643210=1, A64320=1                             |                   A643210=2, A64321=2, A64210=1, A6421=1                   |                                                                     |                                                                                      |\n",
            "+----------+----+----+----+----+----+----+--------------------------------------+------------------------------+----+---------------------------------------+-----------+-----------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------+-------------------------------------------------------------------+-----------------------------------------------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------+--------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_cell_matrices(\"Sub Cascade N questions\", make_sub_cn_questions(), False)\n",
        "  print_cell_matrices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTowAUvI7LrI",
        "outputId": "2de3dd65-c182-4247-e6f6-c984d0a75b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 35 , # failed mlps = 11\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 |  P6 |  P7 | P8 |  P9 | P10 | P11 | P12  | P13  | P14 | P15  | P16  | P17  | P18  | P19  | P20  |\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+\n",
            "|   L0H0   |    |    |    |    |    |    | 50% | 25% |    | 75% |     | 12% | 62%  | 25%  |     | 25%  | 12%  | 25%  | 12%  | 62%  |      |\n",
            "|   L0H1   |    |    |    |    |    |    |     |     |    |     |     |     |      | 100% |     | 100% | 100% | 100% | 100% | 100% | 100% |\n",
            "|   L0H2   |    |    |    |    |    |    |     |     |    |     |     |     | 12%  |      |     |      | 75%  |      |      | 12%  | 38%  |\n",
            "|   L0H3   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      | 12%  | 25%  | 12%  |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |     |     | 12%  |      |     |      | 50%  | 12%  | 12%  | 62%  | 50%  |\n",
            "|   L1H0   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      | 62%  |      |      |      |\n",
            "|   L1H1   |    |    |    |    |    |    |     |     |    |     |     |     | 12%  |      |     |      | 25%  |      |      | 50%  | 25%  |\n",
            "|   L1H2   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      | 50%  | 12%  |      | 25%  | 38%  |\n",
            "|   L1H3   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |     |     | 100% |      |     |      |      |      |      | 25%  |      |\n",
            "|   L2H0   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      | 50%  |      |      |      |      |\n",
            "|   L2H1   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      |      |      |      |      |\n",
            "|   L2H2   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      |      |      |      |      |\n",
            "|   L2H3   |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      |      |      |      |      |      |\n",
            "|   MLP    |    |    |    |    |    |    |     |     |    |     |     |     |      |      |     |      | 38%  | 88%  | 75%  |      |      |\n",
            "+----------+----+----+----+----+----+----+-----+-----+----+-----+-----+-----+------+------+-----+------+------+------+------+------+------+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+----+----+----+----+----+----+----------------------------------------+-----------------+----+---------------------------------------------------------+-----+---------+-------------------------------------------------------------------+-----------------------------------------------------+-----+----------------------------------------------+--------------------------------------------------------------+-----------------------------------------------+------------------------------------------------+-------------------------------------+-----------------------------------------------------+\n",
            "| Position | P0 | P1 | P2 | P3 | P4 | P5 |                   P6                   |        P7       | P8 |                            P9                           | P10 |   P11   |                                P12                                |                         P13                         | P14 |                     P15                      |                             P16                              |                      P17                      |                      P18                       |                 P19                 |                         P20                         |\n",
            "+----------+----+----+----+----+----+----+----------------------------------------+-----------------+----+---------------------------------------------------------+-----+---------+-------------------------------------------------------------------+-----------------------------------------------------+-----+----------------------------------------------+--------------------------------------------------------------+-----------------------------------------------+------------------------------------------------+-------------------------------------+-----------------------------------------------------+\n",
            "|   L0H0   |    |    |    |    |    |    | A6321=1, A63210=1, A64310=1, A643210=1 | A630=1, A6430=1 |    | A632=1, A6320=1, A6430=1, A64210=1, A64320=1, A643210=1 |     | A6430=1 |         A63210=1, A64210=1, A643210=1, A64321=1, A64320=1         |                    A63=1, A630=1                    |     |               A643=1, A6430=1                |                           A6420=1                            |               A6432=1, A64320=1               |                    A64310=1                    |      A64310=2, A64320=2, A630=1     |                                                     |\n",
            "|   L0H1   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   | A64320=2, A64310=2, A63=1, A630=1, A6432=1, A6430=1 |     | A6430=2, A64320=2, A64310=2, A643=1, A6432=1 | A64310=2, A63=1, A630=1, A6420=1, A64320=1, A6432=1, A6430=1 | A64320=3, A643210=2, A632=1, A6320=1, A6432=1 | A64310=3, A643210=2, A631=1, A6310=1, A64321=1 | A64320=3, A630=2, A64310=2, A6430=1 | A64320=2, A64310=2, A63=1, A630=1, A6432=1, A6430=1 |\n",
            "|   L0H2   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                               A63=1                               |                                                     |     |                                              |     A63=1, A630=1, A64320=1, A64310=1, A6432=1, A6430=1      |                                               |                                                |                A630=1               |                A63=1, A630=1, A6432=1               |\n",
            "|   L0H3   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |                    A6430=1                    |                    A64310=2                    |                A63=1                |                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                              A64321=1                             |                                                     |     |                                              |               A63=1, A630=1, A6432=1, A6430=1                |                    A64320=1                   |                    A64321=1                    |      A64320=2, A64310=2, A630=1     |               A64310=2, A63=1, A6430=1              |\n",
            "|   L1H0   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |      A643210=2, A632=1, A6430=1, A64320=1     |                                                |                                     |                                                     |\n",
            "|   L1H1   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                              A6430=1                              |                                                     |     |                                              |                       A6420=1, A642=1                        |                                               |                                                |      A64310=2, A630=1, A6430=1      |                       A64310=2                      |\n",
            "|   L1H2   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |              A63=1, A630=1, A64320=1, A64310=1               |                    A64320=1                   |                                                |          A64310=1, A6430=1          |                  A64320=2, A6432=1                  |\n",
            "|   L1H3   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |                                               |                                                |                                     |                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         | A6430=2, A632=1, A6320=1, A64210=1, A64320=1, A643210=1, A64321=1 |                                                     |     |                                              |                                                              |                                               |                                                |           A630=1, A6430=1           |                                                     |\n",
            "|   L2H0   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |               A63=1, A630=1, A6410=1, A6430=1                |                                               |                                                |                                     |                                                     |\n",
            "|   L2H1   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |                                               |                                                |                                     |                                                     |\n",
            "|   L2H2   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |                                               |                                                |                                     |                                                     |\n",
            "|   L2H3   |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                                                              |                                               |                                                |                                     |                                                     |\n",
            "|   MLP    |    |    |    |    |    |    |                                        |                 |    |                                                         |     |         |                                                                   |                                                     |     |                                              |                 A64320=1, A64310=1, A6430=1                  | A64320=3, A632=1, A6320=1, A643210=1, A6432=1 | A643210=2, A631=1, A6310=1, A64321=1, A64310=1 |                                     |                                                     |\n",
            "+----------+----+----+----+----+----+----+----------------------------------------+-----------------+----+---------------------------------------------------------+-----+---------+-------------------------------------------------------------------+-----------------------------------------------------+-----+----------------------------------------------+--------------------------------------------------------------+-----------------------------------------------+------------------------------------------------+-------------------------------------+-----------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_cell_matrices(\"Sub Neg questions\", make_sub_neg_questions(), False)\n",
        "  print_cell_matrices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZBuAuVa7Luu",
        "outputId": "cb4e3ca0-4a4e-4d38-d4a5-ef09dbcf45cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 100 %Add= 0 ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed129000_train45K\n",
            "\n",
            "The % failure rate when each head or MLP in each position is ablated, # failed heads = 55 , # failed mlps = 19\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+------+------+------+-----+-----+-----+\n",
            "| Position |  P0 | P1 | P2 | P3 | P4 | P5 |  P6 |  P7 | P8 |  P9 | P10 | P11 | P12 | P13 | P14 | P15  | P16  | P17  | P18 | P19 | P20 |\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+------+------+------+-----+-----+-----+\n",
            "|   L0H0   |  8% | 8% | 8% |    |    |    | 38% | 69% |    | 46% | 23% | 31% | 23% | 15% |     |  8%  | 23%  | 23%  |  8% | 15% | 54% |\n",
            "|   L0H1   | 15% |    |    |    |    |    |     |     |    |  8% | 62% | 23% |     |     |     | 100% | 100% | 100% | 92% | 92% | 92% |\n",
            "|   L0H2   |     |    |    |    |    |    |     |     |    |     | 46% |     |     |     |     |      | 23%  | 31%  | 54% | 38% | 38% |\n",
            "|   L0H3   |     |    |    |    |    |    |     |     |    |  8% |     |     |     |     |     | 54%  | 100% | 69%  | 77% | 69% |     |\n",
            "|   MLP    | 23% |    |    |    |    |    | 15% |     |    | 15% | 38% |  8% | 15% |     |     |      | 69%  |  8%  | 46% | 46% | 54% |\n",
            "|   L1H0   |     |    |    |    |    |    |     |     |    |     |     |     |     |  8% |     |      |      |      |     | 15% |  8% |\n",
            "|   L1H1   |     |    |    |    |    |    | 23% |     |    | 23% | 31% | 15% | 15% |     |     |      |      |      |     | 15% |     |\n",
            "|   L1H2   |     |    |    |    |    |    |     |     |    |     |     |     |     |     |     |      |  8%  |  8%  | 15% |     | 46% |\n",
            "|   L1H3   |     |    |    |    |    |    |     |     |    |     |     |     |     |  8% |     |      |      |      |     |     |     |\n",
            "|   MLP    |     |    |    |    |    |    |     |     |    |     |     | 23% | 38% |     |     |      |      | 15%  |  8% | 15% |     |\n",
            "|   L2H0   |     |    |    |    |    |    |     |     |    |     |     |     |     | 46% |     |      |      |      |     |     |     |\n",
            "|   L2H1   |     |    |    |    |    |    |     |     |    |     |     |     |     |     |     |      | 15%  |      |     |     |     |\n",
            "|   L2H2   |     |    |    |    |    |    |     |     |    |     |     |     |     |     |     |      |      |      |     |     |     |\n",
            "|   L2H3   |     |    |    |    |    |    |     |     |    |     |     |     |     |     |     |      |  8%  |      |     |     |     |\n",
            "|   MLP    |     |    |    |    |    |    |     |     |    |     |     |     |     | 15% |     |      |      | 54%  |     |  8% |     |\n",
            "+----------+-----+----+----+----+----+----+-----+-----+----+-----+-----+-----+-----+-----+-----+------+------+------+-----+-----+-----+\n",
            "\n",
            "The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\n",
            "+----------+----------------+----------+----------+----+----+----+-----------------------------------+-----------------------------------+----+---------------------------------------+-----------------------------+----------------------------------------+-------------------+---------------+-----+--------------------------------------------------+--------------------------------+---------------------------------------+---------------------------------------+-------------------------------------+--------------------------------------------+\n",
            "| Position |       P0       |    P1    |    P2    | P3 | P4 | P5 |                 P6                |                 P7                | P8 |                   P9                  |             P10             |                  P11                   |        P12        |      P13      | P14 |                       P15                        |              P16               |                  P17                  |                  P18                  |                 P19                 |                    P20                     |\n",
            "+----------+----------------+----------+----------+----+----+----+-----------------------------------+-----------------------------------+----+---------------------------------------+-----------------------------+----------------------------------------+-------------------+---------------+-----+--------------------------------------------------+--------------------------------+---------------------------------------+---------------------------------------+-------------------------------------+--------------------------------------------+\n",
            "|   L0H0   |     A60=1      | A63210=1 | A63210=1 |    |    |    | A2=2, A43210=1, A643210=1, A210=1 | A210=3, A0=2, A1=2, A3210=1, A3=1 |    | A64320=2, A621=2, A643210=1, A63210=1 | A6430=1, A64310=1, A64321=1 | A64320=1, A643210=1, A64321=1, A6321=1 |  A63210=2, A610=1 | A60=1, A630=1 |     |                      A430=1                      |     A30=1, A310=1, A321=1      |          A20=1, A210=1, A21=1         |                 A210=1                |             A0=1, A210=1            |            A0=4, A210=2, A30=1             |\n",
            "|   L0H1   |     A60=2      |          |          |    |    |    |                                   |                                   |    |                 A630=1                |    A60=4, A610=2, A621=2    |                 A621=3                 |                   |               |     | A40=4, A421=3, A410=2, A4210=2, A43210=1, A430=1 | A30=5, A321=3, A3210=3, A310=2 | A20=4, A210=4, A21=3, A3210=1, A320=1 | A10=6, A21=3, A210=1, A3210=1, A310=1 |  A0=4, A210=4, A10=2, A321=1, A30=1 | A0=4, A21=3, A10=2, A210=1, A3210=1, A30=1 |\n",
            "|   L0H2   |                |          |          |    |    |    |                                   |                                   |    |                                       |    A60=3, A610=2, A621=1    |                                        |                   |               |     |                                                  |     A30=1, A310=1, A321=1      |      A20=1, A210=1, A21=1, A320=1     |     A10=2, A21=2, A210=2, A3210=1     |      A210=2, A0=1, A10=1, A30=1     |            A0=2, A210=2, A21=1             |\n",
            "|   L0H3   |                |          |          |    |    |    |                                   |                                   |    |                 A630=1                |                             |                                        |                   |               |     |          A410=2, A421=2, A4210=2, A40=1          | A30=5, A321=3, A3210=3, A310=2 |     A20=4, A210=3, A3210=1, A320=1    | A10=3, A21=3, A210=2, A3210=1, A310=1 | A0=3, A10=2, A210=2, A3210=1, A30=1 |                                            |\n",
            "|   MLP    | A60=2, A6210=1 |          |          |    |    |    |           A210=1, A60=1           |                                   |    |                A64320=2               |    A60=3, A610=1, A621=1    |                 A621=1                 |   A6210=1, A2=1   |               |     |                                                  | A30=5, A310=2, A321=1, A3210=1 |                A3210=1                |     A2=2, A210=2, A3210=1, A310=1     |     A210=3, A1=1, A3210=1, A30=1    |    A0=3, A210=1, A21=1, A3210=1, A30=1     |\n",
            "|   L1H0   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |    A63210=1   |     |                                                  |                                |                                       |                                       |             A1=1, A210=1            |                    A0=1                    |\n",
            "|   L1H1   |                |          |          |    |    |    |       A4320=1, A310=1, A30=1      |                                   |    |            A320=2, A3210=1            |    A60=2, A6210=1, A621=1   |                A6430=2                 | A43210=1, A6320=1 |               |     |                                                  |                                |                                       |                                       |              A0=1, A3=1             |                                            |\n",
            "|   L1H2   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |               |     |                                                  |             A30=1              |                 A320=1                |             A21=1, A310=1             |                                     |            A0=4, A210=1, A30=1             |\n",
            "|   L1H3   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |     A60=1     |     |                                                  |                                |                                       |                                       |                                     |                                            |\n",
            "|   MLP    |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                 A621=3                 |   A60=3, A610=2   |               |     |                                                  |                                |                 A210=2                |                 A210=1                |             A0=1, A210=1            |                                            |\n",
            "|   L2H0   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   | A60=4, A610=2 |     |                                                  |                                |                                       |                                       |                                     |                                            |\n",
            "|   L2H1   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |               |     |                                                  |            A3210=2             |                                       |                                       |                                     |                                            |\n",
            "|   L2H2   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |               |     |                                                  |                                |                                       |                                       |                                     |                                            |\n",
            "|   L2H3   |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |               |     |                                                  |             A30=1              |                                       |                                       |                                     |                                            |\n",
            "|   MLP    |                |          |          |    |    |    |                                   |                                   |    |                                       |                             |                                        |                   |     A60=2     |     |                                                  |                                |         A20=4, A210=2, A3210=1        |                                       |               A3210=1               |                                            |\n",
            "+----------+----------------+----------+----------+----+----+----+-----------------------------------+-----------------------------------+----+---------------------------------------+-----------------------------+----------------------------------------+-------------------+---------------+-----+--------------------------------------------------+--------------------------------+---------------------------------------+---------------------------------------+-------------------------------------+--------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSY3blNMe7I"
      },
      "source": [
        "#Part 18: SetUp: Calc and graph PCA decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiBsiQAMhS_"
      },
      "outputs": [],
      "source": [
        "tn_questions = 100\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up from 0 to 8\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t8_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(0, 8)\n",
        "        y = random.randint(0, 8-x)\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions, PLUS_INDEX)\n",
        "\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up to 9\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t9_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(0, 9)\n",
        "        y = 9 - x\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions, PLUS_INDEX)\n",
        "\n",
        "\n",
        "# These are n_digit addition questions where the first test_digits add up to 10 to 18\n",
        "# Randomise the last test_digits-1 digits of both numbers\n",
        "def make_t10_questions(test_digit):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "        x = random.randint(1, 9)\n",
        "        y = random.randint(10-x, 9)\n",
        "        x = x * limit + random.randint(0, limit-1)\n",
        "        y = y * limit + random.randint(0, limit-1)\n",
        "        questions.append([x, y])\n",
        "    return make_questions(questions, PLUS_INDEX)\n",
        "\n",
        "\n",
        "def make_tricase_questions(test_digit):\n",
        "  q1 = make_t8_questions(test_digit)\n",
        "  q2 = make_t9_questions(test_digit)\n",
        "  q3 = make_t10_questions(test_digit)\n",
        "\n",
        "  questions = torch.vstack((q1, q2, q3))\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCPgoQZMjgc"
      },
      "outputs": [],
      "source": [
        "# Do one Principal Component Analysis\n",
        "def calc_tricase_pca(t_position, t_layer, t_head, t_digit):\n",
        "  global tn_questions\n",
        "\n",
        "  t_questions = make_tricase_questions(t_digit)\n",
        "  #print('Sample t8 question:', t_questions[0].tolist())\n",
        "  #print('Sample t9 question:', t_questions[tn_questions].tolist())\n",
        "  #print('Sample t10 question:', t_questions[2*tn_questions].tolist())\n",
        "\n",
        "  t_logits, t_cache = main_model.run_with_cache(t_questions)\n",
        "\n",
        "  # Gather attention patterns for all the (randomly chosen) questions\n",
        "  attention_outputs = []\n",
        "  for i in range(len(t_questions)):\n",
        "\n",
        "    # Output of individual heads, without final bias\n",
        "    attention_cache=t_cache[\"result\", t_layer, \"attn\"] # Output of individual heads, without final bias\n",
        "    attention_output=attention_cache[i]  # Shape [n_ctx, n_head, d_model]\n",
        "    attention_outputs.append(attention_output[t_position, t_head, :])\n",
        "\n",
        "  attn_outputs = torch.stack(attention_outputs, dim=0).cpu()\n",
        "\n",
        "  pca = PCA(n_components=6)\n",
        "  pca.fit(attn_outputs)\n",
        "  pca_attn_outputs = pca.transform(attn_outputs)\n",
        "\n",
        "  title = 'P' + str(t_position) + '.L' + str(t_layer) + '.H'+str(t_head) + ', A'+str(t_digit)\n",
        "\n",
        "  return (pca, pca_attn_outputs, title)\n",
        "\n",
        "\n",
        "# Plot one PCA scatter graph\n",
        "def graph_pca(pca, pca_attn_outputs, ax, title):\n",
        "  global tn_questions\n",
        "\n",
        "  ax.scatter(pca_attn_outputs[:tn_questions, 0], pca_attn_outputs[:tn_questions, 1], color='red', label='T8 (0-8)') # t8 questions\n",
        "  ax.scatter(pca_attn_outputs[tn_questions:2*tn_questions, 0], pca_attn_outputs[tn_questions:2*tn_questions, 1], color='green', label='T9') # t9 questions\n",
        "  ax.scatter(pca_attn_outputs[2*tn_questions:, 0], pca_attn_outputs[2*tn_questions:, 1], color='blue', label='T10 (10-18)') # t10 questions\n",
        "\n",
        "  if title != \"\" :\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2K3y7pMlQr"
      },
      "outputs": [],
      "source": [
        "# Graph the PCA of Pasn.Ln.Hn's attention pattern, using T8, T9, T10 questions that differ in the An digit\n",
        "def add_one_pca_subplot(ax, t_position, t_layer, t_head, t_digit):\n",
        "  pca, pca_attn_outputs, title = calc_tricase_pca(t_position, t_layer, t_head, t_digit)\n",
        "  graph_pca( pca, pca_attn_outputs, ax, title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEF7MQqCMngv"
      },
      "outputs": [],
      "source": [
        "def save_plt_to_file( full_title ):\n",
        "  if cfg.save_graph_to_file:\n",
        "    filename = full_title.replace(\" \", \"_\").replace(\",\", \"\").replace(\":\", \"_\")  + '.png'\n",
        "    plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "#Part 19: PCA decomposition tri-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"tri-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "if cfg.n_digits == 5 and cfg.n_layers == 2 and use_pca :\n",
        "\n",
        "  # graph all useful early cells\n",
        "  fig, axs = plt.subplots(4, 2)\n",
        "  fig.set_figheight(8)\n",
        "  fig.set_figwidth(5)\n",
        "\n",
        "  # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "  add_one_pca_subplot(axs[0, 0], 8, 0, 1, 2)    # S8.L0.H1 is clear only for A2\n",
        "  add_one_pca_subplot(axs[0, 1], 9, 0, 1, 1)    # S9.L0.H1 is clear only for A1\n",
        "  add_one_pca_subplot(axs[1, 0], 11, 0, 1, 3)   # S11.L0.H1 is clear only for A3\n",
        "  add_one_pca_subplot(axs[1, 1], 11, 0, 2, 4)   # S11.L0.H2 is clear only for A4\n",
        "  add_one_pca_subplot(axs[2, 0], 12, 0, 1, 3)   # S12.L0.H1 is clear only for A3\n",
        "  add_one_pca_subplot(axs[2, 1], 13, 0, 1, 2)   # S13.L0.H1 is clear only for A2\n",
        "  add_one_pca_subplot(axs[3, 0], 14, 0, 1, 1)   # S14.L0.H1 is clear only for A1\n",
        "\n",
        "  lines_labels = [axs[0,0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Trigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3611cpuEFhoW"
      },
      "source": [
        "#Part 19B: PCA decomposition bi-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"bi-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAT8Z54oMuur"
      },
      "outputs": [],
      "source": [
        "if cfg.n_digits == 5 and cfg.n_layers == 2 and use_pca :\n",
        "\n",
        "  # graph all useful early cells\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  fig.set_figheight(2)\n",
        "  fig.set_figwidth(5)\n",
        "\n",
        "  # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "  add_one_pca_subplot(axs[0], 10, 0, 1, 0)   # S10.L0.H1 is clear only for A0\n",
        "  add_one_pca_subplot(axs[1], 15, 0, 1, 0)   # S15.L0.H1 is clear only for A0\n",
        "\n",
        "  lines_labels = [axs[0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Bigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQhbJTFTMwU_"
      },
      "outputs": [],
      "source": [
        "# Do one Principal Component Analysis and graph it\n",
        "def run_one_tricase_pca(t_position, t_layer, t_head, t_digit):\n",
        "\n",
        "  pca, pca_attn_outputs, title = calc_tricase_pca(t_position, t_layer, t_head, t_digit)\n",
        "\n",
        "  # Plot the PCA results\n",
        "  fig, ax = plt.subplots()\n",
        "  graph_pca(pca, pca_attn_outputs, ax, \"\")\n",
        "\n",
        "  full_title = 'PCA of attention: n_digits=' + str(cfg.n_digits) + ', ' + title\n",
        "  plt.title(full_title + ', EVR[0]=' + str(round(pca.explained_variance_ratio_[0],3)) )\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file(full_title)\n",
        "  plt.show()\n",
        "\n",
        "  print( \"First few principal components explain variance of:\", pca.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "#Part 19C: PCA decomposition of useful cells with digits 0 to 4\n",
        "\n",
        "Parts 19A and 19B are selective. This part is not. Use it to find (verify) the interesting parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfpkXmAMzg4"
      },
      "outputs": [],
      "source": [
        "def graph_all_pca_results():\n",
        "\n",
        "  for useful_cell in useful_cells:\n",
        "    if useful_cell.is_head:\n",
        "      position = useful_cell.position\n",
        "      layer = useful_cell.layer\n",
        "      head = useful_cell.head\n",
        "      print( \"PCA: position=\", position, \"layer=\", layer, \"head=\", head)\n",
        "\n",
        "      fig, axs = plt.subplots(3, 2)\n",
        "\n",
        "      add_one_pca_subplot(axs[0, 0], position, layer, head, 0)\n",
        "      add_one_pca_subplot(axs[0, 1], position, layer, head, 1)\n",
        "      add_one_pca_subplot(axs[1, 0], position, layer, head, 2)\n",
        "      add_one_pca_subplot(axs[1, 1], position, layer, head, 3)\n",
        "      add_one_pca_subplot(axs[2, 0], position, layer, head, 4)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "if use_pca :\n",
        "  graph_all_pca_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 21A : Set Up Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (causual abstraction) to the model attention heads.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgCog0mYkYPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class A_Config():\n",
        "  token_position : int  # The token position we want to get/set. P8 to P11 contribute to A5 calculations\n",
        "  layer : int # The layer we want to get/set\n",
        "  heads = [] # The heads we want to get/set\n",
        "  threshold : int\n",
        "  hook_calls : int\n",
        "  answer_failures : int   # Failures of any digit\n",
        "\n",
        "  questions = []\n",
        "  store = []\n",
        "  null_hooks = []\n",
        "  get_hooks = []\n",
        "  put_hooks = []\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.token_position = 10\n",
        "    self.layer = 0\n",
        "    self.heads = []\n",
        "    self.threshold = 0.00001\n",
        "    self.hook_calls = 0\n",
        "    self.answer_failures = 0\n",
        "    self.questions = []\n",
        "    self.store = []\n",
        "    self.null_hooks = []\n",
        "    self.get_hooks = []\n",
        "    self.put_hooks = []\n",
        "\n",
        "\n",
        "acfg = A_Config()\n",
        "acfg.reset()"
      ],
      "metadata": {
        "id": "i8VoNc_ckfrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get and put attention head value hooks\n",
        "\n",
        "def a_null_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  acfg.hook_calls += 1\n",
        "  #print(\"In a_null_attn_z_hook\", value.shape)  # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "\n",
        "def a_get_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_get_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_get_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In acfg.get_l1_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_put_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_put_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_put_l1_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_reset(token_position, layer, heads):\n",
        "  global acfg\n",
        "\n",
        "  acfg.reset()\n",
        "\n",
        "  acfg.token_position = token_position\n",
        "  acfg.layer = layer\n",
        "  acfg.heads = heads\n",
        "\n",
        "  acfg.null_hooks = [(l_attn_hook_z_name[0], a_null_attn_z_hook)]\n",
        "  acfg.get_hooks = [(l_attn_hook_z_name[0], a_get_l0_attn_z_hook),(l_attn_hook_z_name[1], a_get_l1_attn_z_hook)]\n",
        "  acfg.put_hooks = [(l_attn_hook_z_name[0], a_put_l0_attn_z_hook),(l_attn_hook_z_name[1], a_put_l1_attn_z_hook)]"
      ],
      "metadata": {
        "id": "mMdSybNpnU0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a_predict_question(description, the_hooks, always):\n",
        "  global acfg\n",
        "  global model\n",
        "\n",
        "  acfg.hook_calls = 0\n",
        "  acfg.answer_failures = 0\n",
        "\n",
        "  main_model.reset_hooks()\n",
        "  main_model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = main_model.run_with_hooks(acfg.questions.cuda(), return_type=\"logits\", fwd_hooks=the_hooks)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, acfg.questions.cuda())\n",
        "\n",
        "  for question_num in range(acfg.questions.shape[0]):\n",
        "    loss_max = utils.to_numpy(loss_fn(all_losses_raw[question_num]).max())\n",
        "    answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "    match_str = \"\"\n",
        "    if loss_max > acfg.threshold:\n",
        "      acfg.answer_failures += 1\n",
        "      q = acfg.questions[question_num]\n",
        "      a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "      match_str = get_digit_accuracy_impact( a, answer_str )\n",
        "    if match_str == \"\":\n",
        "      match_str = \"(none)\"\n",
        "\n",
        "    if always or (loss_mean > acfg.threshold):\n",
        "      loss_str = \"(none)\" if loss_mean < 1e-7 else str(loss_max)\n",
        "\n",
        "      print(description, \"  ModelPredicts:\", answer_str, \"  DigitsImpacted:\", match_str, \"  Loss:\", loss_str)\n"
      ],
      "metadata": {
        "id": "0SeIO06JnU7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def a_run_intervention_core(token_position, layer, heads, store_question, alter_question):\n",
        "  a_reset(token_position, layer, heads)\n",
        "\n",
        "  # Predict first question and store activation values (including the Vn.BA)\n",
        "  acfg.questions = make_questions([store_question], PLUS_INDEX)\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  a_predict_question(\"Store activation\", acfg.get_hooks, False)\n",
        "\n",
        "  # Predict second question. Then rerun overriding Pn_Lm_Hp to give bad answer\n",
        "  acfg.questions = make_questions([alter_question], PLUS_INDEX)\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  prompt = \"Intervening on P\" + str(token_position) + \".L\" + str(layer) + \".H\"\n",
        "  for head_index in acfg.heads:\n",
        "    prompt += str(head_index) + \",\"\n",
        "  a_predict_question(prompt, acfg.put_hooks, True)\n",
        "\n",
        "\n",
        "def a_run_intervention(description, token_position, layer, heads, store_question, alter_question):\n",
        "  if cfg.n_digits == 5 and cfg.n_layers == 2:\n",
        "    print(description)\n",
        "    a_run_intervention_core(token_position, layer, heads, store_question, alter_question)\n",
        "    print()"
      ],
      "metadata": {
        "id": "Jk0gVCF9Gr5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 21B : Run Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (casual abstraction) to the model attention heads.\n"
      ],
      "metadata": {
        "id": "7bbeIfUxvLzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P8.L0.H1 performs V2.C = TriCase(D2, D2) impacting A4 and A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V2 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V2 has no MC.\n",
        "a_run_intervention(\"No V2.MC: No impact expected\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [77711, 22711] # Sum is 100422. V2 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A54 digit impacts. Expect 109999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [17711, 22711] # Sum is 035422. V2 has MC\n",
        "alter_question = [ 4444,  5555] # Sum is 009999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A4 digit impact. Expect 019999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P8.L0.H1 is: Based on D2 and D2'. Triggers on a V2 carry value. Provides \"carry 1\" used in A5 and A4 calculation."
      ],
      "metadata": {
        "id": "sFLdZkmEHhIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf8fedd-013d-4b65-bd73-3cfaddde50f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P8.L0.H1 performs V2.C = TriCase(D2, D2) impacting A4 and A5 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P9.L0.H1 performs V1.C = TriCase(D1, D1) impacting A5, A4 & A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "alter_question = [ 11111, 11111] # Sum is 022222. V1 has no MC\n",
        "a_run_intervention(\"No V1.MC: No impact expected\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "a_run_intervention(\"Insert V1.MC: Expect A543 digit impacts. Expect 100999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A43 digit impacts. Expect 010999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A3 digit impact. Expect 001999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H1 is: Based on D1 and D1'. Triggers on a V1 carry value. Provides \"carry 1\" used in A5, A4 & A3 calculation."
      ],
      "metadata": {
        "id": "dNtG_mlXeZKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71bc117-68a9-49cd-a05c-6cc71c665ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P9.L0.H1 performs V1.C = TriCase(D1, D1) impacting A5, A4 & A3 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P10.L0.H1 performs V1.C2 = TriAdd(V1.C, TriCase(D0, D0)) impacting A5, A4, A3 & A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 11111, 33333] # Sum is 044444. V0 has no MC.\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"No impact expected\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: No impact as expected\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A5432 digit impacts. Expect 100099.\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: Impact on A5432 as expected. Got expected value 100099\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A432 digit impacts. Expect 010099.\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A32 digit impacts. Expect 001099\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [    44,    55] # Sum is 000099. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC Expect A2 digit impacts. Expect 000199\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P10.L0.H1 is: Based on D0 and D0'. Triggers on a V0 carry value. Provides \"carry 1\" used in A5, A4, A3 & A2 calculation."
      ],
      "metadata": {
        "id": "UDt2LmNwiMGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf254373-f0e7-464d-d386-77fda3074889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P10.L0.H1 performs V1.C2 = TriAdd(V1.C, TriCase(D0, D0)) impacting A5, A4, A3 & A2 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P11.L0.H1 performs V3.C4 = TriAdd(TriCase(D3, D3),TriAdd(V2.C,V1.C2)) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 44444] # Sum is 088888. V3 sums to 8 (has no MC).\n",
        "alter_question = [11111, 11111] # Sum is 022222. V3 has no MC.\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 13111] # Sum is 032111. V3 sums to 9 (has no MC).\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 16111] # Sum is 032111. V3 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"Insert V3.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P11.L0.H1 is: Based on D3 and D3'. Triggers on a V3 carry value. Provides \"carry 1\" used in A5 calculations."
      ],
      "metadata": {
        "id": "uxGCodzep7qV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074f73c3-3ac9-4987-9fa8-919555cd6540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P11.L0.H1 performs V3.C4 = TriAdd(TriCase(D3, D3),TriAdd(V2.C,V1.C2)) impacting A5 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P11.L0.H2 performs V4.C = TriCase(D4, D4) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V4 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V4 has no MC.\n",
        "a_run_intervention(\"No V4.MC: No impact expected\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "store_question = [71111, 71111] # Sum is 100422. V4 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V4 has no MC\n",
        "a_run_intervention(\"Insert V4.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H2 is: Based on D4 and D4'. Triggers on a V4 carry value. Provides \"carry 1\" used in A5 calculation."
      ],
      "metadata": {
        "id": "yo55vCvCoMq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2c7aae-fbbc-4ca9-b159-134a2701663b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P11.L0.H2 performs V4.C = TriCase(D4, D4) impacting A5 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P12.L0.H0 and H2 performs V4.BA = (D4 + D4) % 10 impacting A4 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [72222, 71111] # Sum is 143333\n",
        "alter_question = [12342, 56573] # Sum is 068915\n",
        "a_run_intervention(\"Override D4/D4'. Expect A4 digit impact. Expect 048915\", 12, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0+H2 is: Adds D4 and D4'. Impacts A4"
      ],
      "metadata": {
        "id": "_jSE5S9UQFpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55414f0-d442-446c-cff7-8a0caa0b3c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P12.L0.H0 and H2 performs V4.BA = (D4 + D4) % 10 impacting A4 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P13.L0.H0 and H2 performs V3.BA = (D3 + D3) % 10 impacting A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [23222, 13111] # Sum is 36333\n",
        "alter_question = [12342, 56573] # Sum is 68915\n",
        "a_run_intervention(\"Override D3/D3'. Expect A3 digit impact. Expect 66915\", 13, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P13.L0.H0+H2 is: Adds D3 and D3'. Impacts A3"
      ],
      "metadata": {
        "id": "b6UpIJbfPG6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c92bbb8-64d5-4cd7-dd03-3f4168b4e328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P13.L0.H0 and H2 performs V3.BA = (D3 + D3) % 10 impacting A3 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P14.L0.H0 and H2 performs V2.BA = (D2 + D2) % 10 impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12342, 56573] # Sum is 68915. Has V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68715\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12133, 56133] # Sum is 68266. No V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68666\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0 and H2 both impact A2, and together sum D2 and D2'"
      ],
      "metadata": {
        "id": "rXiOPyZ1ONcg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86775a5a-2d9e-4b72-d9f3-f7dc66b0b2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P14.L0.H0 and H2 performs V2.BA = (D2 + D2) % 10 impacting A2 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2, impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "\n",
        "store_question = [55555, 44454] # Sum is 100009. Has V1.MC\n",
        "alter_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 14, 0, [1], store_question, alter_question) # Get 055655. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 10, 0, [1], store_question, alter_question) # Get 055555. No impact.\n",
        "\n",
        "store_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "alter_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 14, 0, [1], store_question, alter_question) # Get 066766. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 10, 0, [1], store_question, alter_question) # Get 066666. No impact.\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 14, 0, [1], store_question, alter_question) # Get 100980. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 10, 0, [1], store_question, alter_question) # Get 100080. No impact.\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 behaviour is different from P10.L0.H1 behaviour\n",
        "# - P14.L0.H1 does not simply copy P10.L0.H1 (although this would be a valid way to get perfect accuracy in A2)\n",
        "print()\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55555, 44445] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "store_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "alter_question = [66663, 33337] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 does rely on P10.L0.H1 for V1.C2 information when V1.C != V1.C2\n",
        "# - P14.L0.H1 calculates V1.C information itself from D1+D1'.\n",
        "\n",
        "# Overall confirmed: P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2 when V1.C != V1.C2. Impacts A2"
      ],
      "metadata": {
        "id": "LAzB924mQkyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8792061-7d57-40b7-d204-437e5edb2928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2, impacting A2 accuracy\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P15.L0.H0 and H2 performs V1.BA = (D1 + D1) % 10 impacting A1 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12322, 56523] # Sum is 68845. No V0.MC\n",
        "a_run_intervention(\"Override D1/D1'. Expect A1 digit impact. Expect 68885\", 15, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H0 and H2 both impact A1, and together sum D1 and D1'"
      ],
      "metadata": {
        "id": "jJiVBPZe6DUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64dbd1a-a016-4623-c908-9c15a3eae05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P15.L0.H0 and H2 performs V1.BA = (D1 + D1) % 10 impacting A1 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P15.L0.H1 performs V0.MC = (D0 + D0) / 10 impacting A1 (A one) accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22244, 11149] # Sum is 33393. Has V0.MC\n",
        "alter_question = [12342, 56513] # Sum is 68855. No V0.MC\n",
        "a_run_intervention(\"Override D0.MC. Expect A1 digit impact. Expect 68865\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Now test counter-claim that an intervention where both questions do NOT generate a D0.MC has NO impact on A1\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12342, 56523] # Sum is 68865. No V0.MC\n",
        "a_run_intervention(\"No impact expected\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H1: Triggers when D0 + D0' > 10. Impacts A1 digit by 1"
      ],
      "metadata": {
        "id": "AVrX9QmOnVCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9c20c7-f73a-4248-8a34-08bbdcd33fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P15.L0.H1 performs V0.MC = (D0 + D0) / 10 impacting A1 (A one) accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( \"Test claim that P16.L0.H0 and H2 performs D0.BA = (D0 + D0) % 10 impacting A0 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22225, 11114] # Sum is 33339\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68909\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22228, 11119] # Sum is 33347\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68907\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P16.L0.H0 and H2 both impact A0, and together sum D0 and D0'"
      ],
      "metadata": {
        "id": "8gM8TpWeyysU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c8d0f5-8859-4329-d3dc-08be59fbeac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test claim that P16.L0.H0 and H2 performs D0.BA = (D0 + D0) % 10 impacting A0 accuracy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 22: MLP Visualisation (incomplete, on-hold)"
      ],
      "metadata": {
        "id": "lTs6Cu55jB7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import einops\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# number of questions in batch that generated sample_cache\n",
        "num_questions = varied_questions.shape[0]\n",
        "\n",
        "\n",
        "def get_mlp_data(data_set_name):\n",
        "\n",
        "  data_set = sample_cache[data_set_name]\n",
        "  # print( data_set_name + \" shape\", data_set.shape) # 239, 22, 2040 = num_questions, n_ctx, d_mlp\n",
        "\n",
        "  raw_data = data_set[:,-3]\n",
        "  # print( \"raw_data shape\", raw_data.shape) # 239, 2040 = num_questions, d_mlp\n",
        "\n",
        "  answer = einops.rearrange(raw_data, \"(x y) d_mlp -> x y d_mlp\", x=num_questions).cpu().numpy()\n",
        "  # print( \"answer shape\", answer.shape) # 239, 1, 2040 = num_questions, ??, d_mlp\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "l0_mlp_hook_pre_sq = get_mlp_data('blocks.0.mlp.hook_pre')\n",
        "l0_mlp_hook_post_sq = get_mlp_data('blocks.0.mlp.hook_post')\n",
        "l1_mlp_hook_pre_sq = get_mlp_data('blocks.0.mlp.hook_pre')\n",
        "l1_mlp_hook_post_sq = get_mlp_data('blocks.1.mlp.hook_post')\n",
        "\n",
        "\n",
        "def plot_mlp_neuron_activation(pos: int):\n",
        "    clear_output()\n",
        "\n",
        "    l0_mlp_pre_data = l0_mlp_hook_pre_sq[:,:,pos]\n",
        "    l0_mlp_post_data = l0_mlp_hook_post_sq[:,:,pos]\n",
        "    l1_mlp_pre_data = l1_mlp_hook_pre_sq[:,:,pos]\n",
        "    l1_mlp_post_data = l1_mlp_hook_post_sq[:,:,pos]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
        "\n",
        "    plot = axs[0].imshow(l1_mlp_pre_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_pre_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "    plot = axs[1].imshow(l1_mlp_post_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_post_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "\n",
        "interact(plot_mlp_neuron_activation, pos=widgets.IntText(value=0, description='Index:'))"
      ],
      "metadata": {
        "id": "YviVHnBRjDcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "0a2c81c59c8f482d83e6d349986ad0d6",
            "3b7e502e78c747f392436b107ac256bb",
            "786c115a4ba04ddf9aa52cbe5bf3146c",
            "6b84a0637ce641418f5d542cf0840528",
            "08164dbbd8e8431b9048906463bf5e07",
            "05751c9c4a0b4a09b0ad078234640f1b",
            "566b2b36f1ec4cd79329f17050a55ce3"
          ]
        },
        "outputId": "7c73ee2e-9292-4d69-a9ac-c91d93d845cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntText(value=0, description='Index:'), Output()), _dom_classes=('widget-interact',))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a2c81c59c8f482d83e6d349986ad0d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.plot_mlp_neuron_activation(pos: int)>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "P8RfHXneJw6n",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "904WBkTOLg_5",
        "99LIC1l4MD32",
        "pKZF_B6OMIq3",
        "VpkyhHRoMOSw",
        "fHSY3blNMe7I",
        "Rbiau9foMp3h",
        "3611cpuEFhoW",
        "jIu3Pr9CMx3l",
        "7bbeIfUxvLzl"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a2c81c59c8f482d83e6d349986ad0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b7e502e78c747f392436b107ac256bb",
              "IPY_MODEL_786c115a4ba04ddf9aa52cbe5bf3146c"
            ],
            "layout": "IPY_MODEL_6b84a0637ce641418f5d542cf0840528"
          }
        },
        "3b7e502e78c747f392436b107ac256bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntTextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntTextView",
            "continuous_update": false,
            "description": "Index:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_08164dbbd8e8431b9048906463bf5e07",
            "step": 1,
            "style": "IPY_MODEL_05751c9c4a0b4a09b0ad078234640f1b",
            "value": 0
          }
        },
        "786c115a4ba04ddf9aa52cbe5bf3146c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_566b2b36f1ec4cd79329f17050a55ce3",
            "msg_id": "",
            "outputs": []
          }
        },
        "6b84a0637ce641418f5d542cf0840528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08164dbbd8e8431b9048906463bf5e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05751c9c4a0b4a09b0ad078234640f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566b2b36f1ec4cd79329f17050a55ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}