{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Accurate Integer Mathematics in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "The model weightings created by the sister CoLab [Accurate_Math_Train](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/Accurate_Math_Train.ipynb) are loaded from HuggingFace.\n",
        "\n",
        "Focus is on ins_sub_d6_l3_h4_dm510_dh170_ctx22_seed372001_train20K.pth which was initialised with add_d6_l2_h3_dm510_dh170_ctx22_seed372001_train15K.pth before being trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1: Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 853,
      "metadata": {
        "id": "cwXrSj8KGj-v"
      },
      "outputs": [],
      "source": [
        "# Tokens used in vocab. (Token indexes 0 to 9 represent digits 0 to 9)\n",
        "PLUS_INDEX = 10\n",
        "MINUS_INDEX = 11\n",
        "EQUALS_INDEX = 12\n",
        "MULT_INDEX = 13\n",
        "DIV_INDEX = 14\n",
        "MAX_INDEX = DIV_INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 854,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Main configuration class for main model creation and training\n",
        "class Config():\n",
        "  #@markdown Main Model\n",
        "  n_layers: int = 3 #@param\n",
        "  n_heads: int = 4 #@param\n",
        "\n",
        "  d_vocab: int = MAX_INDEX+1\n",
        "  d_model: int = 510\n",
        "  d_mlp: int = 4 * d_model\n",
        "  d_head: int = 170\n",
        "  seed: int = 372001 # 129000\n",
        "\n",
        "  #@markdown Data\n",
        "  n_digits: int = 6 #@param\n",
        "  n_ctx: int = 3 * n_digits + 4\n",
        "  act_fn: str = 'relu'\n",
        "  batch_size: int = 64\n",
        "\n",
        "  #@markdown Optimizer\n",
        "  n_training_steps: int = 20000 #@param\n",
        "  weight_decay: float = 0.00008\n",
        "  lr: int = 0.1\n",
        "\n",
        "  #@markdown Actions\n",
        "\n",
        "  # Percent of questions that are multiplication, subtraction (rest are addition questions).\n",
        "  perc_mult: int = 0 #@param e.g. 20\n",
        "  perc_sub: int = 100 #@param e.g. 80\n",
        "  def perc_add(self):\n",
        "    return max(0, 100 - self.perc_mult - self.perc_sub)\n",
        "\n",
        "  #@markdown Insert Model\n",
        "  insert: bool = False #@param   Was the model trained using an inserted \"known good\" model\n",
        "\n",
        "\n",
        "  # Save graphs to CoLab temp files as PDF and HTML. Can manually export files for re-use in papers.\n",
        "  save_graph_to_file: bool = True\n",
        "\n",
        "  # The format to output prettytable in. Options are text|html|json|csv|latex\n",
        "  # Use Text for this CoLab, latex for Overleaf output, and html for GitHub blog output\n",
        "  table_out_format: str = \"text\"\n",
        "\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 855,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0DJkn5l2gq3",
        "outputId": "a9c32717-6494-4f97-e742-e71bfd0e570a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: %Mult= 0 %Sub= 100 %Add= 0 sub_d6_l3_h4_dm510_dh170_ctx22_seed372001_train20K\n"
          ]
        }
      ],
      "source": [
        "def file_name_suffix(digits, layers, heads, d_model, d_head, ctx, seed, training_steps):\n",
        "  epoch_str = str(training_steps//1000) + \"K\"\n",
        "  return '_d{}_l{}_h{}_dm{}_dh{}_ctx{}_seed{}_train{}'.format(digits, layers, heads, d_model, d_head, ctx, seed, epoch_str)\n",
        "\n",
        "fname_prefix = 'ins_' if cfg.insert else ''\n",
        "fname_prefix += 'mul' if cfg.perc_mult == 100 else 'sub' if cfg.perc_sub == 100 else 'add' if cfg.perc_add() == 100 else 'mix'\n",
        "main_fname_suffix = fname_prefix + file_name_suffix(cfg.n_digits, cfg.n_layers, cfg.n_heads, cfg.d_model, cfg.d_head, cfg.n_ctx, cfg.seed, cfg.n_training_steps)\n",
        "main_fname_full = main_fname_suffix + '.pth'\n",
        "\n",
        "\n",
        "def print_config():\n",
        "  print(\"Config: %Mult=\", cfg.perc_mult, \"%Sub=\", cfg.perc_sub, \"%Add=\", cfg.perc_add(), main_fname_suffix)\n",
        "\n",
        "print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 2A: Import libraries\n",
        "Imports standard libraries. Don't bother reading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdmr6-_Jkzi",
        "outputId": "39515895-3a1b-44cc-a01f-815e117aa796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.3)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    !pip install numpy --upgrade\n",
        "    !pip install scikit-learn --upgrade\n",
        "    !pip install matplotlib\n",
        "    !pip install prettytable\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from prettytable import PrettyTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import exception:\", e)\n",
        "  use_pca = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Part 2B: Utilities"
      ],
      "metadata": {
        "id": "3BmQHiLALp-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_row_heading(i):\n",
        "  head = i % (cfg.n_heads + 1)\n",
        "  layer = i // (cfg.n_heads + 1)\n",
        "  return ( \"L\" + str(layer) + \"H\" + str(head) ) if head < cfg.n_heads else \"MLP \"\n",
        "\n",
        "\n",
        "def show_2d_map_start(width_inches=12,height_inches=6):\n",
        "  # Create figure and axes\n",
        "  fig, ax = plt.subplots(figsize=(width_inches, height_inches))  # Adjust the figure size as needed\n",
        "\n",
        "  # Ensure cells are square\n",
        "  ax.set_aspect('equal', adjustable='box')\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def show_2d_map_end(title, fig, ax, min_col, max_col):\n",
        "\n",
        "  # Vertical and horizontal axis labels\n",
        "  num_rows = table_rows()\n",
        "  num_cols = max_col - min_col + 1\n",
        "  vertical_labels = [get_row_heading(num_rows-i-1) for i in range(num_rows)]\n",
        "  horizontal_labels = [f\"P{min_col+i}\" for i in range(max_col-min_col+1)]\n",
        "\n",
        "  # Set axis limits\n",
        "  ax.set_xlim(0, len(horizontal_labels))\n",
        "  ax.set_ylim(0, len(vertical_labels))\n",
        "\n",
        "  # Set axis labels\n",
        "  ax.set_xticks(np.arange(0.5, num_cols, 1))\n",
        "  ax.set_yticks(np.arange(0.5, num_rows, 1))\n",
        "  ax.set_xticklabels(horizontal_labels)\n",
        "  ax.set_yticklabels(vertical_labels)\n",
        "\n",
        "  # Move the x-axis to the top\n",
        "  ax.xaxis.tick_top()\n",
        "  ax.xaxis.set_label_position('top')\n",
        "\n",
        "  filename = fname_prefix + '_' + title + '_d{}_l{}_h{}'.format(cfg.n_digits, cfg.n_layers, cfg.n_heads)\n",
        "  ax.set_title(filename)\n",
        "\n",
        "  if cfg.save_graph_to_file:\n",
        "    plt.savefig(filename+\".pdf\")\n",
        "    #plt.savefig(filename+\".svg\")\n",
        "\n",
        "  # Show plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TNHEMAzwHIcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3: Create model\n",
        "This section defines the token embedding / unembedding and creates the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QYFZIalJ3tK"
      },
      "outputs": [],
      "source": [
        "# Embedding / Unembedding\n",
        "\n",
        "def token_to_char(i):\n",
        "  if i < 10:\n",
        "   return str(i)\n",
        "  if i == PLUS_INDEX:\n",
        "    return \"+\"\n",
        "  if i == MINUS_INDEX:\n",
        "    return \"-\"\n",
        "  if i == EQUALS_INDEX:\n",
        "    return \"=\"\n",
        "  if i == MULT_INDEX:\n",
        "    return \"*\"\n",
        "  if i == DIV_INDEX:\n",
        "    return \"\\\\\"\n",
        "  return \"?\"\n",
        "\n",
        "def tokens_to_string(tokens):\n",
        "    tokens = utils.to_numpy(tokens)\n",
        "    return \"\".join([token_to_char(i) for i in tokens[:cfg.n_ctx]])\n",
        "\n",
        "def string_to_tokens(string, batch: bool=False):\n",
        "    lookup = {str(i):i for i in range(10)}\n",
        "    lookup['+']=PLUS_INDEX\n",
        "    lookup['-']=MINUS_INDEX\n",
        "    lookup['=']=EQUALS_INDEX\n",
        "    lookup['*']=MULT_INDEX\n",
        "    lookup['\\\\']=DIV_INDEX\n",
        "\n",
        "    tokens = [lookup[i] for i in string if i not in '\\n ']\n",
        "    if batch:\n",
        "        return torch.tensor(tokens)[None, :]\n",
        "    else:\n",
        "        return torch.tensor(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp,\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx,\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.seed,\n",
        ")\n",
        "\n",
        "main_model = HookedTransformer(ht_cfg)\n",
        "\n",
        "optimizer = torch.optim.AdamW(main_model.parameters(),\n",
        "                        lr = cfg.lr,\n",
        "                        weight_decay = cfg.weight_decay,\n",
        "                        betas = (0.9, 0.98))\n",
        "\n",
        "max_iter = cfg.n_training_steps\n",
        "warmup_iter = max_iter // 5\n",
        "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=int(warmup_iter))\n",
        "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(np.ceil((max_iter-warmup_iter))))\n",
        "scheduler  = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[int(warmup_iter)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Loss Function & Data Generator\n",
        "This section defines the loss function and the training/tesing data generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2iNO-nKDBW"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "# Calculate the per-token probability by comparing a batch of prediction \"logits\" to answer \"tokens\"\n",
        "def logits_to_tokens_loss(logits, tokens):\n",
        "  # Addition answer can have one extra digit than question. Answer also has a +/- sign\n",
        "  n_answer_digits = cfg.n_digits+2\n",
        "\n",
        "  # The addition answer digit token probabilities\n",
        "  ans_logits = logits[:, -(n_answer_digits+1):-1]\n",
        "\n",
        "  # Convert raw score (logits) vector into a probability distribution.\n",
        "  # Emphasize the largest scores and suppress the smaller ones, to make them more distinguishable.\n",
        "  ans_probs = F.log_softmax(ans_logits.to(torch.float64), dim=-1)\n",
        "\n",
        "  max_prob_tokens = torch.argmax(ans_probs, dim=-1)\n",
        "\n",
        "  # The addition answer digit tokens\n",
        "  ans_tokens = tokens[:, -(n_answer_digits):]\n",
        "\n",
        "  # Extract values from the ans_probs tensor, based on indices from the ans_tokens tensor\n",
        "  ans_loss = torch.gather(ans_probs, -1, ans_tokens[:, :, None])[..., 0]\n",
        "\n",
        "  return ans_loss, max_prob_tokens\n",
        "\n",
        "\n",
        "# Calculate loss as negative of average per-token mean probability\n",
        "def loss_fn(ans_loss):\n",
        "  return -ans_loss.mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSp8pS1eKHf6"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" data generator function. Invoked using next().\n",
        "# \"Addition\" batch entries are formated XXXXX+YYYYY=+ZZZZZZ e.g. 550030+800020=+1350050\n",
        "# \"Subtraction\" batch entries are formated XXXXX-YYYYY=-ZZZZZZ e.g. 550030-800020=-0249990, 800020-550030=+0249990\n",
        "# \"Multiplication\" batch entries are formated 000XXX*000YYY=+ZZZZZZ e.g. 000345*000678=+233910\n",
        "def data_generator( ):\n",
        "    torch.manual_seed(cfg.seed)\n",
        "    while True:\n",
        "        #generate a batch of questions (answers calculated below)\n",
        "        batch = torch.zeros((cfg.batch_size, cfg.n_ctx)).to(torch.int64)\n",
        "        x = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "        y = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "\n",
        "        batch_rand = random.randint(1, 100)\n",
        "        batch_op = MULT_INDEX if batch_rand <= cfg.perc_mult else MINUS_INDEX if batch_rand <= cfg.perc_mult + cfg.perc_sub else PLUS_INDEX\n",
        "\n",
        "        if batch_op == MULT_INDEX:\n",
        "          # Convert from NNNNNN*NNNNNN= to 000NNN*000NNN= so answer (product) is NNNNNN\n",
        "          num_zeros = cfg.n_digits // 2\n",
        "          for z in range(num_zeros):\n",
        "            x[:, z] = 0\n",
        "            y[:, z] = 0\n",
        "\n",
        "\n",
        "        # Enrich the question data on 60% of batches to speed up training\n",
        "        if ( batch_op == PLUS_INDEX or batch_op == MINUS_INDEX ) and (random.randint(1, 5) < 3):\n",
        "            # Flatten x and y to 1D tensors\n",
        "            x_flat = x.view(-1)\n",
        "            y_flat = y.view(-1)\n",
        "\n",
        "            if batch_op == PLUS_INDEX :\n",
        "              # The UseSum9 task is compound and rare and so hard to learn.\n",
        "              # Increase the MakeSum9 case frequency\n",
        "              # UseSum9 also relies on MakeCarry1 (50%) from previous column.\n",
        "              num_elements_to_modify = int(0.40 * x.numel()) # 40%\n",
        "              indices_to_modify = torch.randperm(x_flat.numel())[:num_elements_to_modify]\n",
        "              if random.randint(1, 2) == 1:\n",
        "                x_flat[indices_to_modify] = 9 - y_flat[indices_to_modify]\n",
        "              else:\n",
        "                y_flat[indices_to_modify] = 9 - x_flat[indices_to_modify]\n",
        "            else:\n",
        "              # Empirically, the model seems to struggle with the sign calculation.\n",
        "              # Minus signs are rarer than positive signs.\n",
        "              # Generate more negative answers by increasing the y value\n",
        "              y_flat[y_flat < 9] += 1\n",
        "\n",
        "            # Reshape x and y back to its original shape\n",
        "            x = x_flat.view(x.shape)\n",
        "            y = y_flat.view(x.shape)\n",
        "\n",
        "\n",
        "        batch[:, :cfg.n_digits] = x\n",
        "        batch[:, cfg.n_digits] = batch_op\n",
        "        batch[:, 1+cfg.n_digits:1+cfg.n_digits*2] = y\n",
        "        batch[:, 1+cfg.n_digits*2] = EQUALS_INDEX\n",
        "\n",
        "        # Convert each row into a 5-digit number\n",
        "        x_values = x[:, 0]\n",
        "        y_values = y[:, 0]\n",
        "        for dn in range(1,cfg.n_digits):\n",
        "          x_values = x_values * 10 + x[:, dn]\n",
        "          y_values = y_values * 10 + y[:, dn]\n",
        "\n",
        "        # Elementwise operations to give the 1D tensor answers\n",
        "        if batch_op == MULT_INDEX:\n",
        "          answers = x_values * y_values\n",
        "        else:\n",
        "          if batch_op == MINUS_INDEX:\n",
        "            answers = x_values - y_values\n",
        "          else:\n",
        "            answers = x_values + y_values\n",
        "\n",
        "        # Insert the answers into the batch\n",
        "        for i in range(cfg.batch_size):\n",
        "          answer = answers[i]\n",
        "\n",
        "          sign = PLUS_INDEX\n",
        "          if answer < 0:\n",
        "            sign = MINUS_INDEX\n",
        "            answer = - answer\n",
        "\n",
        "          batch[i, 2+cfg.n_digits*2] = sign\n",
        "          for j in range(cfg.n_digits+1):\n",
        "            batch[i, cfg.n_ctx-j-1] = answer % 10\n",
        "            answer = answer // 10\n",
        "            if answer == 0:\n",
        "                break\n",
        "\n",
        "        yield batch.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "# Initialise the data generator\n",
        "ds = data_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmioT1THbJA"
      },
      "outputs": [],
      "source": [
        "# Test data generator\n",
        "tokens = next(ds)\n",
        "print(tokens[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model\", main_fname_full)\n",
        "\n",
        "main_model.load_state_dict(utils.download_file_from_hf(repo_name=\"PhilipQuirke/Accurate6DigitSubtraction\", file_name=main_fname_full, force_is_torch=True))\n",
        "\n",
        "main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxoBWHNKRf0"
      },
      "source": [
        "# Part 8: Sample Questions Set Up\n",
        "\n",
        "Create sets of sample questions exercising different use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj_xSuSSKR9t"
      },
      "outputs": [],
      "source": [
        "# Insert a number into the question\n",
        "def insert_question_number(the_question, index, first_digit_index, the_digits, n):\n",
        "\n",
        "  last_digit_index = first_digit_index + the_digits - 1\n",
        "\n",
        "  for j in range(the_digits):\n",
        "    the_question[index, last_digit_index-j] = n % 10\n",
        "    n = n // 10\n",
        "\n",
        "\n",
        "# Create a single question\n",
        "def make_a_question(the_question, index, q1, q2, operator ):\n",
        "\n",
        "  insert_question_number(the_question, index, 0, cfg.n_digits, q1)\n",
        "\n",
        "  the_question[index, cfg.n_digits] = operator\n",
        "\n",
        "  insert_question_number( the_question, index, cfg.n_digits+1, cfg.n_digits, q2)\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+1] = EQUALS_INDEX\n",
        "\n",
        "  answer = q1+q2\n",
        "  if operator == MINUS_INDEX:\n",
        "    answer = q1-q2\n",
        "  else:\n",
        "    if operator == MULT_INDEX:\n",
        "      answer = q1*q2\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+2] = PLUS_INDEX if answer >= 0 else MINUS_INDEX\n",
        "  if answer < 0:\n",
        "    answer = -answer\n",
        "\n",
        "  insert_question_number(the_question, index, 2*cfg.n_digits + 3, cfg.n_digits+1, answer)\n",
        "\n",
        "\n",
        "# Create a batch of questions from a 2D matrix of ints\n",
        "def make_questions(q_matrix, operator):\n",
        "  max_len = len(q_matrix)\n",
        "  real_len = 0\n",
        "\n",
        "  questions = torch.zeros((max_len, cfg.n_ctx)).to(torch.int64)\n",
        "\n",
        "  limit = 10 ** cfg.n_digits\n",
        "  for i in range(max_len):\n",
        "    a = q_matrix[i][0]\n",
        "    b = q_matrix[i][1]\n",
        "\n",
        "    if a < limit and b < limit:\n",
        "      real_len += 1\n",
        "      make_a_question(questions, i, a, b, operator)\n",
        "\n",
        "  return questions[:real_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xiOHRfGKW-W"
      },
      "outputs": [],
      "source": [
        "# Analyse the question and return the use case as Addition (BA, MC, SimpleUS9 or CascadeUS9) or Subtraction (BS, B1, C1, CN)\n",
        "def get_question_case(question):\n",
        "  qlist = utils.to_numpy(question)\n",
        "  inputs = qlist[:2*cfg.n_digits+2]\n",
        "  operator = qlist[cfg.n_digits]\n",
        "\n",
        "  if operator == PLUS_INDEX:\n",
        "\n",
        "    # Locate the MC and MS digits (if any)\n",
        "    mc = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    ms = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if inputs[dn] + inputs[dn + cfg.n_digits + 1] == 9:\n",
        "        ms[cfg.n_digits-1-dn] = 1\n",
        "      if inputs[dn] + inputs[dn + cfg.n_digits +1] > 9:\n",
        "        mc[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "    # Calculate the use case of a question\n",
        "    if torch.sum(mc) == 0:\n",
        "      return \"S0\"\n",
        "\n",
        "    if torch.sum(ms) == 0:\n",
        "      return \"S1\"\n",
        "\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-2 and mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1:\n",
        "        return \"S3+\" # MC cascades 2 or more digits\n",
        "\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-1 and mc[dn] == 1 and ms[dn+1] == 1:\n",
        "        return \"S2\" # Simple US 9\n",
        "\n",
        "    return \"S1\"\n",
        "\n",
        "\n",
        "  if operator == MINUS_INDEX:\n",
        "\n",
        "    # Locate the B1 and MZ digits (if any)\n",
        "    b1 = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    mz = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if inputs[dn] - inputs[dn + cfg.n_digits + 1] < 0:\n",
        "        b1[cfg.n_digits-1-dn] = 1\n",
        "      if inputs[dn] + inputs[dn + cfg.n_digits +1] == 0:\n",
        "        mz[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "    # Evaluate BaseSub questions - when no column generates a Borrow One\n",
        "    if torch.sum(b1) == 0:\n",
        "      return \"M0\"\n",
        "\n",
        "    # Evaluate subtraction \"cascade multiple steps\" questions\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-2 and b1[dn] == 1 and mz[dn+1] == 1 and mz[dn+2] == 1:\n",
        "        return \"M3+\" # B1 cascades 2 or more digits\n",
        "\n",
        "    # Evaluate subtraction \"cascade 1\" questions\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if dn < cfg.n_digits-1 and b1[dn] == 1 and mz[dn+1] == 1:\n",
        "        return \"M2\" # B1 cascades 1 digit\n",
        "\n",
        "    return \"M1\"\n",
        "\n",
        "\n",
        "  if operator == MULT_INDEX:\n",
        "    return \"MUL\"\n",
        "\n",
        "\n",
        "  return \"OP?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCPyETTKaEs"
      },
      "outputs": [],
      "source": [
        "# Manually create some questions that strongly test one use case\n",
        "\n",
        "\n",
        "# Make BaseAdd questions\n",
        "def make_s0_questions():\n",
        "    return make_questions(\n",
        "      [[0, 0],\n",
        "      [12345, 33333],\n",
        "      [33333, 12345],\n",
        "      [45762, 33113],\n",
        "      [888, 11111],\n",
        "      [2362, 23123],\n",
        "      [15, 81],\n",
        "      [1000, 4440],\n",
        "      [4440, 1000],\n",
        "      [24033, 25133],\n",
        "      [23533, 21133],\n",
        "      [32500, 1],\n",
        "      [31500, 1111],\n",
        "      [5500, 12323],\n",
        "      [4500, 2209],\n",
        "      [33345, 66643], # =099988\n",
        "      [66643, 33345], # =099988\n",
        "      [10990, 44000],\n",
        "      [60000, 30000],\n",
        "      [10000, 20000],\n",
        "      [109900, 440000],\n",
        "      [600000, 300000],\n",
        "      [100000, 200000],\n",
        "      [1099000, 4400000],\n",
        "      [6000000, 3000000],\n",
        "      [1000000, 2000000],\n",
        "      [10990000, 44000000],\n",
        "      [60000000, 3000000],\n",
        "      [10000000, 20000000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make UseCarry1 (addition) questions\n",
        "def make_s1_questions():\n",
        "    return make_questions(\n",
        "      [[ 15, 45],\n",
        "      [ 27, 55],\n",
        "      [ 35, 59],\n",
        "      [ 150, 450],\n",
        "      [ 270, 550],\n",
        "      [ 350, 590],\n",
        "      [ 1500, 4500],\n",
        "      [ 2700, 5500],\n",
        "      [ 3500, 5900],\n",
        "      [ 40035, 40049],\n",
        "      # [ 44000, 46000], D6 L1 H3 model cant handle this.\n",
        "      [ 70000, 40000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 35000],\n",
        "      [ 67000, 25000],\n",
        "      [ 19000, 76000],\n",
        "      [ 15020, 45091],\n",
        "      [ 25002, 55019],\n",
        "      [ 35002, 59019],\n",
        "      [ 150200, 450910],\n",
        "      [ 250020, 550190],\n",
        "      [ 350020, 590190],\n",
        "      [ 1502000, 4509100],\n",
        "      [ 2500200, 5501900],\n",
        "      [ 3500200, 5901900],\n",
        "      [ 15020000, 45091000],\n",
        "      [ 25002000, 55019000],\n",
        "      [ 35002000, 59019000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make SimpleUseSum9 (addition) questions\n",
        "def make_s2_questions():\n",
        "    return make_questions(\n",
        "      [[ 55, 45],\n",
        "      [ 45, 55],\n",
        "      [ 45, 59],\n",
        "      [ 35, 69],\n",
        "      [ 25, 79],\n",
        "      [ 15, 85],\n",
        "      [ 15, 88],\n",
        "      [ 15508, 14500],\n",
        "      [ 14508, 15500],\n",
        "      [ 24533, 25933],\n",
        "      [ 23533, 26933],\n",
        "      [ 32500, 7900],\n",
        "      [ 31500, 8500],\n",
        "      [ 550, 450],\n",
        "      [ 450, 550],\n",
        "      [ 10880, 41127],\n",
        "      [ 41127, 10880],\n",
        "      [ 12386, 82623],\n",
        "      [ 108800, 411270],\n",
        "      [ 411270, 108800],\n",
        "      [ 123860, 826230],\n",
        "      [ 1088000, 4112700],\n",
        "      [ 4112700, 1088000],\n",
        "      [ 1238600, 8262300],\n",
        "      [ 10880000, 41127000],\n",
        "      [ 41127000, 10880000],\n",
        "      [ 12386000, 82623000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make CascadeUseSum9 (addition) questions\n",
        "def make_s3plus_questions():\n",
        "    return make_questions(\n",
        "      # These are two level UseSum9 cascades\n",
        "      [[ 555, 445],\n",
        "      [ 3340, 6660],\n",
        "      [ 8880, 1120],\n",
        "      [ 1120, 8880],\n",
        "      [ 123, 877],\n",
        "      [ 877, 123],\n",
        "      [ 321, 679],\n",
        "      [ 679, 321],\n",
        "      [ 1283, 88786],\n",
        "      # These are three level UseSum9 cascades\n",
        "      [ 5555, 4445],\n",
        "      [ 55550, 44450],\n",
        "      [ 334, 666],\n",
        "      [ 3340, 6660],\n",
        "      [ 33400, 66600],\n",
        "      [ 888, 112],\n",
        "      [ 8880, 1120],\n",
        "      [ 88800, 11200],\n",
        "      [ 1234, 8766],\n",
        "      [ 4321, 5679],\n",
        "      # These are four level UseSum9 cascades\n",
        "      [ 44445, 55555],\n",
        "      [ 33334, 66666],\n",
        "      [ 88888, 11112],\n",
        "      [ 12345, 87655],\n",
        "      [ 54321, 45679],\n",
        "      [ 45545, 54455],\n",
        "      [ 36634, 63366],\n",
        "      [ 81818, 18182],\n",
        "      [ 87345, 12655],\n",
        "      [ 55379, 44621],\n",
        "      # These are five level UseSum9 cascades\n",
        "      [ 818818, 181182],\n",
        "      [ 873345, 126655],\n",
        "      [ 553379, 446621],\n",
        "      # These are six level UseSum9 cascades\n",
        "      [ 8188818, 1811182],\n",
        "      [ 8733345, 1266655],\n",
        "      [ 5533379, 4466621],\n",
        "      # These are seven level UseSum9 cascades\n",
        "      [ 81888818, 18111182],\n",
        "      [ 87333345, 12666655],\n",
        "      [ 55333379, 44626661]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make questions focus mainly on 1 digit at a time\n",
        "# (assuming that the 0 + 0 digit additions/subtractions are trivial bigrams)\n",
        "def make_sn_questions():\n",
        "    return make_questions(\n",
        "      [[ 1, 0],\n",
        "      [ 4, 3],\n",
        "      [ 5, 5],\n",
        "      [ 8, 1],\n",
        "      [ 40, 30],\n",
        "      [ 44, 46],\n",
        "      [ 400, 300],\n",
        "      [ 440, 460],\n",
        "      [ 800, 100],\n",
        "      [ 270, 470],\n",
        "      [ 600, 300],\n",
        "      [ 4000, 3000],\n",
        "      [ 4400, 4600],\n",
        "      [ 6000, 3000],\n",
        "      [ 7000, 4000],\n",
        "      [ 40000, 30000],\n",
        "      [ 44000, 45000],\n",
        "      [ 60000, 30000],\n",
        "      [ 70000, 40000],\n",
        "      [ 10000, 20000],\n",
        "      [ 15000, 25000],\n",
        "      [ 35000, 35000],\n",
        "      [ 45000, 85000],\n",
        "      [ 67000, 85000],\n",
        "      [ 99000, 76000],\n",
        "      [ 76000, 99000],\n",
        "      [ 670000, 850000],\n",
        "      [ 990000, 760000],\n",
        "      [ 760000, 990000],\n",
        "      [ 6700000, 8500000],\n",
        "      [ 9900000, 7600000],\n",
        "      [ 7600000, 9900000],\n",
        "      [ 67000000, 85000000],\n",
        "      [ 99000000, 76000000],\n",
        "      [ 76000000, 99000000]],\n",
        "      PLUS_INDEX)\n",
        "\n",
        "\n",
        "# Make M0 questions - when no column generates a Borrow One. Answer is always positive (or zero).\n",
        "def make_m0_questions():\n",
        "    return make_questions(\n",
        "      [[0, 0],\n",
        "      [6, 6],\n",
        "      [60, 60],\n",
        "      [600, 600],\n",
        "      [6000, 6000],\n",
        "      [60000, 60000],\n",
        "      [600000, 600000],\n",
        "      [6000000, 6000000],\n",
        "      [60000000, 60000000],\n",
        "      [66666, 12345],\n",
        "      [33333, 12321],\n",
        "      [45762, 34551],\n",
        "      [78901, 78901], # = +000000\n",
        "      [23123, 23123], # = +000000\n",
        "      [86, 15],\n",
        "      [4440, 1230],\n",
        "      [88746, 86544],\n",
        "      [27833, 25133],\n",
        "      [23533, 21133],\n",
        "      [32501, 1],\n",
        "      [31511, 1111],\n",
        "      [55555, 12323],\n",
        "      [45454, 22022],\n",
        "      [66643, 3341],\n",
        "      [66643, 30042],\n",
        "      [99999, 44012],\n",
        "      [60000, 30000],\n",
        "      [99000, 99000], # = +000000\n",
        "      [999990, 440120],\n",
        "      [600000, 300000],\n",
        "      [990000, 990000], # = +0000000\n",
        "      [9999900, 4401200],\n",
        "      [6000000, 3000000],\n",
        "      [9900000, 9900000], # = +00000000\n",
        "      [99999000, 44012000],\n",
        "      [60000000, 30000000],\n",
        "      [99000000, 99000000]], # = +000000000\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction M1 questions with exactly one \"borrow 1\" instance. Answer is always positive.\n",
        "def make_m1_questions():\n",
        "    return make_questions(\n",
        "      [[22222, 11113],\n",
        "      [ 22222, 11131],\n",
        "      [ 22222, 11311],\n",
        "      [ 22222, 13111],\n",
        "      [    14,     8],\n",
        "      [   140,    80],\n",
        "      [  1400,   800],\n",
        "      [ 14000,  8000],\n",
        "      [ 55514, 11108],\n",
        "      [ 55140, 11080],\n",
        "      [ 51400, 10800],\n",
        "      [ 14000,  8000],\n",
        "      [ 88888, 22229],\n",
        "      [ 77777, 22292],\n",
        "      [ 66666, 22922],\n",
        "      [ 888888, 222292],\n",
        "      [ 777777, 222922],\n",
        "      [ 666666, 229222],\n",
        "      [ 8888888, 2222922],\n",
        "      [ 7777777, 2229222],\n",
        "      [ 6666666, 2292222],\n",
        "      [ 88888888, 22229222],\n",
        "      [ 77777777, 22292222],\n",
        "      [ 66666666, 22922222]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction M2 questions containing B1 and DZ. Answer is always positive (or zero).\n",
        "def make_m2_questions():\n",
        "    return make_questions(\n",
        "      [[22212, 11113],\n",
        "      [ 22122, 11131],\n",
        "      [ 21222, 11311],\n",
        "      [   904,     8],\n",
        "      [  9040,    80],\n",
        "      [ 90400,   800],\n",
        "      [ 55514, 11118],\n",
        "      [ 55140, 11180],\n",
        "      [ 51400, 11800],\n",
        "      [ 88888, 22289],\n",
        "      [ 77777, 22892],\n",
        "      [ 66666, 28922],\n",
        "      [ 888888, 222892],\n",
        "      [ 777777, 228922],\n",
        "      [ 666666, 289222],\n",
        "      [ 8888888, 2228922],\n",
        "      [ 7777777, 2289222],\n",
        "      [ 6666666, 2892222],\n",
        "      [ 88888888, 22289222],\n",
        "      [ 77777777, 22892222],\n",
        "      [ 66666666, 28922222]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction M3,M4,... questions containing B1 and multiple DZs. Answer is always positive (or zero).\n",
        "def make_m3plus_questions():\n",
        "    return make_questions(\n",
        "      [[21112, 11113],\n",
        "      [ 21122, 11131],\n",
        "      [ 99004,     8],\n",
        "      [ 90040,    80],\n",
        "      [ 55114, 11118],\n",
        "      [ 51140, 11180],\n",
        "      [ 88888, 22889],\n",
        "      [ 77777, 28892],\n",
        "      [ 888888, 228892],\n",
        "      [ 777777, 288922],\n",
        "      [ 8888888, 2288922],\n",
        "      [ 7777777, 2889222],\n",
        "      [ 88888888, 22889222],\n",
        "      [ 77777777, 28892222]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "# Make subtraction questions with negative answers\n",
        "def make_ng_questions():\n",
        "    return make_questions(\n",
        "      [[ 0, 1],\n",
        "      [ 88888, 88889],\n",
        "      [ 55555, 55556],\n",
        "      [ 88881, 88891],\n",
        "      [ 55551, 55561],\n",
        "      [ 88811, 88911],\n",
        "      [ 55511, 55611],\n",
        "      [ 8, 12],\n",
        "      [ 40, 232],\n",
        "      [ 44, 523],\n",
        "      [ 234, 334],\n",
        "      [ 7777, 8434],\n",
        "      [ 88888, 92222],\n",
        "      [ 77777, 84340],\n",
        "      [ 888888, 922220],\n",
        "      [ 777777, 843400],\n",
        "      [ 8888888, 9222200],\n",
        "      [ 7777777, 8434000],\n",
        "      [ 88888888, 92222000],\n",
        "      [ 77777777, 84340000]],\n",
        "      MINUS_INDEX)\n",
        "\n",
        "\n",
        "def make_addition_questions():\n",
        "  s0 = make_s0_questions()\n",
        "  s1 = make_s1_questions()\n",
        "  s2 = make_s2_questions()\n",
        "  s3 = make_s3plus_questions()\n",
        "  s4 = make_sn_questions()\n",
        "\n",
        "  return torch.vstack((s0.cuda(), s1.cuda(), s2.cuda(), s3.cuda(), s4.cuda()))\n",
        "\n",
        "\n",
        "def make_subtraction_questions():\n",
        "  m0 = make_m0_questions()\n",
        "  m1 = make_m1_questions()\n",
        "  m2 = make_m2_questions()\n",
        "  m3 = make_m3plus_questions()\n",
        "  m4 = make_ng_questions()\n",
        "\n",
        "  return torch.vstack((m0.cuda(), m1.cuda(), m2.cuda(), m3.cuda(), m4.cuda()))\n",
        "\n",
        "\n",
        "v0 = next(ds) # Could be Add, Sub or Mult\n",
        "v1 = next(ds) # Could be Add, Sub or Mult\n",
        "\n",
        "\n",
        "# Returns random and manually-chosen questions\n",
        "def make_varied_questions():\n",
        "  if cfg.perc_mult == 100 :\n",
        "    return torch.vstack((v0.cuda(), v1.cuda()))\n",
        "\n",
        "  s0 = make_s0_questions()\n",
        "  s1 = make_s1_questions()\n",
        "  s2 = make_s2_questions()\n",
        "  s3 = make_s3plus_questions()\n",
        "  s4 = make_sn_questions()\n",
        "\n",
        "  m0 = make_m0_questions()\n",
        "  m1 = make_m1_questions()\n",
        "  m2 = make_m2_questions()\n",
        "  m3 = make_m3plus_questions()\n",
        "  m4 = make_ng_questions()\n",
        "\n",
        "  if cfg.perc_sub == 0 :\n",
        "    return torch.vstack((v0.cuda(), s0.cuda(), s1.cuda(), s2.cuda(), s3.cuda(), s4.cuda(), v1.cuda()))\n",
        "\n",
        "  if cfg.perc_sub == 100 :\n",
        "    return torch.vstack((v0.cuda(), m0.cuda(), m1.cuda(), m2.cuda(), m3.cuda(), m4.cuda(), v1.cuda()))\n",
        "\n",
        "  return torch.vstack((v0.cuda(), s0.cuda(), m0.cuda(), s1.cuda(), m1.cuda(), s2.cuda(), m2.cuda(), s3.cuda(), m3.cuda(), s4.cuda(), m4.cuda(), v1.cuda()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RHrsjKqKhR4"
      },
      "outputs": [],
      "source": [
        "# Build a test batch of random and manually-chosen questions\n",
        "varied_questions = make_varied_questions();\n",
        "\n",
        "\n",
        "# Run the sample batch, gather the cache\n",
        "main_model.reset_hooks()\n",
        "main_model.set_use_attn_result(True)\n",
        "sample_logits, sample_cache = main_model.run_with_cache(varied_questions.cuda())\n",
        "print(sample_cache) # Gives names of datasets in the cache\n",
        "sample_losses_raw, sample_max_prob_tokens = logits_to_tokens_loss(sample_logits, varied_questions.cuda())\n",
        "sample_loss_mean = utils.to_numpy(loss_fn(sample_losses_raw).mean())\n",
        "print(\"Sample Mean Loss\", sample_loss_mean) # Loss < 0.04 is good\n",
        "\n",
        "\n",
        "# attn.hook_z is the \"attention head output\" hook point name (at a specified layer)\n",
        "l_attn_hook_z_name = [utils.get_act_name('z', 0, 'a'),utils.get_act_name('z', 1, 'a'),utils.get_act_name('z', 2, 'a')] # 'blocks.0.attn.hook_z' etc\n",
        "sample_attn_z = sample_cache[l_attn_hook_z_name[0]]\n",
        "print(\"Sample\", l_attn_hook_z_name[0], sample_attn_z.shape) # gives [350, 22, 3, 170] = num_questions, cfg.n_ctx, n_heads, d_head\n",
        "mean_attn_z = torch.mean(sample_attn_z, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_attn_hook_z_name[0], mean_attn_z.shape) # gives [1, 22, 3, 170] = 1, cfg.n_ctx, n_heads, d_head\n",
        "\n",
        "\n",
        "# hook_resid_pre is the \"pre residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_pre_name = ['blocks.0.hook_resid_pre','blocks.1.hook_resid_pre','blocks.2.hook_resid_pre']\n",
        "\n",
        "\n",
        "# hook_resid_post is the \"post residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_post_name = ['blocks.0.hook_resid_post','blocks.1.hook_resid_post','blocks.2.hook_resid_post']\n",
        "sample_resid_post = sample_cache[l_hook_resid_post_name[0]]\n",
        "print(\"Sample\", l_hook_resid_post_name[0], sample_resid_post.shape) # gives [350, 22, 510] = num_questions, cfg.n_ctx, d_model\n",
        "mean_resid_post = torch.mean(sample_resid_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_hook_resid_post_name[0], mean_resid_post.shape) # gives [1, 22, 510] = 1, cfg.n_ctx, d_model\n",
        "\n",
        "\n",
        "# mlp.hook_post is the \"MLP layer\" hook point name (at a specified layer)\n",
        "l_mlp_hook_post_name = [utils.get_act_name('post', 0),utils.get_act_name('post', 1),utils.get_act_name('post', 2)] # 'blocks.0.mlp.hook_post' etc\n",
        "sample_mlp_hook_post = sample_cache[l_mlp_hook_post_name[0]]\n",
        "print(\"Sample\", l_mlp_hook_post_name[0], sample_mlp_hook_post.shape) # gives [350, 22, 2040] = num_questions, cfg.n_ctx, d_model*4\n",
        "mean_mlp_hook_post = torch.mean(sample_mlp_hook_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_mlp_hook_post_name[0], mean_mlp_hook_post.shape) # gives [1, 22, 2040] = 1, cfg.n_ctx, d_model*4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHQpt2iOqffb"
      },
      "outputs": [],
      "source": [
        "def tokens_to_unsigned_int( q, offset, digits ):\n",
        "  a = 0\n",
        "  for j in range(digits):\n",
        "    a = a * 10 + q[offset+j]\n",
        "  return a\n",
        "\n",
        "\n",
        "def tokens_to_signed_int( q, offset, digits ):\n",
        "  a = tokens_to_unsigned_int( q, offset+1, digits )\n",
        "  if q[offset] == MINUS_INDEX:\n",
        "    a = - a\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjhfLpSW9Jsq"
      },
      "outputs": [],
      "source": [
        "verbose = True\n",
        "\n",
        "class T_Config():\n",
        "  num_questions : int\n",
        "  correct_answers : int\n",
        "  total_mean_loss : float\n",
        "\n",
        "  sum_num_questions : int\n",
        "  sum_correct_answers : int\n",
        "\n",
        "  output = PrettyTable()\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0.0\n",
        "    self.sum_num_questions = 0\n",
        "    self.sum_correct_answers = 0\n",
        "\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Case\", \"#Questions\", \"#Correct\", \"%Correct\", \"Mean loss\"]\n",
        "\n",
        "\n",
        "  # Clear the question summary results\n",
        "  def clear_questions_results(self, title):\n",
        "    global verbose\n",
        "\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0\n",
        "\n",
        "    if verbose:\n",
        "      print(title)\n",
        "\n",
        "\n",
        "  # Print the question summary results\n",
        "  def print_questions_results(self, prefix):\n",
        "    self.output.add_row([prefix, self.num_questions, str(self.correct_answers), 100*self.correct_answers/self.num_questions, self.total_mean_loss/self.num_questions])\n",
        "    self.sum_num_questions += self.num_questions\n",
        "    self.sum_correct_answers += self.correct_answers\n",
        "\n",
        "\n",
        "  # Print the overall summary results\n",
        "  def print_overall_results(self):\n",
        "    self.output.add_row([\"OVERALL\", self.sum_num_questions, self.sum_correct_answers, \"\", \"\"])\n",
        "    print(self.output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "\n",
        "tcfg = T_Config()\n",
        "tcfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "# Ask model to predict answer for each question & collect results\n",
        "def do_questions(questions, show_failures = False):\n",
        "  global verbose\n",
        "  global tcfg\n",
        "\n",
        "  tcfg.num_questions = questions.shape[0]\n",
        "\n",
        "  # Run with no hook\n",
        "  all_logits = main_model(questions.cuda())\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  for question_num in range(tcfg.num_questions):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    losses = loss_fn(all_losses_raw[question_num])\n",
        "    mean_loss = utils.to_numpy(losses.mean())\n",
        "    tcfg.total_mean_loss += mean_loss\n",
        "\n",
        "    model_answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "    model_answer_num = int(model_answer_str)\n",
        "\n",
        "    # 6 digit addition yields a 7 digit answer. Hence cfg.n_digits+1\n",
        "    a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "\n",
        "    correct = (model_answer_num == a)\n",
        "    if correct :\n",
        "      tcfg.correct_answers += 1\n",
        "\n",
        "    if verbose or (show_failures and not correct):\n",
        "      print(tokens_to_string(q), \"ModelAnswer:\", model_answer_str, \"Correct:\", correct, \"Loss:\", mean_loss )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lag8C3d_KkeQ"
      },
      "source": [
        "# Part 9: Prediction Analysis By Use Case\n",
        "This section runs addition (BA, UC1 and US9) and subtraction (BS, B1, C1, CN) test cases to show which uses cases the model can handle."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_question_results( title, questions, show_failures = False):\n",
        "  tcfg.clear_questions_results(title)\n",
        "  do_questions(questions, show_failures)\n",
        "  tcfg.print_questions_results(title)"
      ],
      "metadata": {
        "id": "oN3mEnSRF0DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6RdolRKnnR"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_add() > 0:\n",
        "  print( \"ADDITION:\")\n",
        "\n",
        "  tcfg.reset()\n",
        "  print_question_results(\"Add.S*: All addition cases\", make_addition_questions(), True)\n",
        "  tcfg.print_overall_results()\n",
        "\n",
        "  tcfg.reset()\n",
        "  print_question_results(\"Add.S0: Only use BA\", make_s0_questions())\n",
        "  print_question_results(\"Add.S1: BA and MC. No US\", make_s1_questions())\n",
        "  print_question_results(\"Add.S2: BA, MC and 1 x US\", make_s2_questions())\n",
        "  print_question_results(\"Add.S3,S4,S5: BA, MC and 2,3,4 x US\", make_s3plus_questions())\n",
        "  print_question_results(\"Add.SN: Cover different answer digits\", make_sn_questions())\n",
        "  tcfg.print_overall_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW2SNwxJ-3Kn"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_sub > 0:\n",
        "  print( \"SUBTRACTION:\")\n",
        "\n",
        "  tcfg.reset()\n",
        "  print_question_results(\"Sub.M*,NG: All subtraction cases\", make_subtraction_questions(), True)\n",
        "  tcfg.print_overall_results()\n",
        "\n",
        "  tcfg.reset()\n",
        "  print_question_results(\"Sub.M0: Only use BS\", make_m0_questions())\n",
        "  print_question_results(\"Sub.M1: BS & B1 only\", make_m1_questions())\n",
        "  print_question_results(\"Sub.M2: BS, B1 and 1 x DZ\", make_m2_questions())\n",
        "  print_question_results(\"Sub.M3,M4,M5: BS, B1 and 2,3,4 x DZ\", make_m3plus_questions())\n",
        "  print_question_results(\"Sub.Neg: Negative answer\", make_ng_questions())\n",
        "  tcfg.print_overall_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyK7QeUjLLFm"
      },
      "source": [
        "# Part 11: Set Up \"Count\" Framework\n",
        "\n",
        "Create way to get model to predict sample question answers and analysis/show results. Use prefix \"c_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYPI4tw0LNhV"
      },
      "outputs": [],
      "source": [
        "# Build up a list of success/failure by case (BA, MC1, US9) found, and the frequency of each case\n",
        "c_case_counts = {}\n",
        "\n",
        "\n",
        "def count_question_cases(questions):\n",
        "  global c_case_counts\n",
        "\n",
        "  c_case_counts = {}\n",
        "\n",
        "  for i in range(questions.shape[0]):\n",
        "    q_case = get_question_case(questions[i])\n",
        "\n",
        "    if q_case in c_case_counts:\n",
        "      # If the key is already in the dictionary, increment its count\n",
        "      c_case_counts[q_case] += 1\n",
        "    else:\n",
        "      # If the key is not in the dictionary, add it with a count of 1\n",
        "      c_case_counts[q_case] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXEfGBMLPFW"
      },
      "outputs": [],
      "source": [
        "# Compare each digit in the answer. Returns a A+45 pattern where '+' means a failed sign and '4' means a failed 4th digit\n",
        "def get_digit_accuracy_impact(a_int, answer_str):\n",
        "  a_str = str(a_int.cpu().numpy()).zfill(cfg.n_digits+1)\n",
        "  match_str = \"A\"\n",
        "  for i in range(cfg.n_digits+1):\n",
        "    match_str += \"\" if answer_str[i] == a_str[i] else str(cfg.n_digits-i)\n",
        "\n",
        "    #pqr handle+/-mismatch\n",
        "\n",
        "  return \"\" if match_str == \"A\" else match_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liT_UbPOLRhO"
      },
      "outputs": [],
      "source": [
        "# Build up a list of success/failure digit-patterns found, and the frequency of each pattern\n",
        "c_pattern_fails = {}\n",
        "\n",
        "\n",
        "def clear_pattern_fails():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  c_pattern_fails = {}\n",
        "\n",
        "\n",
        "def add_pattern_fail(match_str):\n",
        "  global c_pattern_fails\n",
        "\n",
        "  if match_str in c_pattern_fails:\n",
        "    # If the key is already in the dictionary, increment its count\n",
        "    c_pattern_fails[match_str] += 1\n",
        "  else:\n",
        "    # If the key is not in the dictionary, add it with a count of 1\n",
        "    c_pattern_fails[match_str] = 1\n",
        "\n",
        "\n",
        "def get_pattern_fails():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  results = \"\"\n",
        "  top_result = \"\"\n",
        "  if len(c_pattern_fails) > 0 :\n",
        "    sorted_fails = dict(sorted(c_pattern_fails.items(), key=lambda item: item[1], reverse=True))\n",
        "    for key, value in sorted_fails.items():\n",
        "      this_cell = key + \"=\" + str(value)\n",
        "\n",
        "      results = results + this_cell + \" \"\n",
        "\n",
        "      if top_result == \"\":\n",
        "        top_result = this_cell\n",
        "      else:\n",
        "        top_result = top_result + \", \" + this_cell\n",
        "\n",
        "  return results, top_result\n",
        "\n",
        "\n",
        "def get_pattern_fails_total():\n",
        "  global c_pattern_fails\n",
        "\n",
        "  if len(c_pattern_fails) == 0:\n",
        "    return 0\n",
        "\n",
        "  total_sum = 0\n",
        "  for key, value in c_pattern_fails.items():\n",
        "      if isinstance(value, int):\n",
        "          total_sum += value\n",
        "  return total_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TudM4_8PLTh1"
      },
      "outputs": [],
      "source": [
        "# Build up a count of failure cases\n",
        "c_case_fails = {}\n",
        "\n",
        "\n",
        "def clear_case_fails():\n",
        "  global c_case_fails\n",
        "\n",
        "  c_case_fails = {}\n",
        "\n",
        "\n",
        "def add_case_fail(case_key):\n",
        "  global c_case_fails\n",
        "\n",
        "  if case_key in c_case_fails:\n",
        "    # If the key is already in the dictionary, increment its count\n",
        "    c_case_fails[case_key] += 1\n",
        "  else:\n",
        "    # If the key is not in the dictionary, add it with a count of 1\n",
        "    c_case_fails[case_key] = 1\n",
        "\n",
        "\n",
        "def total_case_fails():\n",
        "  global c_case_fails\n",
        "\n",
        "  answer = 0\n",
        "  for _, value in c_case_fails.items():\n",
        "    answer = answer + value\n",
        "  return answer\n",
        "\n",
        "\n",
        "def get_case_fails():\n",
        "  global c_case_fails\n",
        "  global c_case_counts\n",
        "\n",
        "  results = \"\"\n",
        "  num_results = len(c_case_fails)\n",
        "  if num_results > 0:\n",
        "    sorted_fails = dict(sorted(c_case_fails.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    for key, value in sorted_fails.items():\n",
        "      percent = round(100 * value / c_case_counts[key])\n",
        "      results = results + \"%\" + key + \"=\" + str(percent)+ \" \"\n",
        "\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF5JmP8ne2GK"
      },
      "outputs": [],
      "source": [
        "def predict_experiment_question(questions, the_hook, the_threshold, tag = \"\"):\n",
        "\n",
        "  c_loss_mean = 0\n",
        "\n",
        "  clear_case_fails()\n",
        "  clear_pattern_fails()\n",
        "\n",
        "  count_question_cases(questions)\n",
        "\n",
        "  main_model.reset_hooks()\n",
        "  main_model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = main_model.run_with_hooks(questions.cuda(), return_type=\"logits\", fwd_hooks=the_hook)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  answer_str = \"\"\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    c_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if c_loss_mean > the_threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      # 5 digit addition yields a 6 digit answer. Hence cfg.n_digits+1\n",
        "      a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "\n",
        "      match_str = get_digit_accuracy_impact( a, answer_str )\n",
        "      # Only count the question if the model got the question wrong\n",
        "      if 'A' in match_str:\n",
        "        the_case = get_question_case(q)\n",
        "        add_case_fail(the_case)\n",
        "        add_pattern_fail(match_str)\n",
        "\n",
        "        if verbose :\n",
        "          print(tokens_to_string(q), \"ModelAnswer:\", answer_str, \"Matches:\", match_str, \"Loss:\", c_loss_mean, \"Case:\", the_case )\n",
        "\n",
        "  return c_loss_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 12: Ablate ALL Heads in EACH token position. What is the impact on Loss?\n",
        "\n",
        "Here we ablate all heads in each token position (overriding the model memory aka residual stream) and see if loss increases. If loss increases the token position is used by the algorithm. Unused token positions can be excluded from further analysis. Use \"C_\" prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7LwECBLajQ"
      },
      "outputs": [],
      "source": [
        "class C_Config():\n",
        "  position : int = 0  # zero-based token position to ablate\n",
        "  threshold : float = 0.01\n",
        "  questions = varied_questions\n",
        "  output = PrettyTable()\n",
        "  perc_list = []\n",
        "  hook_calls : int = 0\n",
        "\n",
        "  min_useful_position : int = -1 # Minimum useful position where loss increases on ablation\n",
        "  max_useful_position : int = -1 # Maximum useful position where loss increases on ablation\n",
        "\n",
        "\n",
        "  def get_column_headings(self):\n",
        "    datums = [\"Position\"]\n",
        "    for i in range(self.min_useful_position, self.max_useful_position+1):\n",
        "      datums = datums + [\"P\"+str(i)]\n",
        "    return datums\n",
        "\n",
        "\n",
        "ccfg = C_Config()\n",
        "ccfg.output.field_names = [\"Position\", \"Fails\", \"% Fails by Case\", \"# Fails by Patterns\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "\n",
        "def c_set_resid_post_hook(value, hook):\n",
        "  global ccfg\n",
        "\n",
        "  #print( \"In hook\", l_hook_resid_post_name[ccfg.layer], ccfg.ablate, ccfg.position, value.shape) # Get [64, 22, 510] = cfg.batch_size, num_tokens, d_model\n",
        "\n",
        "  # Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,ccfg.position,:] = mean_resid_post[0,ccfg.position,:].clone()\n",
        "\n",
        "\n",
        "num_questions = 0\n",
        "if cfg.n_digits >= 5 :\n",
        "  c_fwd_hooks = [(l_hook_resid_post_name[0], c_set_resid_post_hook)] if cfg.n_layers == 1 else [(l_hook_resid_post_name[0], c_set_resid_post_hook),(l_hook_resid_post_name[1], c_set_resid_post_hook)]\n",
        "\n",
        "  num_questions = ccfg.questions.shape[0]\n",
        "\n",
        "  for ccfg.position in range(cfg.n_ctx):\n",
        "    clear_case_fails()\n",
        "    clear_pattern_fails()\n",
        "\n",
        "    loss_mean = predict_experiment_question(ccfg.questions, c_fwd_hooks, ccfg.threshold)\n",
        "\n",
        "    num_fails = total_case_fails()\n",
        "    perc_fails = 0\n",
        "    if num_fails > 0:\n",
        "      perc_fails = round(100 * num_fails / num_questions)\n",
        "\n",
        "      if ccfg.min_useful_position == -1:\n",
        "        ccfg.min_useful_position = ccfg.position\n",
        "      ccfg.max_useful_position = ccfg.position\n",
        "\n",
        "    ccfg.perc_list = ccfg.perc_list + [perc_fails]\n",
        "\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "    ccfg.output.add_row([str(ccfg.position), str(perc_fails)+\"%\", get_case_fails(), pattern_results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_questions, \"min_useful_position=\", ccfg.min_useful_position, \"max_useful_position=\", ccfg.max_useful_position )\n",
        "print()\n",
        "\n",
        "plt.hist(ccfg.perc_list, cfg.n_ctx, facecolor='blue', alpha=0.5)\n",
        "plt.xlabel('Position')\n",
        "plt.ylabel('Probability')\n",
        "plt.title(r'Histogram of IQ: $\\mu=100$, $\\sigma=15$')\n",
        "# Tweak spacing to prevent clipping of ylabel\n",
        "plt.subplots_adjust(left=0.15)\n",
        "plt.show()\n",
        "\n",
        "print(ccfg.output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 13: Setup: Cell matrix\n",
        "\n",
        "Uses \"u_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def table_row(the_layer, the_head):\n",
        "  return the_layer * (cfg.n_heads+1) + the_head\n",
        "\n",
        "def table_rows():\n",
        "  return (cfg.n_heads + 1) * cfg.n_layers\n",
        "\n",
        "def table_cols():\n",
        "  return ccfg.max_useful_position - ccfg.min_useful_position + 1"
      ],
      "metadata": {
        "id": "Y6YaMsQKpUk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UsefulCell():\n",
        "  # Is this cell an attention head? If not, it must be an MLP layer\n",
        "  is_head: bool = True\n",
        "\n",
        "  # Position.Layer.Head of the cell\n",
        "  position: int = -1  # token-position. Zero to cfg.n_ctx - 1\n",
        "  layer: int = -1\n",
        "  head: int = -1\n",
        "\n",
        "  # Tags related to the cell\n",
        "  tags = []\n",
        "\n",
        "\n",
        "  # Row in a table that this cell is drawn\n",
        "  def cell_row(self):\n",
        "    return table_row(self.layer, self.head)\n",
        "\n",
        "\n",
        "  # Add a tag to this cell (if not already present)\n",
        "  def add_tag(self, tag):\n",
        "    if tag != \"\" and (not (tag in self.tags)):\n",
        "      self.tags += [tag]\n",
        "\n",
        "\n",
        "  def min_tag_suffix(self, prefix):\n",
        "    # Filter strings that start with the given prefix\n",
        "    filtered_strings = [s for s in self.tags if s.startswith(prefix)]\n",
        "\n",
        "    # Extract suffixes\n",
        "    suffixes = [s.split('.')[1] for s in filtered_strings]\n",
        "\n",
        "    # Return the minimum suffix if there are any, else return None\n",
        "    return min(suffixes) if suffixes else \"\""
      ],
      "metadata": {
        "id": "i2gWgm-2J0Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTaSo-UzLlZ_"
      },
      "outputs": [],
      "source": [
        "class U_Config():\n",
        "  # This is a head+MLP (row) by token (column) matrix of percent of failure percentages with associated notes\n",
        "  fail_percs = [[]]\n",
        "  fail_notes = [[]]\n",
        "  num_heads : int\n",
        "  num_mlps : int\n",
        "\n",
        "  # We (once) calculate the list of cells (attention head and MLP layers per position) that are useful to the model.\n",
        "  calc_useful_cells = True\n",
        "  # Once this list of useful cells is calculated (available) it is used to speed up functions.\n",
        "  useful_cells = []\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.fail_percs = [[0 for _ in range(cfg.n_ctx)] for _ in range((cfg.n_heads + 1) * cfg.n_layers)]\n",
        "    self.fail_notes = [[\"\" for _ in range(cfg.n_ctx)] for _ in range((cfg.n_heads + 1) * cfg.n_layers)]\n",
        "    self.num_heads = 0\n",
        "    self.num_mlps = 0\n",
        "\n",
        "    if self.calc_useful_cells:\n",
        "      self.useful_cells = []\n",
        "\n",
        "\n",
        "  def reset_tags(self):\n",
        "    for cell in self.useful_cells:\n",
        "      cell.tags = []\n",
        "\n",
        "\n",
        "  def get_cell( self, the_position, the_row ):\n",
        "    for cell in self.useful_cells:\n",
        "      if cell.position == the_position and cell.cell_row() == the_row:\n",
        "        return cell\n",
        "\n",
        "    return UsefulCell()\n",
        "\n",
        "\n",
        "  def add_fail_perc( self, the_position, the_layer, the_head, perc_fails, notes, tag ):\n",
        "    if perc_fails >= 1:\n",
        "      the_row = table_row(the_layer, the_head)\n",
        "\n",
        "      self.fail_percs[the_row][the_position] = perc_fails\n",
        "      self.fail_notes[the_row][the_position] = notes\n",
        "\n",
        "      if self.calc_useful_cells:\n",
        "        # Add this  usefil cell. Check that we do not already have a cell at that row/col\n",
        "        assert self.get_cell( the_position, the_row).position < 0\n",
        "\n",
        "        new_cell = UsefulCell()\n",
        "        new_cell.is_head = the_head != cfg.n_heads\n",
        "        new_cell.position = the_position\n",
        "        new_cell.layer = the_layer\n",
        "        new_cell.head = the_head\n",
        "        new_cell.add_tag(tag)\n",
        "\n",
        "        self.useful_cells += [new_cell]\n",
        "      else:\n",
        "        self.get_cell(the_position,the_row).add_tag(tag)\n",
        "\n",
        "\n",
        "  def add_head_fail_perc( self, the_position, the_layer, the_head, perc_fails, notes, tag ):\n",
        "    self.add_fail_perc( the_position, the_layer, the_head, perc_fails, notes, tag )\n",
        "    self.num_heads += 1\n",
        "\n",
        "\n",
        "  def add_mlp_fail_perc( self, the_position, the_layer, perc_fails, notes, tag ):\n",
        "    self.add_fail_perc( the_position, the_layer, cfg.n_heads, perc_fails, notes, tag )\n",
        "    self.num_mlps += 1\n",
        "\n",
        "\n",
        "ucfg = U_Config()\n",
        "ucfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "# Print a 2 by 2 matrix of the percentage failures.\n",
        "def print_u_fail_percs(title):\n",
        "  global ucfg\n",
        "  global ccfg\n",
        "\n",
        "  print(title, \"% failures when each head & MLP in each position is ablated: #FailedHeads=\", ucfg.num_heads, \"#FailedMlps=\", ucfg.num_mlps )\n",
        "\n",
        "  fig1, ax1 = show_2d_map_start(12, 2*cfg.n_layers) # Width, Height in inches\n",
        "\n",
        "  # Generate a sequence of colors from green to red\n",
        "  shades = 10\n",
        "  colors = [plt.cm.RdYlGn(i/10) for i in range(shades)]\n",
        "\n",
        "  # Add cells\n",
        "  for i in range(table_rows()):\n",
        "      for j in range(table_cols()):\n",
        "        value = ucfg.fail_percs[i][ccfg.min_useful_position+j]\n",
        "        if value == 100 and table_cols() > 15:\n",
        "          value = 99 # Avoid overlapping figures in the matrix.\n",
        "\n",
        "        cell_color = 'lightgrey'  # Color for empty cells\n",
        "        if value > 0:\n",
        "            color_index = value // shades\n",
        "            cell_color = colors[color_index]\n",
        "            cell_text = str(value)+\"%\"\n",
        "            ax1.text(j + 0.5, i + 0.5, cell_text, ha='center', va='center', color='black')\n",
        "\n",
        "        ax1.add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color=cell_color))\n",
        "\n",
        "  show_2d_map_end(title, fig1, ax1, ccfg.min_useful_position, ccfg.max_useful_position )\n",
        "\n",
        "\n",
        "\n",
        "# Print a 2 by 2 matrix of notes.\n",
        "def print_u_fail_notes():\n",
        "  global ucfg\n",
        "  global ccfg\n",
        "\n",
        "  print(\"The most common failure pattern (with associated failure #) when each head or MLP in each position is ablated\")\n",
        "\n",
        "  cell_output = PrettyTable()\n",
        "  cell_output.field_names = ccfg.get_column_headings()\n",
        "\n",
        "  for i in range((cfg.n_heads + 1) * cfg.n_layers):\n",
        "    datums = [get_row_heading(i)]\n",
        "    for j in range(ccfg.min_useful_position, ccfg.max_useful_position+1):\n",
        "      datums = datums + [ucfg.fail_notes[i][j]]\n",
        "    cell_output.add_row(datums)\n",
        "\n",
        "  print(cell_output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99LIC1l4MD32"
      },
      "source": [
        "# Part 14: Setup: Ablate each MLP in EACH position. Impact on Loss?\n",
        "Ablating the MLP in each layer in each position and seeing if the loss increases shows which head+layer+MLP are used by the algorithm. Use \"m_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaB1fAWbxqWe"
      },
      "outputs": [],
      "source": [
        "class M_Config():\n",
        "  position : int  # zero-based token-position to ablate\n",
        "  layer : int # zero-based layer to ablate. 0 to cfg.n_layers\n",
        "  threshold : float\n",
        "  output = PrettyTable()\n",
        "  hook_calls : int\n",
        "  questions = varied_questions\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.position = 0\n",
        "    self.layer = 0\n",
        "    self.threshold = 0.12\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Position\", \"MLP Layer\", \"% Fails\", \"% Fails by Case\", \"# Fails by Patterns\"]\n",
        "    self.hook_calls = 0\n",
        "\n",
        "\n",
        "mcfg = M_Config()\n",
        "mcfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOxNc9SAMGRH"
      },
      "outputs": [],
      "source": [
        "def m_mlp_hook_post(value, hook):\n",
        "  global mcfg\n",
        "\n",
        "  mcfg.hook_calls += 1\n",
        "  #print( \"In m_mlp_hook_post\", value.shape) # Get [1, 22, 2040] = ???, cfg.n_ctx, ???\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to the MLP\n",
        "  value[:,mcfg.position,:] =  mean_mlp_hook_post[:,mcfg.position,:].clone()\n",
        "\n",
        "\n",
        "def m_perform_core(tag):\n",
        "  clear_case_fails()\n",
        "  clear_pattern_fails()\n",
        "\n",
        "  the_hook = [(l_mlp_hook_post_name[mcfg.layer], m_mlp_hook_post)]\n",
        "  loss_mean = predict_experiment_question(mcfg.questions, the_hook, mcfg.threshold, tag)\n",
        "\n",
        "  num_fails = total_case_fails()\n",
        "  if num_fails > 0:\n",
        "    perc_fails = round(100 * num_fails / mcfg.questions.shape[0])\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "\n",
        "    mcfg.output.add_row([str(mcfg.position), str(mcfg.layer), perc_fails, get_case_fails(), pattern_results])\n",
        "\n",
        "    ucfg.add_mlp_fail_perc( mcfg.position, mcfg.layer, perc_fails, top_pattern, tag )\n",
        "\n",
        "\n",
        "def m_perform_all():\n",
        "  ucfg.reset()\n",
        "  mcfg.reset()\n",
        "  for mcfg.position in range(cfg.n_ctx):\n",
        "    for mcfg.layer in range(cfg.n_layers):\n",
        "      m_perform_core(\"\")\n",
        "\n",
        "\n",
        "def m_perform_useful(tag):\n",
        "  ucfg.reset()\n",
        "  mcfg.reset()\n",
        "  for useful_cell in ucfg.useful_cells:\n",
        "    if not useful_cell.is_head:\n",
        "      mcfg.position = useful_cell.position\n",
        "      mcfg.layer = useful_cell.layer\n",
        "      m_perform_core(tag)\n",
        "\n",
        "\n",
        "def m_print_results(title):\n",
        "  if verbose:\n",
        "    print_config()\n",
        "    print()\n",
        "    print(title, mcfg.questions.shape[0])\n",
        "    print(mcfg.output.get_formatted_string(out_format=cfg.table_out_format))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKZF_B6OMIq3"
      },
      "source": [
        "# Part 15: Setup: Ablate EACH head in EACH position. Impact on Digit & Task Loss?\n",
        "Ablating each head in each layer in each position and seeing if the loss increases shows which position+layer+head are used by the algorithm. Use \"h_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHdJEIw1yMXn"
      },
      "outputs": [],
      "source": [
        "class H_Config():\n",
        "  position : int # zero-based token position to ablate. 0 to cfg.n_ctx - 1\n",
        "  layer : int # zero-based layer to ablate. 0 to cfg.n_layers - 1\n",
        "  head : int # zero-based head to ablate. 0 to cfg.n_heads - 1\n",
        "  threshold : float\n",
        "  output = PrettyTable()\n",
        "  hook_calls: int\n",
        "  questions = varied_questions\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.position = 0 # zero-based token position to ablate. 0 to say 17\n",
        "    self.layer = 0 # zero-based layer to ablate. 0 to 1\n",
        "    self.head = 0 # zero-based head to ablate. 0 to 2\n",
        "    self.threshold = 0.12\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Position\", \"Layer\", \"Head\", \"% Fails\", \"% Fails by Case\", \"# Fails by Impact\"]\n",
        "    self.hook_calls = 0\n",
        "\n",
        "\n",
        "  def print_results(self, title):\n",
        "    if verbose:\n",
        "      print_config()\n",
        "      print()\n",
        "      print(title, self.questions.shape[0], \"#hook_calls=\", self.hook_calls)\n",
        "      print(self.output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "\n",
        "hcfg = H_Config()\n",
        "hcfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EnisO6MMGQ"
      },
      "outputs": [],
      "source": [
        "def h_set_attn_hook_z(value, hook):\n",
        "\n",
        "  hcfg.hook_calls += 1\n",
        "  # print( \"In h_set_attn_hook_z\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,hcfg.position,hcfg.head,:] = mean_attn_z[:,hcfg.position,hcfg.head,:].clone()\n",
        "\n",
        "\n",
        "def h_perform_core(tag):\n",
        "  clear_case_fails()\n",
        "  clear_pattern_fails()\n",
        "\n",
        "  the_hook = [(l_attn_hook_z_name[hcfg.layer], h_set_attn_hook_z)]\n",
        "  loss_mean = predict_experiment_question(hcfg.questions, the_hook, hcfg.threshold, tag)\n",
        "\n",
        "  num_fails = total_case_fails()\n",
        "  if num_fails > 0:\n",
        "    perc_fails = round(100 * num_fails / hcfg.questions.shape[0])\n",
        "    (pattern_results, top_pattern) = get_pattern_fails()\n",
        "\n",
        "    hcfg.output.add_row([str(hcfg.position), str(hcfg.layer), str(hcfg.head), perc_fails, get_case_fails(), pattern_results])\n",
        "\n",
        "    ucfg.add_head_fail_perc( hcfg.position, hcfg.layer, hcfg.head, perc_fails, top_pattern, tag)\n",
        "\n",
        "\n",
        "def h_perform_all():\n",
        "  hcfg.reset()\n",
        "  for hcfg.position in range(ccfg.min_useful_position, ccfg.max_useful_position+1):\n",
        "    for hcfg.layer in range(cfg.n_layers):\n",
        "      for hcfg.head in range(cfg.n_heads):\n",
        "        h_perform_core(\"\")\n",
        "\n",
        "\n",
        "def h_perform_useful(tag):\n",
        "  hcfg.reset()\n",
        "  for useful_cell in ucfg.useful_cells:\n",
        "    if useful_cell.is_head:\n",
        "      hcfg.position = useful_cell.position\n",
        "      hcfg.layer = useful_cell.layer\n",
        "      hcfg.head = useful_cell.head\n",
        "      h_perform_core(tag)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16: Calculate show cell matrixes\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Uluv96KMQJS"
      },
      "outputs": [],
      "source": [
        "def calc_cell_matrices(tag, questions, all_cells):\n",
        "\n",
        "  mcfg.questions = questions\n",
        "  if all_cells:\n",
        "    m_perform_all()\n",
        "  else:\n",
        "    m_perform_useful(tag)\n",
        "  m_print_results(tag)\n",
        "\n",
        "  hcfg.questions = questions\n",
        "  if all_cells:\n",
        "    h_perform_all()\n",
        "  else:\n",
        "    h_perform_useful(tag)\n",
        "  hcfg.print_results(tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE64pXy1MRsw"
      },
      "outputs": [],
      "source": [
        "def print_cell_matrices(title):\n",
        "  print_config()\n",
        "  print()\n",
        "  print_u_fail_percs(title)\n",
        "  print()\n",
        "  print_u_fail_notes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi"
      },
      "outputs": [],
      "source": [
        "def run_cell_matrices():\n",
        "  global verbose\n",
        "\n",
        "  verbose = False\n",
        "\n",
        "  ucfg.calc_useful_cells = True\n",
        "  calc_cell_matrices(\"Varied\", varied_questions, True)\n",
        "  ucfg.calc_useful_cells = False\n",
        "\n",
        "  print_cell_matrices(\"Varied\")\n",
        "\n",
        "\n",
        "run_cell_matrices()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_and_print_cell_matrices(tag, questions):\n",
        "  calc_cell_matrices(tag, questions, False)\n",
        "  print_cell_matrices(tag)"
      ],
      "metadata": {
        "id": "rCGPzHBlfTZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1S8LoDMXEC"
      },
      "source": [
        "# Part 17A - Case Analysis\n",
        "Processing Addition and Subtraction questions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ucfg.reset_tags()"
      ],
      "metadata": {
        "id": "HzKUwZcLH3R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utqnefc2MYxl"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_and_print_cell_matrices(\"Add.S0\", make_s0_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biUdemo5MZAz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_and_print_cell_matrices(\"Add.S1\", make_s1_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rV1zYsCeMarq"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_and_print_cell_matrices(\"Add.S2\", make_s2_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjLzcox9McGN"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  calc_and_print_cell_matrices(\"Add.S3+\", make_s3plus_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CjctKSc7CzC"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_and_print_cell_matrices(\"Sub.M0\", make_m0_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNQvplU87Lkp"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_and_print_cell_matrices(\"Sub.M1\", make_m1_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL53nb9i7Ln6"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_and_print_cell_matrices(\"Sub.M2\", make_m2_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTowAUvI7LrI"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_and_print_cell_matrices(\"Sub.M3+\", make_m3plus_questions())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZBuAuVa7Luu"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  calc_and_print_cell_matrices(\"Sub.NG\", make_ng_questions())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qs = make_m0_questions()\n",
        "\n",
        "#verbose = True\n",
        "print_question_results(\"\", qs)\n",
        "calc_and_print_cell_matrices(\"UnitTest\", qs)"
      ],
      "metadata": {
        "id": "AUIyIz9kRLpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process varied_questions random-questions here in case they include new edge cases not covered in the above hand-crafted questions\n",
        "verbose = True\n",
        "\n",
        "hcfg.reset()\n",
        "hcfg.position = 0\n",
        "hcfg.layer = 0\n",
        "\n",
        "print(\"Head 0\")\n",
        "hcfg.head = 0\n",
        "hcfg.questions = v0\n",
        "h_perform_core(\"??.??\")\n",
        "hcfg.questions = v1\n",
        "h_perform_core(\"??.??\")\n",
        "\n",
        "print(\"Head 1\")\n",
        "hcfg.head = 2\n",
        "hcfg.questions = v0\n",
        "h_perform_core(\"??.??\")\n",
        "hcfg.questions = v1\n",
        "h_perform_core(\"??.??\")"
      ],
      "metadata": {
        "id": "z026qbiRSvem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 17B - Quanta Analysis\n",
        "Show the \"minimum\" addition purpose of each useful cell by S0 to S5 quanta.\n",
        "Show the \"minimum\" subtraction purpose of each useful cell by M0 to M5 quanta"
      ],
      "metadata": {
        "id": "v7-99ZxDOrbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_quanta_tags( tag_prefix, file_prefix):\n",
        "  fig1, ax1 = show_2d_map_start(12, 2*cfg.n_layers) # Width, Height in inches\n",
        "\n",
        "  # Generate a sequence of colors from green to red\n",
        "  shades = 6\n",
        "  colors = [plt.cm.RdYlGn(i/10) for i in range(shades)]\n",
        "\n",
        "  # Add cells\n",
        "  for i in range(table_rows()):\n",
        "    for j in range(table_cols()):\n",
        "      cell_color = 'lightgrey'  # Color for empty cells\n",
        "\n",
        "      cell = ucfg.get_cell( ccfg.min_useful_position+j, i )\n",
        "      if cell.position >= 0:\n",
        "        suffix = cell.min_tag_suffix( tag_prefix )\n",
        "        if suffix != \"\":\n",
        "          color_index = int(suffix[1]) if len(suffix) > 1 and suffix[1].isdigit() else 0\n",
        "          cell_color = colors[color_index]\n",
        "          ax1.text(j + 0.5, i + 0.5, suffix, ha='center', va='center', color='black')\n",
        "\n",
        "      ax1.add_patch(plt.Rectangle((j, i), 1, 1, fill=True, color=cell_color))\n",
        "\n",
        "  show_2d_map_end(file_prefix, fig1, ax1, ccfg.min_useful_position, ccfg.max_useful_position )\n"
      ],
      "metadata": {
        "id": "0tAJl0eYO96W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  draw_quanta_tags( \"Add\", \"Add.All\")"
      ],
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  draw_quanta_tags( \"Sub\", \"Sub.All\")"
      ],
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSY3blNMe7I"
      },
      "source": [
        "#Part 18: SetUp: Calc and graph PCA decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiBsiQAMhS_"
      },
      "outputs": [],
      "source": [
        "tn_questions = 100\n",
        "\n",
        "\n",
        "def make_t_questions(test_digit, test_case, operation):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "\n",
        "\n",
        "      if operation == PLUS_INDEX:\n",
        "        if test_case == 8:\n",
        "          # These are n_digit addition questions where the first test_digits add up from 0 to 8\n",
        "          x = random.randint(0, 8)\n",
        "          y = random.randint(0, 8-x)\n",
        "        if test_case == 9:\n",
        "          # These are n_digit addition questions where the first test_digits add up to 9\n",
        "          x = random.randint(0, 9)\n",
        "          y = 9 - x\n",
        "        if test_case == 10:\n",
        "          # These are n_digit addition questions where the first test_digits add up to 10 to 18\n",
        "          x = random.randint(1, 9)\n",
        "          y = random.randint(10-x, 9)\n",
        "\n",
        "\n",
        "      if operation == MINUS_INDEX:\n",
        "        if test_case == 8:\n",
        "          # These are n_digit subtraction questions where the first test_digits difference is negative\n",
        "          x = random.randint(0, 8)\n",
        "          y = random.randint(x+1, 9)\n",
        "        if test_case == 9:\n",
        "          # These are n_digit subtraction questions where the first test_digits difference is zero\n",
        "          x = random.randint(0, 9)\n",
        "          y = x\n",
        "        if test_case == 10:\n",
        "          # These are n_digit subtraction questions where the first test_digits difference is positive\n",
        "          x = random.randint(0, 9)\n",
        "          y = random.randint(0, x-1)\n",
        "\n",
        "\n",
        "      # Randomise the last test_digits-1 digits of both numbers\n",
        "      x = x * limit + random.randint(0, limit-1)\n",
        "      y = y * limit + random.randint(0, limit-1)\n",
        "      questions.append([x, y])\n",
        "    return make_questions(questions, operation)\n",
        "\n",
        "\n",
        "\n",
        "def make_tricase_questions(test_digit, operation):\n",
        "  q1 = make_t_questions(test_digit, 8, operation)\n",
        "  q2 = make_t_questions(test_digit, 9, operation)\n",
        "  q3 = make_t_questions(test_digit, 10, operation)\n",
        "\n",
        "  questions = torch.vstack((q1, q2, q3))\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCPgoQZMjgc"
      },
      "outputs": [],
      "source": [
        "# Do one Principal Component Analysis\n",
        "def calc_tricase_pca(t_position, t_layer, t_head, t_digit, operation):\n",
        "  global tn_questions\n",
        "\n",
        "  t_questions = make_tricase_questions(t_digit, operation)\n",
        "\n",
        "  t_logits, t_cache = main_model.run_with_cache(t_questions)\n",
        "\n",
        "  # Gather attention patterns for all the (randomly chosen) questions\n",
        "  attention_outputs = []\n",
        "  for i in range(len(t_questions)):\n",
        "\n",
        "    # Output of individual heads, without final bias\n",
        "    attention_cache=t_cache[\"result\", t_layer, \"attn\"] # Output of individual heads, without final bias\n",
        "    attention_output=attention_cache[i]  # Shape [n_ctx, n_head, d_model]\n",
        "    attention_outputs.append(attention_output[t_position, t_head, :])\n",
        "\n",
        "  attn_outputs = torch.stack(attention_outputs, dim=0).cpu()\n",
        "\n",
        "  pca = PCA(n_components=6)\n",
        "  pca.fit(attn_outputs)\n",
        "  pca_attn_outputs = pca.transform(attn_outputs)\n",
        "\n",
        "  title = tokens_to_string([operation]) + 'P' + str(t_position) + '.L' + str(t_layer) + '.H'+str(t_head) + ', A'+str(t_digit) + ', EVR[0]=' + str(int(round(pca.explained_variance_ratio_[0]*100,0))) + '%'\n",
        "\n",
        "  return (pca, pca_attn_outputs, title)\n",
        "\n",
        "\n",
        "# Plot one PCA scatter graph\n",
        "def graph_pca(pca, pca_attn_outputs, ax, title):\n",
        "  global tn_questions\n",
        "\n",
        "  ax.scatter(pca_attn_outputs[:tn_questions, 0], pca_attn_outputs[:tn_questions, 1], color='red', label='T8 (0-8)') # t8 questions\n",
        "  ax.scatter(pca_attn_outputs[tn_questions:2*tn_questions, 0], pca_attn_outputs[tn_questions:2*tn_questions, 1], color='green', label='T9') # t9 questions\n",
        "  ax.scatter(pca_attn_outputs[2*tn_questions:, 0], pca_attn_outputs[2*tn_questions:, 1], color='blue', label='T10 (10-18)') # t10 questions\n",
        "\n",
        "  if title != \"\" :\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2K3y7pMlQr"
      },
      "outputs": [],
      "source": [
        "# Graph the PCA of Pasn.Ln.Hn's attention pattern, using T8, T9, T10 questions that differ in the An digit\n",
        "def add_one_pca_subplot(ax, t_position, t_layer, t_head, t_digit, operation):\n",
        "  try:\n",
        "    pca, pca_attn_outputs, title = calc_tricase_pca(t_position, t_layer, t_head, t_digit, operation)\n",
        "    graph_pca( pca, pca_attn_outputs, ax, title)\n",
        "  except Exception as e:\n",
        "    desc = \"add_one_pca_subplot(\" + str(t_position) + \",\"+ str(t_layer) + \",\"+ str(t_head) + \",\"+ str(t_digit) + \",\"+ str(operation) + \")\"\n",
        "    print( desc + \" Failed:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEF7MQqCMngv"
      },
      "outputs": [],
      "source": [
        "def save_plt_to_file( full_title ):\n",
        "  if cfg.save_graph_to_file:\n",
        "    filename = full_title.replace(\" \", \"_\").replace(\",\", \"\").replace(\":\", \"_\")  + '.png'\n",
        "    plt.savefig(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "#Part 19: Addition PCA decomposition tri-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"tri-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "if not use_pca:\n",
        "  print( \"PCA library failed to import. So PCA not done\")\n",
        "\n",
        "if use_pca and cfg.perc_add() > 0 :\n",
        "  op = PLUS_INDEX\n",
        "\n",
        "  fig, axs = plt.subplots(2, 2)\n",
        "\n",
        "  if cfg.n_digits == 5 and cfg.n_layers == 2 and cfg.n_heads == 3:\n",
        "    fig, axs = plt.subplots(4, 2)\n",
        "    fig.set_figheight(8)\n",
        "    fig.set_figwidth(5)\n",
        "\n",
        "    # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "    add_one_pca_subplot(axs[0, 0], 8, 0, 1, 2, op)    # P8.L0.H1 is interpretable only for A2\n",
        "    add_one_pca_subplot(axs[0, 1], 9, 0, 1, 1, op)    # P9.L0.H1 is interpretable only for A1\n",
        "    add_one_pca_subplot(axs[1, 0], 11, 0, 1, 3, op)   # P11.L0.H1 is interpretable only for A3\n",
        "    add_one_pca_subplot(axs[1, 1], 11, 0, 2, 4, op)   # P11.L0.H2 is interpretable only for A4\n",
        "    add_one_pca_subplot(axs[2, 0], 12, 0, 1, 3, op)   # P12.L0.H1 is interpretable only for A3\n",
        "    add_one_pca_subplot(axs[2, 1], 13, 0, 1, 2, op)   # P13.L0.H1 is interpretable only for A2\n",
        "    add_one_pca_subplot(axs[3, 0], 14, 0, 1, 1, op)   # P14.L0.H1 is interpretable only for A1\n",
        "\n",
        "  if cfg.n_digits == 6 and cfg.n_layers == 2 and cfg.n_heads == 3:\n",
        "    fig, axs = plt.subplots(5, 2)\n",
        "    fig.set_figheight(8)\n",
        "    fig.set_figwidth(5)\n",
        "\n",
        "    # Plot all useful attention heads in the positions 10 to 17 with the clearest An selected\n",
        "    add_one_pca_subplot(axs[0, 0], 10, 0, 0, 3, op)   # P10.L0.H0 is interpretable only for A3\n",
        "    add_one_pca_subplot(axs[0, 1], 11, 0, 0, 2, op)   # P11.L0.H0 is interpretable only for A2\n",
        "    add_one_pca_subplot(axs[1, 0], 12, 0, 0, 1, op)   # P12.L0.H0 is interpretable only for A1\n",
        "    add_one_pca_subplot(axs[1, 1], 14, 0, 0, 4, op)   # P14.L0.H0 is interpretable only for A4\n",
        "    add_one_pca_subplot(axs[2, 0], 14, 1, 1, 4, op)   # P14.L1.H1 is interpretable only for A4\n",
        "    add_one_pca_subplot(axs[2, 1], 15, 0, 0, 4, op)   # P15.L0.H0 is interpretable only for A4\n",
        "    add_one_pca_subplot(axs[3, 0], 16, 0, 0, 3, op)   # P16.L0.H0 is interpretable only for A3\n",
        "    add_one_pca_subplot(axs[3, 1], 17, 0, 0, 2, op)   # P17.L0.H0 is interpretable only for A2\n",
        "    add_one_pca_subplot(axs[4, 0], 19, 0, 0, 0, op)   # P19.L0.H0 is interpretable only for A0\n",
        "\n",
        "\n",
        "  lines_labels = [axs[0,0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Trigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3611cpuEFhoW"
      },
      "source": [
        "#Part 19B: Addition PCA decomposition bi-state results\n",
        "\n",
        "Plot attention heads in the positions 8 to 16 with a clear \"bi-state\" response to (exactly) one An."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAT8Z54oMuur"
      },
      "outputs": [],
      "source": [
        "if not use_pca:\n",
        "  print( \"PCA library failed to import. So PCA not done\")\n",
        "\n",
        "if use_pca and cfg.perc_add() > 0 :\n",
        "  op = PLUS_INDEX\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2)\n",
        "  fig.set_figheight(2)\n",
        "  fig.set_figwidth(5)\n",
        "\n",
        "  if cfg.n_digits == 5 and cfg.n_layers == 2 and cfg.n_heads == 3:\n",
        "    # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "    add_one_pca_subplot(axs[0], 10, 0, 1, 0, op)   # P10.L0.H1 is clear only for A0\n",
        "    add_one_pca_subplot(axs[1], 15, 0, 1, 0, op)   # P15.L0.H1 is clear only for A0\n",
        "\n",
        "  if cfg.n_digits == 6 and cfg.n_layers == 2 and cfg.n_heads == 3:\n",
        "    # Plot all useful attention heads in the positions 8 to 12 with the clearest An selected\n",
        "    add_one_pca_subplot(axs[0], 12, 0, 2, 0, op)   # P12.L0.H2 is clear only for A0\n",
        "\n",
        "\n",
        "  lines_labels = [axs[0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  fig.legend(lines, labels, loc='lower center', ncol=4)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('PCA_Bigrams')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "#Part 19C: PCA decomposition of useful cells with digits 0 to 4\n",
        "\n",
        "Parts 19A and 19B are selective. This part is not. Use it to find (verify) the interesting parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfpkXmAMzg4"
      },
      "outputs": [],
      "source": [
        "def graph_all_pca_results(op):\n",
        "  for useful_cell in ucfg.useful_cells:\n",
        "    if useful_cell.is_head:\n",
        "      position = useful_cell.position\n",
        "      layer = useful_cell.layer\n",
        "      head = useful_cell.head\n",
        "      print( \"PCA: position=\", position, \"layer=\", layer, \"head=\", head)\n",
        "\n",
        "      fig, axs = plt.subplots(4, 2)\n",
        "\n",
        "      add_one_pca_subplot(axs[0, 0], position, layer, head, 0, op)\n",
        "      add_one_pca_subplot(axs[0, 1], position, layer, head, 1, op)\n",
        "      add_one_pca_subplot(axs[1, 0], position, layer, head, 2, op)\n",
        "      add_one_pca_subplot(axs[1, 1], position, layer, head, 3, op)\n",
        "      add_one_pca_subplot(axs[2, 0], position, layer, head, 4, op)\n",
        "      add_one_pca_subplot(axs[2, 1], position, layer, head, 5, op)\n",
        "      add_one_pca_subplot(axs[3, 0], position, layer, head, 6, op)\n",
        "      add_one_pca_subplot(axs[3, 1], position, layer, head, 7, op)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "if use_pca :\n",
        "\n",
        "  if cfg.perc_add() > 0:\n",
        "    graph_all_pca_results(PLUS_INDEX)\n",
        "  if cfg.perc_sub > 0:\n",
        "    graph_all_pca_results(MINUS_INDEX)\n",
        "\n",
        "else:\n",
        "  print( \"PCA library failed to import. So PCA not done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgCog0mYkYPV"
      },
      "source": [
        "# Part 21A : Set Up Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (causual abstraction) to the model attention heads.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8VoNc_ckfrJ"
      },
      "outputs": [],
      "source": [
        "class A_Config():\n",
        "  token_position : int  # The token position we want to get/set. P8 to P11 contribute to A5 calculations\n",
        "  layer : int # The layer we want to get/set\n",
        "  heads = [] # The heads we want to get/set\n",
        "  threshold : int\n",
        "  hook_calls : int\n",
        "  answer_failures : int   # Failures of any digit\n",
        "\n",
        "  questions = []\n",
        "  store = []\n",
        "  null_hooks = []\n",
        "  get_hooks = []\n",
        "  put_hooks = []\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.token_position = 10\n",
        "    self.layer = 0\n",
        "    self.heads = []\n",
        "    self.threshold = 0.00001\n",
        "    self.hook_calls = 0\n",
        "    self.answer_failures = 0\n",
        "    self.questions = []\n",
        "    self.store = []\n",
        "    self.null_hooks = []\n",
        "    self.get_hooks = []\n",
        "    self.put_hooks = []\n",
        "\n",
        "\n",
        "acfg = A_Config()\n",
        "acfg.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMdSybNpnU0m"
      },
      "outputs": [],
      "source": [
        "# Get and put attention head value hooks\n",
        "\n",
        "def a_null_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  acfg.hook_calls += 1\n",
        "  #print(\"In a_null_attn_z_hook\", value.shape)  # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "\n",
        "def a_get_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_get_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_get_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In acfg.get_l1_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "    acfg.store = value.clone()\n",
        "\n",
        "\n",
        "def a_put_l0_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 0:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_put_l1_attn_z_hook(value, hook):\n",
        "  global acfg\n",
        "\n",
        "  if acfg.layer == 1:\n",
        "    acfg.hook_calls += 1\n",
        "    # print( \"In a_put_l1_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "    for head_index in acfg.heads:\n",
        "      value[:,acfg.token_position,head_index,:] = acfg.store[:,acfg.token_position,head_index,:].clone()\n",
        "\n",
        "\n",
        "def a_reset(token_position, layer, heads):\n",
        "  global acfg\n",
        "\n",
        "  acfg.reset()\n",
        "\n",
        "  acfg.token_position = token_position\n",
        "  acfg.layer = layer\n",
        "  acfg.heads = heads\n",
        "\n",
        "  acfg.null_hooks = [(l_attn_hook_z_name[0], a_null_attn_z_hook)]\n",
        "  acfg.get_hooks = [(l_attn_hook_z_name[0], a_get_l0_attn_z_hook),(l_attn_hook_z_name[1], a_get_l1_attn_z_hook)]\n",
        "  acfg.put_hooks = [(l_attn_hook_z_name[0], a_put_l0_attn_z_hook),(l_attn_hook_z_name[1], a_put_l1_attn_z_hook)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SeIO06JnU7I"
      },
      "outputs": [],
      "source": [
        "def a_predict_question(description, the_hooks, always):\n",
        "  global acfg\n",
        "  global model\n",
        "\n",
        "  acfg.hook_calls = 0\n",
        "  acfg.answer_failures = 0\n",
        "\n",
        "  main_model.reset_hooks()\n",
        "  main_model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = main_model.run_with_hooks(acfg.questions.cuda(), return_type=\"logits\", fwd_hooks=the_hooks)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, acfg.questions.cuda())\n",
        "\n",
        "  for question_num in range(acfg.questions.shape[0]):\n",
        "    loss_max = utils.to_numpy(loss_fn(all_losses_raw[question_num]).max())\n",
        "    answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "    match_str = \"\"\n",
        "    if loss_max > acfg.threshold:\n",
        "      acfg.answer_failures += 1\n",
        "      q = acfg.questions[question_num]\n",
        "      a = tokens_to_signed_int(q, cfg.n_digits*2 + 2, cfg.n_digits+1)\n",
        "      match_str = get_digit_accuracy_impact( a, answer_str )\n",
        "    if match_str == \"\":\n",
        "      match_str = \"(none)\"\n",
        "\n",
        "    if always or (loss_mean > acfg.threshold):\n",
        "      loss_str = \"(none)\" if loss_mean < 1e-7 else str(loss_max)\n",
        "\n",
        "      print(description, \"  ModelPredicts:\", answer_str, \"  DigitsImpacted:\", match_str, \"  Loss:\", loss_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk0gVCF9Gr5D"
      },
      "outputs": [],
      "source": [
        "def a_run_intervention_core(token_position, layer, heads, store_question, alter_question):\n",
        "  a_reset(token_position, layer, heads)\n",
        "\n",
        "  # Predict first question and store activation values (including the Vn.BA)\n",
        "  acfg.questions = make_questions([store_question], PLUS_INDEX)\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  a_predict_question(\"Store activation\", acfg.get_hooks, False)\n",
        "\n",
        "  # Predict second question. Then rerun overriding Pn_Lm_Hp to give bad answer\n",
        "  acfg.questions = make_questions([alter_question], PLUS_INDEX)\n",
        "  a_predict_question(\"Unit test (null hook)\", acfg.null_hooks, False)\n",
        "  prompt = \"Intervening on P\" + str(token_position) + \".L\" + str(layer) + \".H\"\n",
        "  for head_index in acfg.heads:\n",
        "    prompt += str(head_index) + \",\"\n",
        "  a_predict_question(prompt, acfg.put_hooks, True)\n",
        "\n",
        "\n",
        "def a_run_intervention(description, token_position, layer, heads, store_question, alter_question):\n",
        "  if cfg.n_digits == 5 and cfg.n_layers == 2:\n",
        "    print(description)\n",
        "    a_run_intervention_core(token_position, layer, heads, store_question, alter_question)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFZIELF0VIQ2"
      },
      "source": [
        "# Part 21C: Subtraction edge case tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAkYKToUVPCB"
      },
      "outputs": [],
      "source": [
        "global verbose\n",
        "verbose = True\n",
        "\n",
        "if cfg.perc_sub > 0:\n",
        "  # Look for questions that fail even with no intervention\n",
        "  acfg.questions = make_ng_questions()\n",
        "  a_predict_question(\"Subtraction Neg questions\", acfg.null_hooks, True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bbeIfUxvLzl"
      },
      "source": [
        "# Part 21B : Run Addition Interchange Interventions\n",
        "\n",
        "Here we test our mapping of our mathematical framework (casual abstraction) to the model attention heads.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFLdZkmEHhIo"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P8.L0.H1 performs V2.C = TriCase(D2, D2) impacting A4 and A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V2 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V2 has no MC.\n",
        "a_run_intervention(\"No V2.MC: No impact expected\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [77711, 22711] # Sum is 100422. V2 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A54 digit impacts. Expect 109999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [17711, 22711] # Sum is 035422. V2 has MC\n",
        "alter_question = [ 4444,  5555] # Sum is 009999. V2 has no MC\n",
        "a_run_intervention(\"Insert V2.MC: Expect A4 digit impact. Expect 019999.\", 8, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P8.L0.H1 is: Based on D2 and D2'. Triggers on a V2 carry value. Provides \"carry 1\" used in A5 and A4 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNtG_mlXeZKd"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P9.L0.H1 performs V1.C = TriCase(D1, D1) impacting A5, A4 & A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "alter_question = [ 11111, 11111] # Sum is 022222. V1 has no MC\n",
        "a_run_intervention(\"No V1.MC: No impact expected\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V1 has no MC.\n",
        "a_run_intervention(\"Insert V1.MC: Expect A543 digit impacts. Expect 100999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A43 digit impacts. Expect 010999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11171, 11171] # Sum is 022342. V1 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V1 has no MC\n",
        "a_run_intervention(\"Insert V1.MC: Expect A3 digit impact. Expect 001999.\", 9, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H1 is: Based on D1 and D1'. Triggers on a V1 carry value. Provides \"carry 1\" used in A5, A4 & A3 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDt2LmNwiMGA"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P10.L0.H1 performs V1.C2 = TriAdd(V1.C, TriCase(D0, D0)) impacting A5, A4, A3 & A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [ 11111, 33333] # Sum is 044444. V0 has no MC.\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"No impact expected\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: No impact as expected\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [ 44444, 55555] # Sum is 099999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A5432 digit impacts. Expect 100099.\", 10, 0, [1], store_question, alter_question)\n",
        "# Results: Impact on A5432 as expected. Got expected value 100099\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [  4444,  5555] # Sum is 009999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A432 digit impacts. Expect 010099.\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [   444,   555] # Sum is 000999. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC: Expect A32 digit impacts. Expect 001099\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [ 11117, 11117] # Sum is 022234. V0 has MC\n",
        "alter_question = [    44,    55] # Sum is 000099. V0 has no MC\n",
        "a_run_intervention(\"Insert D0.MC Expect A2 digit impacts. Expect 000199\", 10, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P10.L0.H1 is: Based on D0 and D0'. Triggers on a V0 carry value. Provides \"carry 1\" used in A5, A4, A3 & A2 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxGCodzep7qV"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P11.L0.H1 performs V3.C4 = TriAdd(TriCase(D3, D3),TriAdd(V2.C,V1.C2)) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 44444] # Sum is 088888. V3 sums to 8 (has no MC).\n",
        "alter_question = [11111, 11111] # Sum is 022222. V3 has no MC.\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 13111] # Sum is 032111. V3 sums to 9 (has no MC).\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"No V3.MC: No impact expected\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "store_question = [16111, 16111] # Sum is 032111. V3 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V3 has no MC\n",
        "a_run_intervention(\"Insert V3.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P11.L0.H1 is: Based on D3 and D3'. Triggers on a V3 carry value. Provides \"carry 1\" used in A5 calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo55vCvCoMq7"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P11.L0.H2 performs V4.C = TriCase(D4, D4) impacting A5 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [44444, 55555] # Sum is 099999. V4 has no MC.\n",
        "alter_question = [11111, 11111] # Sum is 022222. V4 has no MC.\n",
        "a_run_intervention(\"No V4.MC: No impact expected\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "store_question = [71111, 71111] # Sum is 100422. V4 has MC\n",
        "alter_question = [44444, 55555] # Sum is 099999. V4 has no MC\n",
        "a_run_intervention(\"Insert V4.MC: Expect A5 digit impact. Expect 199999.\", 11, 0, [2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P9.L0.H2 is: Based on D4 and D4'. Triggers on a V4 carry value. Provides \"carry 1\" used in A5 calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jSE5S9UQFpn"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P12.L0.H0 and H2 performs V4.BA = (D4 + D4) % 10 impacting A4 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [72222, 71111] # Sum is 143333\n",
        "alter_question = [12342, 56573] # Sum is 068915\n",
        "a_run_intervention(\"Override D4/D4'. Expect A4 digit impact. Expect 048915\", 12, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0+H2 is: Adds D4 and D4'. Impacts A4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6UpIJbfPG6r"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P13.L0.H0 and H2 performs V3.BA = (D3 + D3) % 10 impacting A3 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [23222, 13111] # Sum is 36333\n",
        "alter_question = [12342, 56573] # Sum is 68915\n",
        "a_run_intervention(\"Override D3/D3'. Expect A3 digit impact. Expect 66915\", 13, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P13.L0.H0+H2 is: Adds D3 and D3'. Impacts A3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXiOPyZ1ONcg"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P14.L0.H0 and H2 performs V2.BA = (D2 + D2) % 10 impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12342, 56573] # Sum is 68915. Has V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68715\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22322, 11311] # Sum is 33633. No V1.MC\n",
        "alter_question = [12133, 56133] # Sum is 68266. No V1.MC\n",
        "a_run_intervention(\"Override D2/D2'. Expect A2 digit impact. Expect 68666\", 14, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P12.L0.H0 and H2 both impact A2, and together sum D2 and D2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAzB924mQkyN"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2, impacting A2 accuracy\")\n",
        "print()\n",
        "\n",
        "\n",
        "store_question = [55555, 44454] # Sum is 100009. Has V1.MC\n",
        "alter_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 14, 0, [1], store_question, alter_question) # Get 055655. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 055655\", 10, 0, [1], store_question, alter_question) # Get 055555. No impact.\n",
        "\n",
        "store_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "alter_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 14, 0, [1], store_question, alter_question) # Get 066766. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 066766\", 10, 0, [1], store_question, alter_question) # Get 066666. No impact.\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55590, 44490] # Sum is 100080. Has V1.MC\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 14, 0, [1], store_question, alter_question) # Get 100980. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 100980\", 10, 0, [1], store_question, alter_question) # Get 100080. No impact.\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 behaviour is different from P10.L0.H1 behaviour\n",
        "# - P14.L0.H1 does not simply copy P10.L0.H1 (although this would be a valid way to get perfect accuracy in A2)\n",
        "print()\n",
        "\n",
        "store_question = [12345, 54321] # Sum is 066666. No V1.MC\n",
        "alter_question = [55555, 44445] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "store_question = [22222, 33333] # Sum is 055555. No V1.MC\n",
        "alter_question = [66663, 33337] # Sum is 100000. Has V0.MC, V1.MC, V1.C2\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C2. Expect A2 digit impact. Expect 100900\", 14, 0, [1], store_question, alter_question) # Get 100900. Correct\n",
        "a_run_intervention(\"Override V1.MC impacting V1.C1. Expect A2 digit impact. Expect 099900\", 10, 0, [1], store_question, alter_question) # Get 099900. Correct\n",
        "\n",
        "# Above shows:\n",
        "# - P14.L0.H1 does rely on P10.L0.H1 for V1.C2 information when V1.C != V1.C2\n",
        "# - P14.L0.H1 calculates V1.C information itself from D1+D1'.\n",
        "\n",
        "# Overall confirmed: P14.L0.H1 calculates V1.C1 but also relies on P10.V1.C2 when V1.C != V1.C2. Impacts A2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJiVBPZe6DUe"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P15.L0.H0 and H2 performs V1.BA = (D1 + D1) % 10 impacting A1 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12322, 56523] # Sum is 68845. No V0.MC\n",
        "a_run_intervention(\"Override D1/D1'. Expect A1 digit impact. Expect 68885\", 15, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H0 and H2 both impact A1, and together sum D1 and D1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVrX9QmOnVCM"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P15.L0.H1 performs V0.MC = (D0 + D0) / 10 impacting A1 (A one) accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22244, 11149] # Sum is 33393. Has V0.MC\n",
        "alter_question = [12342, 56513] # Sum is 68855. No V0.MC\n",
        "a_run_intervention(\"Override D0.MC. Expect A1 digit impact. Expect 68865\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Now test counter-claim that an intervention where both questions do NOT generate a D0.MC has NO impact on A1\n",
        "store_question = [22242, 11141] # Sum is 33383. No V0.MC\n",
        "alter_question = [12342, 56523] # Sum is 68865. No V0.MC\n",
        "a_run_intervention(\"No impact expected\", 15, 0, [1], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P15.L0.H1: Triggers when D0 + D0' > 10. Impacts A1 digit by 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gM8TpWeyysU"
      },
      "outputs": [],
      "source": [
        "print( \"Test claim that P16.L0.H0 and H2 performs D0.BA = (D0 + D0) % 10 impacting A0 accuracy\")\n",
        "print()\n",
        "\n",
        "store_question = [22225, 11114] # Sum is 33339\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68909\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "store_question = [22228, 11119] # Sum is 33347\n",
        "alter_question = [12342, 56563] # Sum is 68905\n",
        "a_run_intervention(\"Override D0/D0'. Expect A0 digit impact. Expect 68907\", 16, 0, [0,2], store_question, alter_question)\n",
        "\n",
        "# Confirmed that P16.L0.H0 and H2 both impact A0, and together sum D0 and D0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTs6Cu55jB7y"
      },
      "source": [
        "#Part 22: MLP Visualisation (incomplete, on-hold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YviVHnBRjDcs"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# number of questions in batch that generated sample_cache\n",
        "num_questions = varied_questions.shape[0]\n",
        "\n",
        "\n",
        "def get_mlp_data(data_set_name):\n",
        "\n",
        "  data_set = sample_cache[data_set_name]\n",
        "  # print( data_set_name + \" shape\", data_set.shape) # 239, 22, 2040 = num_questions, n_ctx, d_mlp\n",
        "\n",
        "  raw_data = data_set[:,-3]\n",
        "  # print( \"raw_data shape\", raw_data.shape) # 239, 2040 = num_questions, d_mlp\n",
        "\n",
        "  answer = einops.rearrange(raw_data, \"(x y) d_mlp -> x y d_mlp\", x=num_questions).cpu().numpy()\n",
        "  # print( \"answer shape\", answer.shape) # 239, 1, 2040 = num_questions, ??, d_mlp\n",
        "\n",
        "  return answer\n",
        "\n",
        "\n",
        "l0_mlp_hook_pre_sq = get_mlp_data('blocks.0.mlp.hook_pre')\n",
        "l0_mlp_hook_post_sq = get_mlp_data('blocks.0.mlp.hook_post')\n",
        "l1_mlp_hook_pre_sq = get_mlp_data('blocks.1.mlp.hook_pre') if cfg.n_layers > 1 else l0_mlp_hook_pre_sq\n",
        "l1_mlp_hook_post_sq = get_mlp_data('blocks.1.mlp.hook_post') if cfg.n_layers > 1 else l0_mlp_hook_post_sq\n",
        "\n",
        "\n",
        "def plot_mlp_neuron_activation(pos: int):\n",
        "    clear_output()\n",
        "\n",
        "    l0_mlp_pre_data = l0_mlp_hook_pre_sq[:,:,pos]\n",
        "    l0_mlp_post_data = l0_mlp_hook_post_sq[:,:,pos]\n",
        "    l1_mlp_pre_data = l1_mlp_hook_pre_sq[:,:,pos]\n",
        "    l1_mlp_post_data = l1_mlp_hook_post_sq[:,:,pos]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
        "\n",
        "    plot = axs[0].imshow(l1_mlp_pre_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_pre_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "    plot = axs[1].imshow(l1_mlp_post_data, cmap='magma', vmin=0, vmax=1)\n",
        "    cbar = plt.colorbar(plot, fraction=0.1)\n",
        "    cbar.set_label(r'l0_mlp_post_data {}'.format(pos))\n",
        "    #axs[0].set_ylim(-0.5, 99.5)\n",
        "    #axs[0].set_yticks(range(100), labels=range(100), size=5.5);\n",
        "    #axs[0].set_xticks(range(100), labels=range(100), size=5.5, rotation='vertical');\n",
        "\n",
        "\n",
        "interact(plot_mlp_neuron_activation, pos=widgets.IntText(value=0, description='Index:'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjaQvhhayUL"
      },
      "source": [
        "# Part 25 : Is the model 100% accurate?\n",
        "\n",
        "This is hard to prove. If it does 1M predictions without error, then we assume it is 100%.\n",
        "\n",
        "This part takes ~9 mins to run for add_6d_2l_3h model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlLOZMVkeqvm"
      },
      "outputs": [],
      "source": [
        "def null_hook(value, hook):\n",
        "  global verbose\n",
        "\n",
        "  verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znsauYqjaxok"
      },
      "outputs": [],
      "source": [
        "def one_million_questions():\n",
        "  global verbose\n",
        "  global ds\n",
        "\n",
        "  verbose = False\n",
        "\n",
        "  cfg.batch_size = 512 # For speed\n",
        "  cfg.seed = 345621 # Randomly chosen\n",
        "  ds = data_generator() # Re-initialise the data generator\n",
        "\n",
        "  the_threshold = 0.12\n",
        "  the_successes = 0\n",
        "  the_fails = 0\n",
        "\n",
        "  num_batches = 1000000//cfg.batch_size\n",
        "  for epoch in range(num_batches):\n",
        "      tokens = next(ds)\n",
        "\n",
        "      the_hook = [(l_attn_hook_z_name[0], null_hook)]\n",
        "      predict_experiment_question(tokens, the_hook, the_threshold)\n",
        "\n",
        "      if get_pattern_fails_total() > 0:\n",
        "        break\n",
        "\n",
        "      the_successes = the_successes + cfg.batch_size\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "          print(\"Batch\", epoch, \"of\", num_batches, \"#Successes=\", the_successes)\n",
        "\n",
        "  print(\"successes\", the_successes, \"num_fails\", the_fails)\n",
        "\n",
        "\n",
        "# Commented out as it takes ~9 minutes to run with cfg.n_layers=2, n_digits=6, train=30K\n",
        "# one_million_questions()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "-KJhCxFtNKfm",
        "99LIC1l4MD32",
        "fHSY3blNMe7I",
        "Rbiau9foMp3h",
        "3611cpuEFhoW",
        "jIu3Pr9CMx3l",
        "sgCog0mYkYPV",
        "7bbeIfUxvLzl",
        "lTs6Cu55jB7y",
        "2PjaQvhhayUL"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}